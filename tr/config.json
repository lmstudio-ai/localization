{
  "noInstanceSelected": "Hiç bir model örneği seçilmedi",
  "resetToDefault": "Sıfırla",
  "showAdvancedSettings": "Gelişmiş ayarları göster",
  "showAll": "Tümünü göster",
  "basicSettings": "Temel",
  "configSubtitle": "Ön ayarları yükle veya kaydet ve model parametre geçersiz kılmasını dene",
  "inferenceParameters/title": "Tahmin Parametreleri",
  "inferenceParameters/info": "Etkileyen tahmin parametrelerini dene.",
  "generalParameters/title": "Genel",
  "samplingParameters/title": "Örnekleme",
  "basicTab": "Temel",
  "advancedTab": "Gelişmiş",
  "advancedTab/title": "🧪 Gelişmiş Yapılandırma",
  "advancedTab/expandAll": "Tümünü genişlet",
  "advancedTab/overridesTitle": "Yapılandırma Geçersiz Kılmaları",
  "advancedTab/noConfigsText": "Kaydedilmemiş herhangi bir değişikliğiniz yok - yukarıdaki değerleri düzenleyerek burada geçersiz kılmaları görebilirsiniz.",
  "loadInstanceFirst": "Yapılandırılabilir parametreleri görmek için bir model yükleyin",
  "noListedConfigs": "Yapılandırılabilir parametre yok",
  "generationParameters/info": "Metin üretimi etkileyen temel parametrelerle dene.",
  "loadParameters/title": "Parametreleri Yükle",
  "loadParameters/description": "Modelin nasıl başlatılacağını ve belleğe yükleneceğini kontrol eden ayarlar.",
  "loadParameters/reload": "Değişiklikleri uygulamak için yeniden yükleyin",
  "discardChanges": "Değişiklikleri atla",
  "loadModelToSeeOptions": "Seçenekleri görmek için bir model yükleyin",
  "llm.prediction.systemPrompt/title": "Sistem İstemi",
  "llm.prediction.systemPrompt/description": "Model'e arka plan yönergeleri vermek için bu alanı kullanın, örneğin kurallar, kısıtlamalar veya genel gereksinimler.",
  "llm.prediction.systemPrompt/subTitle": "AI'ye yönelik rehberlik",
  "llm.prediction.temperature/title": "Sıcaklık",
  "llm.prediction.temperature/subTitle": "Ne kadar rastgelelik eklemek. 0 her zaman aynı sonucu verecekken, daha yüksek değerler yaratıcılığı ve çeşitliliği artırır.",
  "llm.prediction.temperature/info": "llama.cpp yardım belgelerinden: \"Varsayılan değer <{{dynamicValue}}>, rastgelelik ve determinizmanın bir dengesini sağlar. Sıcaklık 0'a yaklaşımı durumunda, her sefer aynı sonucu vermek için en olası bir sonraki token'ı her zaman seçer.\"",
  "llm.prediction.llama.sampling/title": "Örnekleme",
  "llm.prediction.topKSampling/title": "En Üst K Örnekleme",
  "llm.prediction.topKSampling/subTitle": "Sonraki token'ı model tarafından tahmin edilen en yüksek olasılıklı token'lardan biri olarak kısıtlar. Sıcaklık'a benzer şekilde davrandır.",
  "llm.prediction.topKSampling/info": "llama.cpp yardım belgelerinden:\n\nEn üst K örnekleme, model tarafından tahmin edilen en yüksek olasılıklı token'lardan biri olarak bir sonraki token'ı seçen bir metin üretimi yöntemidir.\n\nBu, düşük olasılık veya anlamsız token'ları üretecek riskini azaltır, ancak çıktı çeşitliliğini de sınırlayabilir.\n\nDaha yüksek bir değer için en üst K (örneğin, 100), daha fazla token'i göz önünde bulundurup daha çeşitli metin oluşturacakken, düşük bir değer (örneğin, 10) en olası token'lara odaklanıp daha konservatif bir metin oluşturacaktır.\n\n• Varsayılan değer <{{dynamicValue}}>",
  "llm.prediction.llama.cpuThreads/title": "CPU İş Parçacıkları",
  "llm.prediction.llama.cpuThreads/subTitle": "Tahmin sırasında kullanılacak CPU iş parçacığı sayısı",
  "llm.prediction.llama.cpuThreads/info": "Hesaplama sırasında kullanılan iş parçacığı sayısı. İş parçacığı sayısını artırmanın her zaman daha iyi performans sağlayacağını garanti etmez. Varsayılan değer <{{dynamicValue}}>. ",
  "llm.prediction.maxPredictedTokens/title": "Yanıt Uzunluğunu Sınırlandır",
  "llm.prediction.maxPredictedTokens/subTitle": "AI'nin yanıt uzunluğunu isteğe bağlı olarak sınırlandır",
  "llm.prediction.maxPredictedTokens/info": "Sohbet bot'ının yanıt uzunluğunu kontrol edin. Sınır koymak için açın veya kapattığınızda sohbet bot'u yanıt sonu ne zaman duracağını karar verir.",
  "llm.prediction.maxPredictedTokens/inputLabel": "Maksimum yanıt uzunluğu (token'lar)",
  "llm.prediction.maxPredictedTokens/wordEstimate": "Yaklaşık {{maxWords}} kelime",
  "llm.prediction.repeatPenalty/title": "Tekrar Penaltisi",
  "llm.prediction.repeatPenalty/subTitle": "Aynı token'ı tekrarlamayı ne kadar azaltmak",
  "llm.prediction.repeatPenalty/info": "llama.cpp yardım belgelerinden: \"Modelin yinelenen veya monoton metin üretmesini önlemeye yardımcı olur.\n\nDaha yüksek bir değer (örneğin, 1.5), yinelemeleri daha zorla puanlayacaktırken, düşük bir değer (örneğin, 0.9) daha toleranslı olacaktır.\" • Varsayılan değer <{{dynamicValue}}>",
  "llm.prediction.minPSampling/title": "Min P Örnekleme",
  "llm.prediction.minPSampling/subTitle": "Bir token'ın seçilmek üzere çıkış için minimum temel olasılığı",
  "llm.prediction.minPSampling/info": "llama.cpp yardım belgelerinden:\n\nToken'ların en çok muhtemel token'a göre oranla dikkate alınması gereken minimum olasılığı. [0, 1] aralığında olmalıdır.\n\n• Varsayılan değer <{{dynamicValue}}>",
  "llm.prediction.topPSampling/title": "Top P Örnekleme",
  "llm.prediction.topPSampling/subTitle": "Bir token'ın seçilmek üzere çıkış için minimum temel olasılığı",
  
  "llm.prediction.topPSampling/subTitle": "Olası bir sonraki tokenler için minimum kümülatif olasılık. Sıcaklık parametresine benzer şekilde çalışır.",
  "llm.prediction.topPSampling/info": "llama.cpp yardım dokümanlarından:\n\nTop-p sampling, diğer adıyla nucleus sampling, bir sonraki tokeni en az p kümülatif olasılığa sahip olan token alt kümesinden seçen bir metin oluşturma yöntemidir.\n\nBu yöntem, hem token olasılıklarını hem de örneklenen token sayısını dikkate alarak çeşitlilik ve kalite arasında bir denge sağlar.\n\nDaha yüksek bir top-p değeri (örneğin, 0.95) daha çeşitli metinler üretirken, daha düşük bir değer (örneğin, 0.5) daha odaklı ve muhafazakar metinler oluşturur. Değer (0, 1] aralığında olmalıdır.\n\n• Varsayılan değer <{{dynamicValue}}>",
  "llm.prediction.stopStrings/title": "Durdurma Dizeleri",
  "llm.prediction.stopStrings/subTitle": "Modelin daha fazla token üretmesini durdurması gereken dizeler",
  "llm.prediction.stopStrings/info": "Belirli dizeler, karşılaşıldığında modelin daha fazla token üretmesini durdurur.",
  "llm.prediction.stopStrings/placeholder": "Bir dize girin ve ⏎ tuşuna basın",
  "llm.prediction.contextOverflowPolicy/title": "Bağlam Taşması",
  "llm.prediction.contextOverflowPolicy/subTitle": "Konuşma modelin işleyebileceği boyutu aştığında modelin nasıl davranması gerektiği",
  "llm.prediction.contextOverflowPolicy/info": "Konuşmanın modelin çalışma belleğini ('bağlam') aştığı durumda ne yapılacağını belirleyin.",
  "llm.prediction.llama.frequencyPenalty/title": "Frekans Cezası",
  "llm.prediction.llama.presencePenalty/title": "Varlık Cezası",
  "llm.prediction.llama.tailFreeSampling/title": "Kuyruk Serbest Örneklemesi",
  "llm.prediction.llama.locallyTypicalSampling/title": "Yerel Tipik Örneklemesi",
  "llm.prediction.onnx.topKSampling/title": "En İyi K Örneklemesi",
  "llm.prediction.onnx.topKSampling/subTitle": "Bir sonraki tokeni en yüksek olasılıklı K token arasından sınırlar. Sıcaklık parametresine benzer şekilde çalışır.",
  "llm.prediction.onnx.topKSampling/info": "ONNX dokümantasyonundan:\n\nEn üstteki K filtreleme için saklanacak en yüksek olasılıklı kelime dağarcığı tokenlerinin sayısı.\n\n• Bu filtre varsayılan olarak kapalıdır.",
  "llm.prediction.onnx.repeatPenalty/title": "Tekrarlama Cezası",
  "llm.prediction.onnx.repeatPenalty/subTitle": "Aynı tokenin tekrar etmesini ne kadar engellemek istediğinizi belirtir",
  "llm.prediction.onnx.repeatPenalty/info": "Daha yüksek bir değer, modelin kendisini tekrar etmesini engeller.",
  "llm.prediction.onnx.topPSampling/title": "En İyi P Örneklemesi",
  "llm.prediction.onnx.topPSampling/subTitle": "Olası bir sonraki tokenler için minimum kümülatif olasılık. Sıcaklık parametresine benzer şekilde çalışır.",
  "llm.prediction.onnx.topPSampling/info": "ONNX dokümantasyonundan:\n\nSadece toplam olasılıkları TopP veya daha yüksek olan en olası tokenler oluşturulmak üzere saklanır.\n\n• Bu filtre varsayılan olarak kapalıdır.",
  "llm.prediction.seed/title": "Tohum",
  "llm.prediction.structured/title": "Yapılandırılmış Çıktı",
  "llm.prediction.structured/info": "Yapılandırılmış Çıktı",
  "llm.prediction.structured/description": "Gelişmiş: Modelden belirli bir çıktı formatı zorlamak için bir JSON Şeması sağlayabilirsiniz. Daha fazla bilgi için [belgelere](https://lmstudio.ai/docs/advanced/structured-output) bakın.",
  "llm.prediction.promptTemplate/title": "Komut Şablonu",
  "llm.prediction.promptTemplate/subTitle": "Sohbet mesajlarının modele gönderildiği format. Bunu değiştirmek beklenmedik davranışlara neden olabilir - ne yaptığınızdan emin olun!",
  "llm.load.contextLength/title": "Bağlam Uzunluğu",
  "llm.load.contextLength/subTitle": "Modelin tek bir komutta dikkate alabileceği maksimum token sayısı. Daha fazla yönetme yöntemi için 'Çıkarım Parametreleri' altında 'Konuşma Taşması' seçeneklerine bakın.",
  "llm.load.contextLength/info": "Modelin aynı anda dikkate alabileceği maksimum token sayısını belirtir, bu da işleme sırasında ne kadar bağlam tuttuğunu etkiler.",
  "llm.load.contextLength/warning": "Bağlam uzunluğu için yüksek bir değer ayarlamak bellek kullanımını önemli ölçüde artırabilir.",
  "llm.load.seed/title": "Tohum",
  "llm.load.seed/subTitle": "Metin oluşturmada kullanılan rastgele sayı üretecinin tohum değeri. -1 rastgele demektir.",
  "llm.load.seed/info": "Rastgele Tohum: Tekrarlanabilir sonuçlar sağlamak için rastgele sayı üretimi için tohum değerini ayarlar.",
  "llm.load.llama.evalBatchSize/title": "Değerlendirme Parti Boyutu",
  "llm.load.llama.evalBatchSize/subTitle": "Bir seferde işlenecek giriş token sayısı. Bunu artırmak performansı artırır ancak bellek kullanımını artırır.",
  "llm.load.llama.evalBatchSize/info": "Değerlendirme sırasında bir partide birlikte işlenen örnek sayısını ayarlar, hız ve bellek kullanımını etkiler.",
  "llm.load.llama.ropeFrequencyBase/title": "RoPE Frekans Tabanı",
  "llm.load.llama.ropeFrequencyBase/subTitle": "Rotary Pozisyon Gömme (RoPE) için özel taban frekansı. Bunu artırmak yüksek bağlam uzunluklarında daha iyi performans sağlayabilir.",
  "llm.load.llama.ropeFrequencyBase/info": "[Gelişmiş] Rotary Pozisyon Kodlaması için taban frekansını ayarlar, pozisyon bilgisi nasıl gömüldüğünü etkiler.",
  "llm.load.llama.ropeFrequencyScale/title": "RoPE Frekans Ölçeği",
  "llm.load.llama.ropeFrequencyScale/subTitle": "Bağlam uzunluğu, RoPE kullanarak etkin bağlamı genişletmek için bu faktörle ölçeklenir.",
  "llm.load.llama.ropeFrequencyScale/info": "[Gelişmiş] Rotary Pozisyon Kodlaması için frekans ölçeğini değiştirerek pozisyon kodlama inceliğini kontrol eder.",
  "llm.load.llama.acceleration.offloadRatio/title": "GPU Yük Aktarma",
  "llm.load.llama.acceleration.offloadRatio/subTitle": "GPU hızlandırma için hesaplanacak ayrık model katmanlarının sayısı",
  "llm.load.llama.acceleration.offloadRatio/info": "GPU'ya aktarılacak katman sayısını ayarlayın.",
  "llm.load.llama.flashAttention/title": "Hızlı Dikkat",
  "llm.load.llama.flashAttention/subTitle": "Bazı modellerde bellek kullanımını ve üretim süresini azaltır",
  "llm.load.llama.flashAttention/info": "Dikkat mekanizmalarını hızlandırarak daha hızlı ve verimli işleme sağlar.",
  "llm.load.numExperts/title": "Uzman Sayısı",
  "llm.load.numExperts/subTitle": "Modelde kullanılacak uzman sayısı",
  "llm.load.numExperts/info": "Modelde kullanılacak uzman sayısı",
  "llm.load.llama.keepModelInMemory/title": "Modeli Bellekte Tut",
  "llm.load.llama.keepModelInMemory/subTitle": "Model GPU'ya aktarılsa bile sistem belleğini ayırır. Performansı artırır ancak daha fazla sistem RAM'i gerektirir.",
  "llm.load.llama.keepModelInMemory/info": "Modelin diske taşınmasını önler, daha hızlı erişim sağlar ancak daha yüksek RAM kullanımı gerektirir.",
  "llm.load.llama.useFp16ForKVCache/title": "KV Önbelleği İçin FP16 Kullan",
  "llm.load.llama.useFp16ForKVCache/info": "Önbelleği yarı hassasiyetli (FP16) olarak saklayarak bellek kullanımını azaltır.",
  "llm.load.llama.tryMmap/title": "mmap() Deneyin",
  "llm.load.llama.tryMmap/subTitle": "Modelin yükleme süresini iyileştirir. Bunu devre dışı bırakmak, model sistem RAM'inden büyük olduğunda performansı artırabilir.",
  "llm.load.llama.tryMmap/info": "Model dosyalarını doğrudan diskten belleğe yükler.",
  "embedding.load.contextLength/title": "Bağlam Uzunluğu",
  "embedding.load.contextLength/subTitle": "Modelin tek bir komutta dikkate alabileceği maksimum token sayısı. Daha fazla yönetme yöntemi için 'Çıkarım Parametreleri' altında 'Konuşma Taşması' seçeneklerine bakın.",
  "embedding.load.contextLength/info": "Modelin aynı anda dikkate alabileceği maksimum token sayısını belirtir, bu da işleme sırasında ne kadar bağlam tuttuğunu etkiler.",
  "embedding.load.llama.ropeFrequencyBase/title": "RoPE Frekans Tabanı",
  "embedding.load.llama.ropeFrequencyBase/subTitle": "Rotary Pozisyon Gömme (RoPE) için özel taban frekansı. Bunu artırmak yüksek bağlam uzunluklarında daha iyi performans sağlayabilir.",
  "embedding.load.llama.ropeFrequencyBase/info": "[Gelişmiş] Rotary Pozisyon Kodlaması için taban frekansını ayarlar, pozisyon bilgisi nasıl gömüldüğünü etkiler.",
  "embedding.load.llama.evalBatchSize/title": "Değerlendirme Parti Boyutu",
  "embedding.load.llama.evalBatchSize/subTitle": "Bir seferde işlenecek giriş token sayısı. Bunu artırmak performansı artırır ancak bellek kullanımını artırır.",
  "embedding.load.llama.evalBatchSize/info": "Değerlendirme sırasında bir partide birlikte işlenen token sayısını ayarlar.",
  "embedding.load.llama.ropeFrequencyScale/title": "RoPE Frekans Ölçeği",
  "embedding.load.llama.ropeFrequencyScale/subTitle": "Bağlam uzunluğu, RoPE kullanarak etkin bağlamı genişletmek için bu faktörle ölçeklenir.",
  "embedding.load.llama.ropeFrequencyScale/info": "[Gelişmiş] Rotary Pozisyon Kodlaması için frekans ölçeğini değiştirerek pozisyon kodlama inceliğini kontrol eder.",
  "embedding.load.llama.acceleration.offloadRatio/title": "GPU Yük Aktarma",
  "embedding.load.llama.acceleration.offloadRatio/subTitle": "GPU hızlandırma için hesaplanacak ayrık model katmanlarının sayısı",
  "embedding.load.llama.acceleration.offloadRatio/info": "GPU'ya aktarılacak katman sayısını ayarlayın.",
  "embedding.load.llama.keepModelInMemory/title": "Modeli Bellekte Tut",
  "embedding.load.llama.keepModelInMemory/subTitle": "Model GPU'ya aktarılsa bile sistem belleğini ayırır. Performansı artırır ancak daha fazla sistem RAM'i gerektirir.",
  "embedding.load.llama.keepModelInMemory/info": "Modelin diske taşınmasını önler, daha hızlı erişim sağlar ancak daha yüksek RAM kullanımı gerektirir.",
  "embedding.load.llama.tryMmap/title": "mmap() Deneyin",
  "embedding.load.llama.tryMmap/subTitle": "Modelin yükleme süresini iyileştirir. Bunu devre dışı bırakmak, model sistem RAM'inden büyük olduğunda performansı artırabilir.",
  "embedding.load.llama.tryMmap/info": "Model dosyalarını doğrudan diskten belleğe yükler.",
  "embedding.load.seed/title": "Tohum",
  "embedding.load.seed/subTitle": "Metin oluşturmada kullanılan rastgele sayı üretecinin tohum değeri. -1 rastgele tohum demektir.",
  "embedding.load.seed/info": "Rastgele Tohum: Tekrarlanabilir sonuçlar sağlamak için rastgele sayı üretimi için tohum değerini ayarlar.",

  "presetTooltip": {
    "included/title": "Ön Ayar Değerleri",
    "included/description": "Aşağıdaki alanlar uygulanacak",
    "included/empty": "Bu bağlamda ön ayarın hiçbir alanı uygulanamaz.",
    "included/conflict": "Bu değeri uygulayıp uygulamayacağınızı seçmeniz istenecek",
    "separateLoad/title": "Yükleme Zamanı Yapılandırması",
    "separateLoad/description.1": "Ön ayar ayrıca aşağıdaki yükleme zamanı yapılandırmasını içerir. Yükleme zamanı yapılandırmaları model genelinde geçerlidir ve etkili olması için modelin yeniden yüklenmesi gerekir. Tutun",
    "separateLoad/description.2": "uygulamak için",
    "separateLoad/description.3": ".",
    "excluded/title": "Uygulanmayabilir",
    "excluded/description": "Aşağıdaki alanlar ön ayarda yer alır ancak şu anki bağlamda uygulanamaz.",
    "legacy/title": "Eski Ön Ayar",
    "legacy/description": "Bu ön ayar eski bir ön ayardır. Şu anda otomatik olarak işlenen veya artık geçerli olmayan aşağıdaki alanları içerir."
  },
  "customInputs": {
    "string": {
      "emptyParagraph": "<Boş>"
    },
    "checkboxNumeric": {
      "off": "KAPALI"
    },
    "stringArray": {
      "empty": "<Boş>"
    },
    "llmPromptTemplate": {
      "type": "Tür",
      "types.jinja/label": "Şablon (Jinja)",
      "jinja.bosToken/label": "BOS Token",
      "jinja.eosToken/label": "EOS Token",
      "jinja.template/label": "Şablon",
      "jinja/error": "Jinja şablonu ayrıştırılamadı: {{error}}",
      "jinja/empty": "Lütfen yukarıya bir Jinja şablonu girin.",
      "jinja/unlikelyToWork": "Yukarıda sağladığınız Jinja şablonu \"messages\" değişkenine atıfta bulunmadığı için çalışmayabilir. Lütfen doğru bir şablon girdiğinizden emin olun.",
      "types.manual/label": "Manuel",
      "manual.subfield.beforeSystem/label": "Sistem Öncesi",
      "manual.subfield.beforeSystem/placeholder": "Sistem öneki girin...",
      "manual.subfield.afterSystem/label": "Sistem Sonrası",
      "manual.subfield.afterSystem/placeholder": "Sistem soneki girin...",
      "manual.subfield.beforeUser/label": "Kullanıcı Öncesi",
      "manual.subfield.beforeUser/placeholder": "Kullanıcı öneki girin...",
      "manual.subfield.afterUser/label": "Kullanıcı Sonrası",
      "manual.subfield.afterUser/placeholder": "Kullanıcı soneki girin...",
      "manual.subfield.beforeAssistant/label": "Asistan Öncesi",
      "manual.subfield.beforeAssistant/placeholder": "Asistan öneki girin...",
      "manual.subfield.afterAssistant/label": "Asistan Sonrası",
      "manual.subfield.afterAssistant/placeholder": "Asistan soneki girin...",
      "stopStrings/label": "Ek Durdurma Dizeleri",
      "stopStrings/subTitle": "Kullanıcı tanımlı durdurma dizelerine ek olarak kullanılacak şablon özel durdurma dizeleri."
    },
    "contextLength": {
      "maxValueTooltip": "Bu, modelin eğitildiği maksimum token sayısıdır. Bu değere ayarlamak için tıklayın",
      "maxValueTextStart": "Model en fazla",
      "maxValueTextEnd": "token destekler",
      "tooltipHint": "Bir model belirli bir token sayısına kadar desteklese de, makinenizin kaynakları yükü kaldırabilecek durumda değilse performans düşebilir - bu değeri artırırken dikkatli olun."
    },
    "contextOverflowPolicy": {
      "stopAtLimit": "Limite Ulaşınca Durdur",
      "stopAtLimitSub": "Modelin belleği dolduğunda oluşturmaya son ver",
      "truncateMiddle": "Ortadan Kısalt",
      "truncateMiddleSub": "Konuşmanın ortasındaki mesajları kaldırarak yeni mesajlar için yer açar. Model yine de konuşmanın başlangıcını hatırlayacaktır",
      "rollingWindow": "Kayan Pencere",
      "rollingWindowSub": "Model her zaman en son birkaç mesajı alır ancak konuşmanın başlangıcını unutabilir"
    },
    "llamaAccelerationOffloadRatio": {
      "max": "MAKS",
      "off": "KAPALI"
    }
  },
  "saveConflictResolution": {
    "title": "Ön Ayara Hangi Değerleri Dahil Etmek İstiyorsunuz?",
    "description": "Hangi değerleri tutmak istediğinizi seçin",
    "instructions": "Dahil etmek için bir değere tıklayın",
    "userValues": "Önceki Değer",
    "presetValues": "Yeni Değer",
    "confirm": "Onayla",
    "cancel": "İptal"
  },
  "applyConflictResolution": {
    "title": "Hangi değerleri tutmak istiyorsunuz?",
    "description": "Gelen Ön Ayar ile çakışan kaydedilmemiş değişiklikleriniz var",
    "instructions": "Tutmak istediğiniz değere tıklayın",
    "userValues": "Mevcut Değer",
    "presetValues": "Gelen Ön Ayar Değeri",
    "confirm": "Onayla",
    "cancel": "İptal"
  },
  "empty": "<Boş>",
  "presets": {
    "title": "Ön Ayar",
    "commitChanges": "Değişiklikleri Kaydet",
    "commitChanges/description": "Değişikliklerinizi ön ayara kaydedin.",
    "commitChanges.manual": "Yeni alanlar tespit edildi. Ön ayara hangi değişiklikleri dahil edeceğinizi seçebileceksiniz.",
    "commitChanges.manual.hold.0": "Tutun",
    "commitChanges.manual.hold.1": "ön ayara hangi değişiklikleri kaydedeceğinizi seçmek için.",
    "commitChanges.saveAll.hold.0": "Tutun",
    "commitChanges.saveAll.hold.1": "tüm değişiklikleri kaydetmek için.",
    "commitChanges.saveInPreset.hold.0": "Tutun",
    "commitChanges.saveInPreset.hold.1": "değişiklikleri yalnızca zaten ön ayarda yer alan alanlara kaydetmek için.",
    "commitChanges/error": "Değişiklikler ön ayara kaydedilemedi.",
    "commitChanges.manual/description": "Ön ayara hangi değişiklikleri dahil edeceğinizi seçin.",
    "saveAs": "Yeni Olarak Kaydet...",
    "presetNamePlaceholder": "Ön ayar için bir isim girin...",
    "cannotCommitChangesLegacy": "Bu bir eski ön ayar ve değiştirilemez. \"Yeni Olarak Kaydet...\" kullanarak bir kopya oluşturabilirsiniz.",
    "cannotCommitChangesNoChanges": "Kaydedilecek değişiklik yok.",
    "emptyNoUnsaved": "Bir Ön Ayar Seçin...",
    "emptyWithUnsaved": "Kaydedilmemiş Ön Ayar",
    "saveEmptyWithUnsaved": "Ön Ayarı Farklı Kaydet...",
    "saveConfirm": "Kaydet",
    "saveCancel": "İptal",
    "saving": "Kaydediliyor...",
    "save/error": "Ön ayar kaydedilemedi.",
    "deselect": "Ön Ayarı Bırak",
    "deselect/error": "Ön ayar bırakılamadı.",
    "select/error": "Ön ayar seçilemedi.",
    "delete/error": "Ön ayar silinemedi.",
    "discardChanges": "Kaydedilmemiş Değişiklikleri At",
    "discardChanges/info": "Tüm kaydedilmemiş değişiklikleri atın ve ön ayarı orijinal haline geri yükleyin",
    "newEmptyPreset": "Yeni boş ön ayar oluştur...",
    "contextMenuSelect": "Ön Ayar Seç",
    "contextMenuDelete": "Sil"
  },
 
 "flashAttentionWarning": "Flash Attention, bazı modellerle sorunlara neden olabilecek deneysel bir özelliktir. Sorun yaşarsanız, devre dışı bırakmayı deneyin.",
  "seedUncheckedHint": "Rastgele Tohum",
  "ropeFrequencyBaseUncheckedHint": "Otomatik",
  "ropeFrequencyScaleUncheckedHint": "Otomatik"
}
