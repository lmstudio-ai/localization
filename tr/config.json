{
  "noInstanceSelected": "Model örneği seçilmedi",
  "resetToDefault": "Varsayılana sıfırla",
  "showAdvancedSettings": "Gelişmiş ayarları göster",
  "showAll": "Hepsini göster",
  "basicSettings": "Temel",
  "configSubtitle": "Ön ayarları yükleyin veya kaydedin ve model parametre geçersiz kılmaları ile deney yapın",
  "inferenceParameters/title": "Tahmin Parametreleri",
  "inferenceParameters/info": "Tahmini etkileyen parametrelerle deney yapın.",
  "generalParameters/title": "Genel",
  "samplingParameters/title": "Örnekleme",
  "basicTab": "Temel",
  "advancedTab": "Gelişmiş",
  "loadInstanceFirst": "Yapılandırılabilir parametreleri görmek için bir model yükleyin",
  "generationParameters/info": "Metin üretimini etkileyen temel parametrelerle deney yapın.",
  "loadParameters/title": "Yükleme Parametreleri",
  "loadParameters/description": "Bu parametreleri değiştirmek modelin yeniden yüklenmesini gerektirir",
  "loadParameters/reload": "Yükleme parametre değişikliklerini uygulamak için yeniden yükle",
  "discardChanges": "Değişiklikleri at",
  "llm.prediction.systemPrompt/title": "AI için Yönergeler",
  "llm.prediction.systemPrompt/description": "Model için bir dizi kural, kısıtlama veya genel gereksinim gibi arka plan talimatları sağlamak için bu alanı kullanın. Bu alan genellikle \"sistem istemi\" olarak da adlandırılır.",
  "llm.prediction.temperature/title": "Sıcaklık",
  "llm.prediction.temperature/info": "llama.cpp yardım belgelerinden: \"Varsayılan değer <{{dynamicValue}}> olup, rastgelelik ve determinizm arasında bir denge sağlar. Aşırı durumda, 0 sıcaklığı her zaman en olası sonraki belirteci seçer ve her çalışmada aynı çıktılara yol açar\"",
  "llm.prediction.llama.topKSampling/title": "Top K Örnekleme",
  "llm.prediction.llama.topKSampling/info": "llama.cpp yardım belgelerinden:\n\nTop-k örnekleme, model tarafından tahmin edilen en olası k belirtecinden yalnızca bir sonraki belirteci seçen bir metin üretim yöntemidir.\n\nDüşük olasılıklı veya anlamsız belirteçler üretme riskini azaltır, ancak aynı zamanda çıktının çeşitliliğini de sınırlayabilir.\n\nDaha yüksek bir top-k değeri (örneğin, 100) daha fazla belirteci dikkate alır ve daha çeşitli metinlere yol açar, daha düşük bir değer (örneğin, 10) en olası belirteçlere odaklanır ve daha muhafazakar metinler üretir.\n\n• Varsayılan değer <{{dynamicValue}}>",
  "llm.prediction.llama.cpuThreads/title": "CPU İş Parçacıkları",
  "llm.prediction.llama.cpuThreads/info": "Hesaplama sırasında kullanılacak iş parçacığı sayısı. İş parçacığı sayısının artırılması her zaman daha iyi performansla ilişkilendirilmez. Varsayılan <{{dynamicValue}}>.",
  "llm.prediction.maxPredictedTokens/title": "Yanıt Uzunluğunu Sınırla",
  "llm.prediction.maxPredictedTokens/info": "Sohbet botunun yanıtının maksimum uzunluğunu kontrol edin. Bir yanıtın maksimum uzunluğuna bir sınır koymak için açın veya sohbet botunun ne zaman duracağına karar vermesine izin vermek için kapatın.",
  "llm.prediction.maxPredictedTokens/inputLabel": "Maksimum yanıt uzunluğu (belirteçler)",
  "llm.prediction.maxPredictedTokens/wordEstimate": "Yaklaşık {{maxWords}} kelime",
  "llm.prediction.llama.repeatPenalty/title": "Tekrar Cezası",
  "llm.prediction.llama.repeatPenalty/info": "llama.cpp yardım belgelerinden: \"Modelin tekrarlayan veya monoton metinler üretmesini önlemeye yardımcı olur.\n\nDaha yüksek bir değer (örneğin, 1.5) tekrarları daha güçlü bir şekilde cezalandırır, daha düşük bir değer (örneğin, 0.9) daha hoşgörülüdür.\" • Varsayılan değer <{{dynamicValue}}>",
  "llm.prediction.llama.minPSampling/title": "Min P Örnekleme",
  "llm.prediction.llama.minPSampling/info": "llama.cpp yardım belgelerinden:\n\nEn olası belirtecin olasılığına göre bir belirtecin dikkate alınması için minimum olasılık. [0, 1] aralığında olmalıdır.\n\n• Varsayılan değer <{{dynamicValue}}>",
  "llm.prediction.llama.topPSampling/title": "Top P Örnekleme",
  "llm.prediction.llama.topPSampling/info": "llama.cpp yardım belgelerinden:\n\nTop-p örnekleme, aynı zamanda çekirdek örnekleme olarak da bilinir, bir sonraki belirteci, birlikte en az p olasılığına sahip bir belirteç alt kümesinden seçen bir metin üretim yöntemidir.\n\nBu yöntem, belirteçlerin olasılıklarını ve örneklenecek belirteç sayısını dikkate alarak çeşitlilik ve kalite arasında bir denge sağlar.\n\nDaha yüksek bir top-p değeri (örneğin, 0.95) daha çeşitli metinlere yol açar, daha düşük bir değer (örneğin, 0.5) daha odaklanmış ve muhafazakar metinler üretir. (0, 1] aralığında olmalıdır.\n\n• Varsayılan değer <{{dynamicValue}}>",
  "llm.prediction.stopStrings/title": "Durdurma Dizeleri",
  "llm.prediction.stopStrings/info": "Karşılaşıldığında modelin daha fazla belirteç üretmesini durduracak belirli dizeler",
  "llm.prediction.stopStrings/placeholder": "Bir dize girin ve ⏎ tuşuna basın",
  "llm.prediction.contextOverflowPolicy/title": "Konuşma Taşması",
  "llm.prediction.contextOverflowPolicy/info": "Konuşma modelin çalışma belleğinin ('bağlam') boyutunu aştığında ne yapılacağını belirleyin",
  "llm.prediction.contextOverflowPolicy/stopAtLimit": "Sınırda Durdur",
  "llm.prediction.contextOverflowPolicy/stopAtLimitSub": "Modelin belleği dolduğunda üretimi durdur",
  "llm.prediction.contextOverflowPolicy/truncateMiddle": "Ortayı Kısalt",
  "llm.prediction.contextOverflowPolicy/truncateMiddleSub": "Yeni mesajlar için yer açmak için konuşmanın ortasındaki mesajları kaldırır. Model hala konuşmanın başlangıcını hatırlayacaktır",
  "llm.prediction.contextOverflowPolicy/rollingWindow": "Kaydırma Penceresi",
  "llm.prediction.contextOverflowPolicy/rollingWindowSub": "Model her zaman en son birkaç mesajı alacak, ancak konuşmanın başlangıcını unutabilir",
  "llm.prediction.llama.frequencyPenalty/title": "Frekans Cezası",
  "llm.prediction.llama.presencePenalty/title": "Varlık Cezası",
  "llm.prediction.llama.tailFreeSampling/title": "Kuyruksuz Örnekleme",
  "llm.prediction.llama.locallyTypicalSampling/title": "Yerel Tipik Örnekleme",
  "llm.prediction.mlx.repeatPenalty/title": "Tekrar Cezası",
  "llm.prediction.mlx.repeatPenalty/info": "Daha yüksek bir değer modelin kendini tekrar etmesini caydırır",
  "llm.prediction.seed/title": "Tohum",
  "llm.prediction.structured/title": "Yapılandırılmış Çıktı",
  "llm.prediction.structured/info": "Yapılandırılmış Çıktı",
  "llm.load.contextLength/title": "Bağlam Uzunluğu",
  "llm.load.contextLength/info": "Modelin işlem sırasında bir kerede dikkate alabileceği maksimum belirteç sayısını belirler, bu da modelin işlem sırasında ne kadar bağlamı koruduğunu etkiler",
  "llm.load.seed/title": "Tohum",
  "llm.load.seed/info": "Rastgele Tohum: Rastgele sayı üretimi için tohum ayarlar, tekrarlanabilir sonuçlar sağlar",
  "llm.load.llama.evalBatchSize/title": "Değerlendirme Yığın Boyutu",
  "llm.load.llama.evalBatchSize/info": "Değerlendirme sırasında bir yığın halinde işlenen örnek sayısını ayarlar, hız ve bellek kullanımını etkiler",
  "llm.load.llama.ropeFrequencyBase/title": "RoPE Frekans Temeli",
  "llm.load.llama.ropeFrequencyBase/info": "[Gelişmiş] Döner Konumsal Kodlama için temel frekansı ayarlar, konumsal bilginin nasıl gömüldüğünü etkiler",
  "llm.load.llama.ropeFrequencyScale/title": "RoPE Frekans Ölçeği",
  "llm.load.llama.ropeFrequencyScale/info": "[Gelişmiş] Döner Konumsal Kodlama frekansının ölçeklendirilmesini değiştirir, konumsal kodlama ayrıntılarını kontrol eder",
  "llm.load.llama.gpuOffload/title": "GPU Yükleme",
  "llm.load.llama.gpuOffload/info": "Hesaplamanın GPU'ya aktarılma oranını ayarlayın. GPU yüklemeyi devre dışı bırakmak için kapalı olarak ayarlayın veya modelin karar vermesine izin vermek için otomatik olarak ayarlayın.",
  "llm.load.llama.flashAttention/title": "Flash Dikkat",
  "llm.load.llama.flashAttention/info": "Dikkat mekanizmalarını hızlandırarak daha hızlı ve verimli işlem sağlar",
  "llm.load.llama.keepModelInMemory/title": "Modeli Bellekte Tut",
  "llm.load.llama.keepModelInMemory/info": "Modelin diske takas edilmesini önler, daha yüksek RAM kullanımı pahasına daha hızlı erişim sağlar",
  "llm.load.llama.useFp16ForKVCache/title": "KV Önbelleği İçin FP16 Kullan",
  "llm.load.llama.useFp16ForKVCache/info": "Önbelleği yarı hassasiyette (FP16) depolayarak bellek kullanımını azaltır",
  "llm.load.llama.tryMmap/title": "mmap() Deneyin",
  "llm.load.llama.tryMmap/info": "Model dosyalarını doğrudan diskten belleğe yükleyin"
}
