{
  "tabs/server": "Локальный сервер",
  "tabs/extensions": "LM RUNTIME",
  "loadSettings/title": "Настройки загрузки",
  "modelSettings/placeholder": "Выберите модель для настройки",

  "loadedModels/noModels": "Модели не загружены",
  
  "serverOptions/title": "Настройки сервера",
  "serverOptions/configurableTitle": "Настраиваемые параметры",
  "serverOptions/port/hint": "Установите сетевой порт, который будет использовать локальный сервер. По умолчанию LM Studio использует порт 1234. Возможно, вам придется изменить его, если порт уже занят.",
  "serverOptions/port/subtitle": "Порт для прослушивания",
  "serverOptions/autostart/title": "Автоматический запуск сервера",
  "serverOptions/autostart/hint": "Запускать локальный сервер автоматически при загрузке модели",
  "serverOptions/port/integerWarning": "Номер порта должен быть целым числом",
  "serverOptions/port/invalidPortWarning": "Порт должен быть в пределах от 1 до 65535",
  "serverOptions/cors/title": "Включить CORS",
  "serverOptions/cors/hint1": "Включение CORS (Cross-origin Resource Sharing) позволит веб-сайтам, которые вы посещаете, делать запросы к серверу LM Studio.",
  "serverOptions/cors/hint2": "CORS может быть необходим для запросов с веб-страниц или расширений, таких как VS Code.",
  "serverOptions/cors/subtitle": "Разрешить кросс-доменные запросы",
  "serverOptions/network/title": "Доступ по локальной сети",
  "serverOptions/network/subtitle": "Открыть сервер для устройств в сети",
  "serverOptions/network/hint1": "Разрешить подключения с других устройств в сети.",
  "serverOptions/network/hint2": "Если не отмечено, сервер будет слушать только на localhost.",
  "serverOptions/verboseLogging/title": "Подробное ведение журнала",
  "serverOptions/verboseLogging/subtitle": "Включить подробное ведение журнала для локального сервера",
  "serverOptions/contentLogging/title": "Ведение журнала запросов и ответов",
  "serverOptions/contentLogging/subtitle": "Настройки ведения журнала запросов / ответов",
  "serverOptions/contentLogging/hint": "Записывать ли запросы и/или ответы в файл журнала локального сервера.",
  "serverOptions/loadModel/error": "Не удалось загрузить модель",
  
  "serverLogs/scrollToBottom": "Перейти к концу",
  "serverLogs/clearLogs": "Очистить журналы ({{shortcut}})",
  "serverLogs/openLogsFolder": "Открыть папку с журналами сервера",

  "runtimeSettings/title": "Настройки выполнения",
  "runtimeSettings/chooseRuntime/title": "Настроить Runtimes",
  "runtimeSettings/chooseRuntime/description": "Выберите выполнение для каждого формата модели",
  "runtimeSettings/chooseRuntime/showAllVersions/label": "Показать все версии",
  "runtimeSettings/chooseRuntime/showAllVersions/hint": "По умолчанию LM Studio показывает только последнюю версию каждого runtime. Включите эту опцию, чтобы увидеть все доступные версии.",
  "runtimeSettings/chooseRuntime/select/placeholder": "Выберите Runtime",

  "runtimeOptions/uninstall": "Удалить",
  "runtimeOptions/uninstallDialog/title": "Удалить {{runtimeName}}?",
  "runtimeOptions/uninstallDialog/body": "Удаление этого runtime удалит его из системы. Это действие необратимо.",
  "runtimeOptions/uninstallDialog/body/caveats": "Некоторые файлы могут быть удалены только после перезапуска LM Studio.",
  "runtimeOptions/uninstallDialog/error": "Не удалось удалить runtime",
  "runtimeOptions/uninstallDialog/confirm": "Продолжить и удалить",
  "runtimeOptions/uninstallDialog/cancel": "Отмена",

  "inferenceParams/noParams": "Нет настраиваемых параметров вывода для этого типа модели",

  "endpoints/openaiCompatRest/title": "Поддерживаемые конечные точки (похожие на OpenAI)",
  "endpoints/openaiCompatRest/getModels": "Список текущих загруженных моделей",
  "endpoints/openaiCompatRest/postCompletions": "Режим завершений текста. Предсказать следующие токены, исходя из запроса. Примечание: OpenAI считает эту конечную точку 'устаревшей'.",
  "endpoints/openaiCompatRest/postChatCompletions": "Завершения чата. Отправить историю чата модели для предсказания следующего ответа ассистента",
  "endpoints/openaiCompatRest/postEmbeddings": "Встраивание текста. Генерировать встраивания текста для данного текстового ввода. Принимает строку или массив строк.",

  "model.createVirtualModelFromInstance": "Сохранить настройки как новую виртуальную модель",
  "model.createVirtualModelFromInstance/error": "Не удалось сохранить настройки как новую виртуальную модель",

  "apiConfigOptions/title": "Конфигурация API"
}
