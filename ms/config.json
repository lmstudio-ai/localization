{
  "noInstanceSelected": "Tiada contoh model dipilih",
  "resetToDefault": "Set semula",
  "showAdvancedSettings": "Tunjukkan tetapan lanjutan",
  "showAll": "Semua",
  "basicSettings": "Asas",
  "configSubtitle": "Muat atau simpan prasetel dan eksperimen dengan penggantian parameter model",
  "inferenceParameters/title": "Parameter Ramalan",
  "inferenceParameters/info": "Eksperimen dengan parameter yang mempengaruhi ramalan.",
  "generalParameters/title": "Umum",
  "samplingParameters/title": "Pensampelan",
  "basicTab": "Asas",
  "advancedTab": "Lanjutan",
  "advancedTab/title": "üß™ Konfigurasi Lanjutan",
  "advancedTab/expandAll": "Kembangkan semua",
  "advancedTab/overridesTitle": "Penggantian Konfigurasi",
  "advancedTab/noConfigsText": "Anda tiada perubahan yang belum disimpan - edit nilai di atas untuk melihat penggantian di sini.",
  "loadInstanceFirst": "Muat model untuk melihat parameter yang boleh dikonfigurasi",
  "noListedConfigs": "Tiada parameter yang boleh dikonfigurasi",
  "generationParameters/info": "Eksperimen dengan parameter asas yang mempengaruhi penjanaan teks.",
  "loadParameters/title": "Parameter Muat",
  "loadParameters/description": "Tetapan untuk mengawal cara model dimulakan dan dimuatkan ke dalam memori.",
  "loadParameters/reload": "Muat semula untuk menerapkan perubahan",
  "discardChanges": "Buang perubahan",
  "loadModelToSeeOptions": "Muat model untuk melihat pilihan",
  "llm.prediction.systemPrompt/title": "Prompt Sistem",
  "llm.prediction.systemPrompt/description": "Gunakan medan ini untuk memberikan arahan latar belakang kepada model, seperti set peraturan, kekangan, atau keperluan umum.",
  "llm.prediction.systemPrompt/subTitle": "Garis panduan untuk AI",
  "llm.prediction.temperature/title": "Suhu",
  "llm.prediction.temperature/subTitle": "Berapa banyak rawak yang diperkenalkan. 0 akan menghasilkan hasil yang sama setiap kali, manakala nilai yang lebih tinggi akan meningkatkan kreativiti dan varians",
  "llm.prediction.temperature/info": "Daripada dokumen bantuan llama.cpp: \"Nilai lalai ialah <{{dynamicValue}}>, yang memberikan keseimbangan antara rawak dan determinisme. Pada tahap ekstrem, suhu 0 akan selalu memilih token seterusnya yang paling mungkin, menghasilkan output yang sama dalam setiap larian\"",
  "llm.prediction.llama.sampling/title": "Pensampelan",
  "llm.prediction.topKSampling/title": "Pensampelan Top K",
  "llm.prediction.topKSampling/subTitle": "Menghadkan token seterusnya kepada salah satu token k paling mungkin. Bertindak serupa dengan suhu",
  "llm.prediction.topKSampling/info": "Daripada dokumen bantuan llama.cpp:\n\nPensampelan top-k ialah kaedah penjanaan teks yang memilih token seterusnya hanya daripada token k paling mungkin yang diramalkan oleh model.\n\nIa membantu mengurangkan risiko menjana token yang tidak mungkin atau tidak masuk akal, tetapi ia juga mungkin menghadkan kepelbagaian output.\n\nNilai yang lebih tinggi untuk top-k (contohnya, 100) akan mempertimbangkan lebih banyak token dan menghasilkan teks yang lebih pelbagai, manakala nilai yang lebih rendah (contohnya, 10) akan menumpukan pada token yang paling mungkin dan menjana teks yang lebih konservatif.\n\n‚Ä¢ Nilai lalai ialah <{{dynamicValue}}>",
  "llm.prediction.llama.cpuThreads/title": "Benang CPU",
  "llm.prediction.llama.cpuThreads/subTitle": "Bilangan benang CPU yang digunakan semasa inferens",
  "llm.prediction.llama.cpuThreads/info": "Bilangan benang yang digunakan semasa pengiraan. Meningkatkan bilangan benang tidak selalu berkorelasi dengan prestasi yang lebih baik. Lalai ialah <{{dynamicValue}}>.",
  "llm.prediction.maxPredictedTokens/title": "Hadkan Panjang Respons",
  "llm.prediction.maxPredictedTokens/subTitle": "Secara pilihan mengehadkan panjang respons AI",
  "llm.prediction.maxPredictedTokens/info": "Kawal panjang maksimum respons chatbot. Hidupkan untuk menetapkan had pada panjang maksimum respons, atau matikan untuk membiarkan chatbot memutuskan bila hendak berhenti.",
  "llm.prediction.maxPredictedTokens/inputLabel": "Panjang respons maksimum (token)",
  "llm.prediction.maxPredictedTokens/wordEstimate": "Kira-kira {{maxWords}} perkataan",
  "llm.prediction.repeatPenalty/title": "Penalti Ulangan",
  "llm.prediction.repeatPenalty/subTitle": "Berapa banyak untuk menggalakkan pengulangan token yang sama",
  "llm.prediction.repeatPenalty/info": "Daripada dokumen bantuan llama.cpp: \"Membantu mengelakkan model daripada menjana teks yang berulang atau monoton.\n\nNilai yang lebih tinggi (contohnya, 1.5) akan mengenakan penalti yang lebih kuat terhadap pengulangan, manakala nilai yang lebih rendah (contohnya, 0.9) akan lebih bertolak ansur.\" ‚Ä¢ Nilai lalai ialah <{{dynamicValue}}>",
  "llm.prediction.minPSampling/title": "Pensampelan Min P",
  "llm.prediction.minPSampling/subTitle": "Kebarangkalian asas minimum untuk token dipilih untuk output",
  "llm.prediction.minPSampling/info": "Daripada dokumen bantuan llama.cpp:\n\nKebarangkalian minimum untuk token dipertimbangkan, relatif kepada kebarangkalian token yang paling mungkin. Mesti dalam [0, 1].\n\n‚Ä¢ Nilai lalai ialah <{{dynamicValue}}>",
  "llm.prediction.topPSampling/title": "Pensampelan Top P",
  "llm.prediction.topPSampling/subTitle": "Kebarangkalian kumulatif minimum untuk token seterusnya yang mungkin. Bertindak serupa dengan suhu",
  "llm.prediction.topPSampling/info": "Daripada dokumen bantuan llama.cpp:\n\nPensampelan top-p, juga dikenali sebagai pensampelan nukleus, ialah kaedah penjanaan teks lain yang memilih token seterusnya daripada subset token yang bersama-sama mempunyai kebarangkalian kumulatif sekurang-kurangnya p.\n\nKaedah ini memberikan keseimbangan antara kepelbagaian dan kualiti dengan mempertimbangkan kedua-dua kebarangkalian token dan bilangan token yang akan disampel.\n\nNilai yang lebih tinggi untuk top-p (contohnya, 0.95) akan menghasilkan teks yang lebih pelbagai, manakala nilai yang lebih rendah (contohnya, 0.5) akan menjana teks yang lebih fokus dan konservatif. Mesti dalam (0, 1].\n\n‚Ä¢ Nilai lalai ialah <{{dynamicValue}}>",
  "llm.prediction.stopStrings/title": "Hentikan Rentetan",
  "llm.prediction.stopStrings/subTitle": "Rentetan yang sepatutnya menghentikan model daripada menjana lebih banyak token",
  "llm.prediction.stopStrings/info": "Rentetan khusus yang apabila ditemui akan menghentikan model daripada menjana lebih banyak token",
  "llm.prediction.stopStrings/placeholder": "Masukkan rentetan dan tekan ‚èé",
  "llm.prediction.contextOverflowPolicy/title": "Limpahan Konteks",
  "llm.prediction.contextOverflowPolicy/subTitle": "Bagaimana model sepatutnya berkelakuan apabila perbualan menjadi terlalu besar untuk diuruskan",
  "llm.prediction.contextOverflowPolicy/info": "Tentukan apa yang perlu dilakukan apabila perbualan melebihi saiz memori kerja model ('konteks')",
  "llm.prediction.llama.frequencyPenalty/title": "Penalti Kekerapan",
  "llm.prediction.llama.presencePenalty/title": "Penalti Kehadiran",
  "llm.prediction.llama.tailFreeSampling/title": "Pensampelan Bebas Ekor",
  "llm.prediction.llama.locallyTypicalSampling/title": "Pensampelan Tempatan Biasa",
  "llm.prediction.onnx.topKSampling/title": "Pensampelan Top K",
  "llm.prediction.onnx.topKSampling/subTitle": "Menghadkan token seterusnya kepada salah satu token k paling mungkin. Bertindak serupa dengan suhu",
  "llm.prediction.onnx.topKSampling/info": "Daripada dokumentasi ONNX:\n\nBilangan token perbendaharaan kata dengan kebarangkalian tertinggi untuk disimpan untuk penapisan top-k\n\n‚Ä¢ Penapis ini dimatikan secara lalai",
  "llm.prediction.onnx.repeatPenalty/title": "Penalti Ulangan",
  "llm.prediction.onnx.repeatPenalty/subTitle": "Berapa banyak untuk menggalakkan pengulangan token yang sama",
  "llm.prediction.onnx.repeatPenalty/info": "Nilai yang lebih tinggi menggalakkan model daripada mengulangi dirinya sendiri",
  "llm.prediction.onnx.topPSampling/title": "Pensampelan Top P",
  "llm.prediction.onnx.topPSampling/subTitle": "Kebarangkalian kumulatif minimum untuk token seterusnya yang mungkin. Bertindak serupa dengan suhu",
  "llm.prediction.onnx.topPSampling/info": "Daripada dokumentasi ONNX:\n\nHanya token yang paling mungkin dengan kebarangkalian yang menambah sehingga TopP atau lebih tinggi disimpan untuk penjanaan\n\n‚Ä¢ Penapis ini dimatikan secara lalai",
  "llm.prediction.seed/title": "Benih",
  "llm.prediction.structured/title": "Output Berstruktur",
  "llm.prediction.structured/info": "Output Berstruktur",
  "llm.prediction.structured/description": "Lanjutan: anda boleh menyediakan Skema JSON untuk menguatkuasakan format output tertentu daripada model. Baca [dokumentasi](https://lmstudio.ai/docs/advanced/structured-output) untuk mengetahui lebih lanjut",
  "llm.prediction.promptTemplate/title": "Templat Prompt",
  "llm.prediction.promptTemplate/subTitle": "Format di mana mesej dalam sembang dihantar kepada model. Menukar ini mungkin memperkenalkan tingkah laku yang tidak dijangka - pastikan anda tahu apa yang anda lakukan!",

  "llm.load.contextLength/title": "Panjang Konteks",
  "llm.load.contextLength/subTitle": "Bilangan maksimum token yang boleh dihadiri oleh model dalam satu prompt. Lihat pilihan Limpahan Perbualan di bawah \"Parameter Inferens\" untuk lebih banyak cara untuk mengurus ini",
  "llm.load.contextLength/info": "Menentukan bilangan maksimum token yang boleh dipertimbangkan oleh model pada satu masa, mempengaruhi berapa banyak konteks yang dikekalkan semasa pemprosesan",
  "llm.load.contextLength/warning": "Menetapkan nilai yang tinggi untuk panjang konteks boleh memberi kesan yang ketara terhadap penggunaan memori",
  "llm.load.seed/title": "Benih",
  "llm.load.seed/subTitle": "Benih untuk penjana nombor rawak yang digunakan dalam penjanaan teks. -1 ialah benih rawak",
  "llm.load.seed/info": "Benih Rawak: Menetapkan benih untuk penjanaan nombor rawak untuk memastikan hasil yang boleh dihasilkan semula",

  "llm.load.llama.evalBatchSize/title": "Saiz Batch Penilaian",
  "llm.load.llama.evalBatchSize/subTitle": "Bilangan token input yang diproses pada satu masa. Meningkatkan ini meningkatkan prestasi pada kos penggunaan memori",
  "llm.load.llama.evalBatchSize/info": "Menetapkan bilangan contoh yang diproses bersama dalam satu kumpulan semasa penilaian, mempengaruhi kelajuan dan penggunaan memori",
  "llm.load.llama.ropeFrequencyBase/title": "Asas Frekuensi RoPE",
  "llm.load.llama.ropeFrequencyBase/subTitle": "Asas frekuensi tersuai untuk penyematan posisi putar (RoPE). Meningkatkan ini mungkin membolehkan prestasi yang lebih baik pada panjang konteks yang tinggi",
  "llm.load.llama.ropeFrequencyBase/info": "[Lanjutan] Melaraskan frekuensi asas untuk Penyematan Posisi Putar, mempengaruhi cara maklumat posisi disemati",
  "llm.load.llama.ropeFrequencyScale/title": "Skala Frekuensi RoPE",
  "llm.load.llama.ropeFrequencyScale/subTitle": "Panjang konteks dilesenkan oleh faktor ini untuk melanjutkan konteks berkesan menggunakan RoPE",
  "llm.load.llama.ropeFrequencyScale/info": "[Lanjutan] Mengubah suai penskalaan frekuensi untuk Penyematan Posisi Putar untuk mengawal kehalusan penyematan posisi",
  "llm.load.llama.acceleration.offloadRatio/title": "Offload GPU",
  "llm.load.llama.acceleration.offloadRatio/subTitle": "Bilangan lapisan model diskret untuk dikira pada GPU untuk pecutan GPU",
  "llm.load.llama.acceleration.offloadRatio/info": "Tetapkan bilangan lapisan untuk offload ke GPU.",
  "llm.load.llama.flashAttention/title": "Perhatian Kilat",
  "llm.load.llama.flashAttention/subTitle": "Mengurangkan penggunaan memori dan masa penjanaan pada beberapa model",
  "llm.load.llama.flashAttention/info": "Mempercepatkan mekanisme perhatian untuk pemprosesan yang lebih pantas dan cekap",
  "llm.load.numExperts/title": "Bilangan Pakar",
  "llm.load.numExperts/subTitle": "Bilangan pakar yang digunakan dalam model",
  "llm.load.numExperts/info": "Bilangan pakar yang digunakan dalam model",
  "llm.load.llama.keepModelInMemory/title": "Simpan Model dalam Memori",
  "llm.load.llama.keepModelInMemory/subTitle": "Simpan memori sistem untuk model, walaupun di-offload ke GPU. Meningkatkan prestasi tetapi memerlukan lebih banyak RAM sistem",
  "llm.load.llama.keepModelInMemory/info": "Mengelakkan model daripada ditukar ke cakera, memastikan akses yang lebih pantas pada kos penggunaan RAM yang lebih tinggi",
  "llm.load.llama.useFp16ForKVCache/title": "Gunakan FP16 Untuk KV Cache",
  "llm.load.llama.useFp16ForKVCache/info": "Mengurangkan penggunaan memori dengan menyimpan cache dalam separuh ketepatan (FP16)",
  "llm.load.llama.tryMmap/title": "Cuba mmap()",
  "llm.load.llama.tryMmap/subTitle": "Meningkatkan masa muat untuk model. Melumpuhkan ini mungkin meningkatkan prestasi apabila model lebih besar daripada RAM sistem yang tersedia",
  "llm.load.llama.tryMmap/info": "Muat fail model terus dari cakera ke memori",

  "embedding.load.contextLength/title": "Panjang Konteks",
  "embedding.load.contextLength/subTitle": "Bilangan maksimum token yang boleh dihadiri oleh model dalam satu prompt. Lihat pilihan Limpahan Perbualan di bawah \"Parameter Inferens\" untuk lebih banyak cara untuk mengurus ini",
  "embedding.load.contextLength/info": "Menentukan bilangan maksimum token yang boleh dipertimbangkan oleh model pada satu masa, mempengaruhi berapa banyak konteks yang dikekalkan semasa pemprosesan",
  "embedding.load.llama.ropeFrequencyBase/title": "Asas Frekuensi RoPE",
  "embedding.load.llama.ropeFrequencyBase/subTitle": "Asas frekuensi tersuai untuk penyematan posisi putar (RoPE). Meningkatkan ini mungkin membolehkan prestasi yang lebih baik pada panjang konteks yang tinggi",
  "embedding.load.llama.ropeFrequencyBase/info": "[Lanjutan] Melaraskan frekuensi asas untuk Penyematan Posisi Putar, mempengaruhi cara maklumat posisi disemati",
  "embedding.load.llama.evalBatchSize/title": "Saiz Batch Penilaian",
  "embedding.load.llama.evalBatchSize/subTitle": "Bilangan token input yang diproses pada satu masa. Meningkatkan ini meningkatkan prestasi pada kos penggunaan memori",
  "embedding.load.llama.evalBatchSize/info": "Menetapkan bilangan token yang diproses bersama dalam satu kumpulan semasa penilaian",
  "embedding.load.llama.ropeFrequencyScale/title": "Skala Frekuensi RoPE",
  "embedding.load.llama.ropeFrequencyScale/subTitle": "Panjang konteks dilesenkan oleh faktor ini untuk melanjutkan konteks berkesan menggunakan RoPE",
  "embedding.load.llama.ropeFrequencyScale/info": "[Lanjutan] Mengubah suai penskalaan frekuensi untuk Penyematan Posisi Putar untuk mengawal kehalusan penyematan posisi",
  "embedding.load.llama.acceleration.offloadRatio/title": "Offload GPU",
  "embedding.load.llama.acceleration.offloadRatio/subTitle": "Bilangan lapisan model diskret untuk dikira pada GPU untuk pecutan GPU",
  "embedding.load.llama.acceleration.offloadRatio/info": "Tetapkan bilangan lapisan untuk offload ke GPU.",
  "embedding.load.llama.keepModelInMemory/title": "Simpan Model dalam Memori",
  "embedding.load.llama.keepModelInMemory/subTitle": "Simpan memori sistem untuk model, walaupun di-offload ke GPU. Meningkatkan prestasi tetapi memerlukan lebih banyak RAM sistem",
  "embedding.load.llama.keepModelInMemory/info": "Mengelakkan model daripada ditukar ke cakera, memastikan akses yang lebih pantas pada kos penggunaan RAM yang lebih tinggi",
  "embedding.load.llama.tryMmap/title": "Cuba mmap()",
  "embedding.load.llama.tryMmap/subTitle": "Meningkatkan masa muat untuk model. Melumpuhkan ini mungkin meningkatkan prestasi apabila model lebih besar daripada RAM sistem yang tersedia",
  "embedding.load.llama.tryMmap/info": "Muat fail model terus dari cakera ke memori",
  "embedding.load.seed/title": "Benih",
  "embedding.load.seed/subTitle": "Benih untuk penjana nombor rawak yang digunakan dalam penjanaan teks. -1 ialah benih rawak",

  "embedding.load.seed/info": "Benih Rawak: Menetapkan benih untuk penjanaan nombor rawak untuk memastikan hasil yang boleh dihasilkan semula",

  "presetTooltip": {
    "included/title": "Nilai Prasetel",
    "included/description": "Medan berikut akan diterapkan",
    "included/empty": "Tiada medan prasetel ini yang terpakai dalam konteks ini.",
    "included/conflict": "Anda akan diminta untuk memilih sama ada untuk menerapkan nilai ini",
    "separateLoad/title": "Konfigurasi Masa Muat",
    "separateLoad/description.1": "Prasetel juga termasuk konfigurasi masa muat berikut. Konfigurasi masa muat adalah untuk seluruh model dan memerlukan memuat semula model untuk berkuat kuasa. Tahan",
    "separateLoad/description.2": "untuk menerapkan ke",
    "separateLoad/description.3": ".",
    "excluded/title": "Mungkin tidak terpakai",
    "excluded/description": "Medan berikut termasuk dalam prasetel tetapi tidak terpakai dalam konteks semasa.",
    "legacy/title": "Prasetel Warisan",
    "legacy/description": "Prasetel ini ialah prasetel warisan. Ia termasuk medan berikut yang sama ada dikendalikan secara automatik sekarang, atau tidak lagi terpakai."
  },

  "customInputs": {
    "string": {
      "emptyParagraph": "<Kosong>"
    },
    "checkboxNumeric": {
      "off": "MATI"
    },
    "stringArray": {
      "empty": "<Kosong>"
    },
    "llmPromptTemplate": {
      "type": "Jenis",
      "types.jinja/label": "Templat (Jinja)",
      "jinja.bosToken/label": "Token BOS",
      "jinja.eosToken/label": "Token EOS",
      "jinja.template/label": "Templat",
      "jinja/error": "Gagal menghurai templat Jinja: {{error}}",
      "jinja/empty": "Sila masukkan templat Jinja di atas.",
      "jinja/unlikelyToWork": "Templat Jinja yang anda berikan di atas tidak mungkin berfungsi kerana ia tidak merujuk pembolehubah \"messages\". Sila semak semula jika anda telah memasukkan templat yang betul.",
      "types.manual/label": "Manual",
      "manual.subfield.beforeSystem/label": "Sebelum Sistem",
      "manual.subfield.beforeSystem/placeholder": "Masukkan awalan Sistem...",
      "manual.subfield.afterSystem/label": "Selepas Sistem",
      "manual.subfield.afterSystem/placeholder": "Masukkan akhiran Sistem...",
      "manual.subfield.beforeUser/label": "Sebelum Pengguna",
      "manual.subfield.beforeUser/placeholder": "Masukkan awalan Pengguna...",
      "manual.subfield.afterUser/label": "Selepas Pengguna",
      "manual.subfield.afterUser/placeholder": "Masukkan akhiran Pengguna...",
      "manual.subfield.beforeAssistant/label": "Sebelum Pembantu",
      "manual.subfield.beforeAssistant/placeholder": "Masukkan awalan Pembantu...",
      "manual.subfield.afterAssistant/label": "Selepas Pembantu",
      "manual.subfield.afterAssistant/placeholder": "Masukkan akhiran Pembantu...",
      "stopStrings/label": "Rentetan Henti Tambahan",
      "stopStrings/subTitle": "Rentetan henti khusus templat yang akan digunakan selain rentetan henti yang ditentukan oleh pengguna."
    },
    "contextLength": {
      "maxValueTooltip": "Ini ialah bilangan maksimum token yang model dilatih untuk mengendalikan. Klik untuk menetapkan konteks kepada nilai ini",
      "maxValueTextStart": "Model menyokong sehingga",
      "maxValueTextEnd": "token",
      "tooltipHint": "Walaupun model mungkin menyokong sehingga bilangan token tertentu, prestasi mungkin merosot jika sumber mesin anda tidak dapat mengendalikan beban - berhati-hati apabila meningkatkan nilai ini"
    },
    "contextOverflowPolicy": {
      "stopAtLimit": "Berhenti pada Had",
      "stopAtLimitSub": "Berhenti menjana sebaik sahaja memori model penuh",
      "truncateMiddle": "Potong Tengah",
      "truncateMiddleSub": "Mengeluarkan mesej dari tengah perbualan untuk memberi ruang kepada yang lebih baru. Model masih akan ingat permulaan perbualan",
      "rollingWindow": "Tetingkap Bergulir",
      "rollingWindowSub": "Model akan sentiasa mendapat beberapa mesej terkini tetapi mungkin lupa permulaan perbualan"
    },
    "llamaAccelerationOffloadRatio": {
      "max": "MAKS",
      "off": "MATI"
    }
  },
  "saveConflictResolution": {
    "title": "Pilih nilai yang hendak dimasukkan dalam Prasetel",
    "description": "Pilih dan pilih nilai yang hendak disimpan",
    "instructions": "Klik pada nilai untuk memasukkannya",
    "userValues": "Nilai Sebelumnya",
    "presetValues": "Nilai Baru",
    "confirm": "Sahkan",
    "cancel": "Batal"
  },
  "applyConflictResolution": {
    "title": "Nilai mana yang hendak disimpan?",
    "description": "Anda mempunyai perubahan yang belum disimpan yang bertindih dengan Prasetel yang masuk",
    "instructions": "Klik pada nilai untuk menyimpannya",
    "userValues": "Nilai Semasa",
    "presetValues": "Nilai Prasetel Masuk",
    "confirm": "Sahkan",
    "cancel": "Batal"
  },
  "empty": "<Kosong>",
  "presets": {
    "title": "Prasetel",
    "commitChanges": "Komit Perubahan",
    "commitChanges/description": "Komit perubahan anda kepada prasetel.",
    "commitChanges.manual": "Medan baru dikesan. Anda akan dapat memilih perubahan yang hendak dimasukkan dalam prasetel.",
    "commitChanges.manual.hold.0": "Tahan",
    "commitChanges.manual.hold.1": "untuk memilih perubahan yang hendak dikomit ke prasetel.",
    "commitChanges.saveAll.hold.0": "Tahan",
    "commitChanges.saveAll.hold.1": "untuk menyimpan semua perubahan.",
    "commitChanges.saveInPreset.hold.0": "Tahan",
    "commitChanges.saveInPreset.hold.1": "untuk hanya menyimpan perubahan pada medan yang sudah termasuk dalam prasetel.",
    "commitChanges/error": "Gagal mengkomit perubahan kepada prasetel.",
    "commitChanges.manual/description": "Pilih perubahan yang hendak dimasukkan dalam prasetel.",
    "saveAs": "Simpan Sebagai Baru...",
    "presetNamePlaceholder": "Masukkan nama untuk prasetel...",
    "cannotCommitChangesLegacy": "Ini ialah prasetel warisan dan tidak boleh diubah suai. Anda boleh mencipta salinan dengan menggunakan \"Simpan Sebagai Baru...\".",
    "cannotCommitChangesNoChanges": "Tiada perubahan untuk dikomit.",
    "emptyNoUnsaved": "Pilih Prasetel...",
    "emptyWithUnsaved": "Prasetel Belum Disimpan",
    "saveEmptyWithUnsaved": "Simpan Prasetel Sebagai...",
    "saveConfirm": "Simpan",
    "saveCancel": "Batal",
    "saving": "Menyimpan...",
    "save/error": "Gagal menyimpan prasetel.",
    "deselect": "Nyahpilih Prasetel",
    "deselect/error": "Gagal nyahpilih prasetel.",
    "select/error": "Gagal memilih prasetel.",
    "delete/error": "Gagal memadam prasetel.",
    "discardChanges": "Buang Perubahan Belum Disimpan",
    "discardChanges/info": "Buang semua perubahan yang belum dikomit dan pulihkan prasetel kepada keadaan asalnya",
    "newEmptyPreset": "Cipta prasetel kosong baru...",
    "contextMenuSelect": "Pilih Prasetel",
    "contextMenuDelete": "Padam"
  },

  "flashAttentionWarning": "Perhatian Kilat ialah ciri eksperimen yang mungkin menyebabkan masalah dengan beberapa model. Jika anda menghadapi masalah, cuba lumpuhkannya.",

  "seedUncheckedHint": "Benih Rawak",
  "ropeFrequencyBaseUncheckedHint": "Auto",
  "ropeFrequencyScaleUncheckedHint": "Auto"
}
