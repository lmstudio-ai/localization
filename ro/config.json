{
  "noInstanceSelected": "Nicio instanÈ›Äƒ de model selectatÄƒ",
  "resetToDefault": "Resetare",
  "showAdvancedSettings": "AratÄƒ setÄƒrile avansate",
  "showAll": "Toate",
  "basicSettings": "De bazÄƒ",
  "configSubtitle": "ÃncÄƒrcaÈ›i sau salvaÈ›i presetÄƒrile È™i experimentaÈ›i cu suprascrieri de parametri de model",
  "inferenceParameters/title": "Parametri de predicÈ›ie",
  "inferenceParameters/info": "ExperimentaÈ›i cu parametrii care influenÈ›eazÄƒ predicÈ›ia.",
  "generalParameters/title": "General",
  "samplingParameters/title": "EÈ™antionare",
  "basicTab": "De bazÄƒ",
  "advancedTab": "Avansat",
  "advancedTab/title": "ğŸ§ª Configurare avansatÄƒ",
  "advancedTab/expandAll": "Extinde tot",
  "advancedTab/overridesTitle": "Suprascrieri de configurare",
  "advancedTab/noConfigsText": "Nu aveÈ›i modificÄƒri nesalvate - editaÈ›i valorile de mai sus pentru a vedea suprascrierile aici.",
  "loadInstanceFirst": "ÃncÄƒrcaÈ›i un model pentru a vizualiza parametrii configurabili",
  "noListedConfigs": "Niciun parametru configurabil",
  "generationParameters/info": "ExperimentaÈ›i cu parametrii de bazÄƒ care influenÈ›eazÄƒ generarea textului.",
  "loadParameters/title": "Parametri de Ã®ncÄƒrcare",
  "loadParameters/description": "SetÄƒri pentru a controla modul Ã®n care modelul este iniÈ›ializat È™i Ã®ncÄƒrcat Ã®n memorie.",
  "loadParameters/reload": "ReÃ®ncÄƒrcaÈ›i pentru a aplica modificÄƒrile",
  "discardChanges": "RenunÈ›Äƒ la modificÄƒri",
  "loadModelToSeeOptions": "ÃncÄƒrcaÈ›i un model pentru a vedea opÈ›iunile",
  "llm.prediction.systemPrompt/title": "Prompt de sistem",
  "llm.prediction.systemPrompt/description": "UtilizaÈ›i acest cÃ¢mp pentru a furniza instrucÈ›iuni de fundal modelului, cum ar fi un set de reguli, constrÃ¢ngeri sau cerinÈ›e generale.",
  "llm.prediction.systemPrompt/subTitle": "Ghid pentru AI",
  "llm.prediction.temperature/title": "TemperaturÄƒ",
  "llm.prediction.temperature/subTitle": "CÃ¢t de multÄƒ aleatorietate sÄƒ se introducÄƒ. 0 va da acelaÈ™i rezultat de fiecare datÄƒ, Ã®n timp ce valori mai mari vor creÈ™te creativitatea È™i variaÈ›ia",
  "llm.prediction.temperature/info": "Din documentaÈ›ia de ajutor a llama.cpp: \"Valoarea implicitÄƒ este <{{dynamicValue}}>, care oferÄƒ un echilibru Ã®ntre aleatorietate È™i determinism. Ãn extreme, o temperaturÄƒ de 0 va alege Ã®ntotdeauna urmÄƒtorul token cel mai probabil, conducÃ¢nd la ieÈ™iri identice la fiecare rulare\"",
  "llm.prediction.llama.sampling/title": "EÈ™antionare",
  "llm.prediction.topKSampling/title": "EÈ™antionare Top K",
  "llm.prediction.topKSampling/subTitle": "LimiteazÄƒ urmÄƒtorul token la unul dintre cei top-k tokeni cei mai probabili. FuncÈ›ioneazÄƒ similar cu temperatura",
  "llm.prediction.topKSampling/info": "Din documentaÈ›ia de ajutor a llama.cpp:\n\nEÈ™antionarea top-k este o metodÄƒ de generare a textului care selecteazÄƒ urmÄƒtorul token doar dintre cei k tokeni cei mai probabili prezis de model.\n\nAjutÄƒ la reducerea riscului de a genera tokeni cu probabilitate scÄƒzutÄƒ sau fÄƒrÄƒ sens, dar poate limita È™i diversitatea ieÈ™irii.\n\nO valoare mai mare pentru top-k (de exemplu, 100) va considera mai mulÈ›i tokeni È™i va conduce la un text mai divers, Ã®n timp ce o valoare mai micÄƒ (de exemplu, 10) se va concentra pe cei mai probabili tokeni È™i va genera un text mai conservator.\n\nâ€¢ Valoarea implicitÄƒ este <{{dynamicValue}}>",
  "llm.prediction.llama.cpuThreads/title": "Fire CPU",
  "llm.prediction.llama.cpuThreads/subTitle": "NumÄƒrul de fire CPU utilizate Ã®n timpul inferenÈ›ei",
  "llm.prediction.llama.cpuThreads/info": "NumÄƒrul de fire utilizate Ã®n timpul calculului. CreÈ™terea numÄƒrului de fire nu se coreleazÄƒ Ã®ntotdeauna cu o performanÈ›Äƒ mai bunÄƒ. Implicit este <{{dynamicValue}}>.",
  "llm.prediction.maxPredictedTokens/title": "LimiteazÄƒ lungimea rÄƒspunsului",
  "llm.prediction.maxPredictedTokens/subTitle": "OpÈ›ional, limitaÈ›i lungimea rÄƒspunsului AI",
  "llm.prediction.maxPredictedTokens/info": "ControlaÈ›i lungimea maximÄƒ a rÄƒspunsului chatbot-ului. ActivaÈ›i pentru a seta o limitÄƒ maximÄƒ de rÄƒspuns, sau dezactivaÈ›i pentru a lÄƒsa chatbot-ul sÄƒ decidÄƒ cÃ¢nd sÄƒ se opreascÄƒ.",
  "llm.prediction.maxPredictedTokens/inputLabel": "Lungime maximÄƒ a rÄƒspunsului (tokeni)",
  "llm.prediction.maxPredictedTokens/wordEstimate": "Aproximativ {{maxWords}} cuvinte",
  "llm.prediction.repeatPenalty/title": "Penalizare repetare",
  "llm.prediction.repeatPenalty/subTitle": "CÃ¢t de mult sÄƒ descurajeze repetarea aceluiaÈ™i token",
  "llm.prediction.repeatPenalty/info": "Din documentaÈ›ia de ajutor a llama.cpp: \"AjutÄƒ la prevenirea generÄƒrii de text repetitiv sau monoton.\n\nO valoare mai mare (de exemplu, 1.5) va penaliza repetiÈ›iile mai sever, Ã®n timp ce o valoare mai micÄƒ (de exemplu, 0.9) va fi mai indulgentÄƒ.\" â€¢ Valoarea implicitÄƒ este <{{dynamicValue}}>",
  "llm.prediction.minPSampling/title": "EÈ™antionare Min P",
  "llm.prediction.minPSampling/subTitle": "Probabilitatea de bazÄƒ minimÄƒ pentru ca un token sÄƒ fie selectat pentru ieÈ™ire",
  "llm.prediction.minPSampling/info": "Din documentaÈ›ia de ajutor a llama.cpp:\n\nProbabilitatea minimÄƒ pentru ca un token sÄƒ fie considerat, relativ la probabilitatea celui mai probabil token. Trebuie sÄƒ fie Ã®n [0, 1].\n\nâ€¢ Valoarea implicitÄƒ este <{{dynamicValue}}>",
  "llm.prediction.topPSampling/title": "EÈ™antionare Top P",
  "llm.prediction.topPSampling/subTitle": "Probabilitatea cumulativÄƒ minimÄƒ pentru urmÄƒtorii tokeni posibili. FuncÈ›ioneazÄƒ similar cu temperatura",
  "llm.prediction.topPSampling/info": "Din documentaÈ›ia de ajutor a llama.cpp:\n\nEÈ™antionarea top-p, cunoscutÄƒ È™i sub numele de eÈ™antionare nucleu, este o altÄƒ metodÄƒ de generare a textului care selecteazÄƒ urmÄƒtorul token dintr-un subset de tokeni care Ã®mpreunÄƒ au o probabilitate cumulativÄƒ de cel puÈ›in p.\n\nAceastÄƒ metodÄƒ oferÄƒ un echilibru Ã®ntre diversitate È™i calitate, luÃ¢nd Ã®n considerare atÃ¢t probabilitÄƒÈ›ile tokenilor, cÃ¢t È™i numÄƒrul de tokeni din care se alege.\n\nO valoare mai mare pentru top-p (de exemplu, 0.95) va conduce la un text mai divers, Ã®n timp ce o valoare mai micÄƒ (de exemplu, 0.5) va genera un text mai concentrat È™i conservator. Trebuie sÄƒ fie Ã®n intervalul (0, 1].\n\nâ€¢ Valoarea implicitÄƒ este <{{dynamicValue}}>",
  "llm.prediction.stopStrings/title": "È˜iruri de oprire",
  "llm.prediction.stopStrings/subTitle": "È˜iruri care ar trebui sÄƒ opreascÄƒ modelul din generarea altor tokeni",
  "llm.prediction.stopStrings/info": "È˜iruri specifice care, atunci cÃ¢nd sunt Ã®ntÃ¢lnite, vor opri modelul din generarea de tokeni suplimentari",
  "llm.prediction.stopStrings/placeholder": "IntroduceÈ›i un È™ir È™i apÄƒsaÈ›i â",
  "llm.prediction.contextOverflowPolicy/title": "DepÄƒÈ™irea contextului",
  "llm.prediction.contextOverflowPolicy/subTitle": "Cum ar trebui sÄƒ se comporte modelul atunci cÃ¢nd conversaÈ›ia devine prea mare pentru a fi gestionatÄƒ",
  "llm.prediction.contextOverflowPolicy/info": "DecideÈ›i ce sÄƒ faceÈ›i atunci cÃ¢nd conversaÈ›ia depÄƒÈ™eÈ™te dimensiunea memoriei de lucru a modelului ('context')",
  "llm.prediction.llama.frequencyPenalty/title": "Penalizare de frecvenÈ›Äƒ",
  "llm.prediction.llama.presencePenalty/title": "Penalizare de prezenÈ›Äƒ",
  "llm.prediction.llama.tailFreeSampling/title": "EÈ™antionare fÄƒrÄƒ coadÄƒ",
  "llm.prediction.llama.locallyTypicalSampling/title": "EÈ™antionare local tipicÄƒ",
  "llm.prediction.onnx.topKSampling/title": "EÈ™antionare Top K",
  "llm.prediction.onnx.topKSampling/subTitle": "LimiteazÄƒ urmÄƒtorul token la unul dintre cei top-k tokeni cei mai probabili. FuncÈ›ioneazÄƒ similar cu temperatura",
  "llm.prediction.onnx.topKSampling/info": "Din documentaÈ›ia ONNX:\n\nNumÄƒrul de tokeni cu cea mai mare probabilitate din vocabular care se pÄƒstreazÄƒ pentru filtrarea top-k\n\nâ€¢ Acest filtru este dezactivat implicit",
  "llm.prediction.onnx.repeatPenalty/title": "Penalizare repetare",
  "llm.prediction.onnx.repeatPenalty/subTitle": "CÃ¢t de mult sÄƒ descurajeze repetarea aceluiaÈ™i token",
  "llm.prediction.onnx.repeatPenalty/info": "O valoare mai mare descurajeazÄƒ modelul sÄƒ se repete",
  "llm.prediction.onnx.topPSampling/title": "EÈ™antionare Top P",
  "llm.prediction.onnx.topPSampling/subTitle": "Probabilitatea cumulativÄƒ minimÄƒ pentru urmÄƒtorii tokeni posibili. FuncÈ›ioneazÄƒ similar cu temperatura",
  "llm.prediction.onnx.topPSampling/info": "Din documentaÈ›ia ONNX:\n\nSe pÄƒstreazÄƒ doar tokenii cei mai probabili ale cÄƒror probabilitÄƒÈ›i Ã®nsumeazÄƒ TopP sau mai mult pentru generare\n\nâ€¢ Acest filtru este dezactivat implicit",
  "llm.prediction.seed/title": "SÄƒmÃ¢nÈ›Äƒ",
  "llm.prediction.structured/title": "IeÈ™ire structuratÄƒ",
  "llm.prediction.structured/info": "IeÈ™ire structuratÄƒ",
  "llm.prediction.structured/description": "Avansat: puteÈ›i furniza un JSON Schema pentru a impune un anumit format de ieÈ™ire de la model. CitiÈ›i [documentaÈ›ia](https://lmstudio.ai/docs/advanced/structured-output) pentru a afla mai multe",
  "llm.prediction.promptTemplate/title": "È˜ablon de prompt",
  "llm.prediction.promptTemplate/subTitle": "Formatul Ã®n care mesajele din chat sunt trimise cÄƒtre model. Schimbarea acestuia poate introduce comportamente neaÈ™teptate - asiguraÈ›i-vÄƒ cÄƒ È™tiÈ›i ce faceÈ›i!",
  "llm.load.contextLength/title": "Lungimea contextului",
  "llm.load.contextLength/subTitle": "NumÄƒrul maxim de tokeni la care modelul poate presta atenÈ›ie Ã®ntr-un singur prompt. ConsultaÈ›i opÈ›iunile de depÄƒÈ™ire a conversaÈ›iei din secÈ›iunea \"Parametri de inferenÈ›Äƒ\" pentru mai multe modalitÄƒÈ›i de gestionare a acestui aspect",
  "llm.load.contextLength/info": "SpecificaÈ›i numÄƒrul maxim de tokeni pe care modelul Ã®i poate considera simultan, influenÈ›Ã¢nd cÃ¢t de mult context reÈ›ine Ã®n timpul procesÄƒrii",
  "llm.load.contextLength/warning": "Setarea unei valori mari pentru lungimea contextului poate afecta semnificativ utilizarea memoriei",
  "llm.load.seed/title": "SÄƒmÃ¢nÈ›Äƒ",
  "llm.load.seed/subTitle": "SÄƒmÃ¢nÈ›a pentru generatorul de numere aleatorii folosit Ã®n generarea textului. -1 Ã®nseamnÄƒ aleatoriu",
  "llm.load.seed/info": "SÄƒmÃ¢nÈ›Äƒ aleatorie: SeteazÄƒ sÄƒmÃ¢nÈ›a pentru generarea numerelor aleatorii pentru a asigura rezultate reproductibile",
  "llm.load.llama.evalBatchSize/title": "Dimensiunea lotului de evaluare",
  "llm.load.llama.evalBatchSize/subTitle": "NumÄƒrul de tokeni de intrare procesaÈ›i simultan. CreÈ™terea acestuia Ã®mbunÄƒtÄƒÈ›eÈ™te performanÈ›a, dar creÈ™te utilizarea memoriei",
  "llm.load.llama.evalBatchSize/info": "SeteazÄƒ numÄƒrul de exemple procesate Ã®mpreunÄƒ Ã®ntr-un singur lot Ã®n timpul evaluÄƒrii, afectÃ¢nd viteza È™i utilizarea memoriei",
  "llm.load.llama.ropeFrequencyBase/title": "BazÄƒ de frecvenÈ›Äƒ RoPE",
  "llm.load.llama.ropeFrequencyBase/subTitle": "FrecvenÈ›Äƒ de bazÄƒ personalizatÄƒ pentru Ã®ncorporÄƒrile poziÈ›ionale rotative (RoPE). CreÈ™terea acesteia poate permite o performanÈ›Äƒ mai bunÄƒ la lungimi mari de context",
  "llm.load.llama.ropeFrequencyBase/info": "[Avansat] AjusteazÄƒ frecvenÈ›a de bazÄƒ pentru codarea poziÈ›ionalÄƒ rotativÄƒ, influenÈ›Ã¢nd modul Ã®n care informaÈ›iile poziÈ›ionale sunt Ã®ncorporate",
  "llm.load.llama.ropeFrequencyScale/title": "ScalÄƒ de frecvenÈ›Äƒ RoPE",
  "llm.load.llama.ropeFrequencyScale/subTitle": "Lungimea contextului este scalatÄƒ prin acest factor pentru a extinde contextul efectiv folosind RoPE",
  "llm.load.llama.ropeFrequencyScale/info": "[Avansat] ModificÄƒ scalarea frecvenÈ›ei pentru codarea poziÈ›ionalÄƒ rotativÄƒ pentru a controla granularitatea codÄƒrii poziÈ›ionale",
  "llm.load.llama.acceleration.offloadRatio/title": "DescÄƒrcare GPU",
  "llm.load.llama.acceleration.offloadRatio/subTitle": "NumÄƒrul de straturi discrete ale modelului care vor fi procesate pe GPU pentru accelerare",
  "llm.load.llama.acceleration.offloadRatio/info": "SetaÈ›i numÄƒrul de straturi de descÄƒrcat pe GPU.",
  "llm.load.llama.flashAttention/title": "AtenÈ›ie Flash",
  "llm.load.llama.flashAttention/subTitle": "Reduce utilizarea memoriei È™i timpul de generare la unele modele",
  "llm.load.llama.flashAttention/info": "AccelereazÄƒ mecanismele de atenÈ›ie pentru o procesare mai rapidÄƒ È™i mai eficientÄƒ",
  "llm.load.numExperts/title": "NumÄƒrul de experÈ›i",
  "llm.load.numExperts/subTitle": "NumÄƒrul de experÈ›i de utilizat Ã®n model",
  "llm.load.numExperts/info": "NumÄƒrul de experÈ›i de utilizat Ã®n model",
  "llm.load.llama.keepModelInMemory/title": "PÄƒstreazÄƒ modelul Ã®n memorie",
  "llm.load.llama.keepModelInMemory/subTitle": "RezervaÈ›i memorie sistemului pentru model, chiar È™i cÃ¢nd este descÄƒrcat pe GPU. ÃmbunÄƒtÄƒÈ›eÈ™te performanÈ›a, dar necesitÄƒ mai multÄƒ memorie RAM a sistemului",
  "llm.load.llama.keepModelInMemory/info": "Previne ca modelul sÄƒ fie mutat pe disc, asigurÃ¢nd un acces mai rapid Ã®n schimbul unei utilizÄƒri mai mari a memoriei RAM",
  "llm.load.llama.useFp16ForKVCache/title": "UtilizeazÄƒ FP16 pentru cache-ul KV",
  "llm.load.llama.useFp16ForKVCache/info": "Reduce utilizarea memoriei prin stocarea cache-ului Ã®n precizie redusÄƒ (FP16)",
  "llm.load.llama.tryMmap/title": "ÃncearcÄƒ mmap()",
  "llm.load.llama.tryMmap/subTitle": "ÃmbunÄƒtÄƒÈ›eÈ™te timpul de Ã®ncÄƒrcare al modelului. Dezactivarea acestuia poate Ã®mbunÄƒtÄƒÈ›i performanÈ›a cÃ¢nd modelul este mai mare decÃ¢t memoria RAM disponibilÄƒ",
  "llm.load.llama.tryMmap/info": "ÃncÄƒrcaÈ›i fiÈ™ierele modelului direct de pe disc Ã®n memorie",
  "embedding.load.contextLength/title": "Lungimea contextului",
  "embedding.load.contextLength/subTitle": "NumÄƒrul maxim de tokeni la care modelul poate presta atenÈ›ie Ã®ntr-un singur prompt. ConsultaÈ›i opÈ›iunile de depÄƒÈ™ire a conversaÈ›iei din secÈ›iunea \"Parametri de inferenÈ›Äƒ\" pentru mai multe modalitÄƒÈ›i de gestionare a acestui aspect",
  "embedding.load.contextLength/info": "SpecificaÈ›i numÄƒrul maxim de tokeni pe care modelul Ã®i poate considera simultan, influenÈ›Ã¢nd cÃ¢t de mult context reÈ›ine Ã®n timpul procesÄƒrii",
  "embedding.load.llama.ropeFrequencyBase/title": "BazÄƒ de frecvenÈ›Äƒ RoPE",
  "embedding.load.llama.ropeFrequencyBase/subTitle": "FrecvenÈ›Äƒ de bazÄƒ personalizatÄƒ pentru Ã®ncorporÄƒrile poziÈ›ionale rotative (RoPE). CreÈ™terea acesteia poate permite o performanÈ›Äƒ mai bunÄƒ la lungimi mari de context",
  "embedding.load.llama.ropeFrequencyBase/info": "[Avansat] AjusteazÄƒ frecvenÈ›a de bazÄƒ pentru codarea poziÈ›ionalÄƒ rotativÄƒ, influenÈ›Ã¢nd modul Ã®n care informaÈ›iile poziÈ›ionale sunt Ã®ncorporate",
  "embedding.load.llama.evalBatchSize/title": "Dimensiunea lotului de evaluare",
  "embedding.load.llama.evalBatchSize/subTitle": "NumÄƒrul de tokeni de intrare procesaÈ›i simultan. CreÈ™terea acestuia Ã®mbunÄƒtÄƒÈ›eÈ™te performanÈ›a, dar creÈ™te utilizarea memoriei",
  "embedding.load.llama.evalBatchSize/info": "SeteazÄƒ numÄƒrul de tokeni procesaÈ›i Ã®mpreunÄƒ Ã®ntr-un singur lot Ã®n timpul evaluÄƒrii",
  "embedding.load.llama.ropeFrequencyScale/title": "ScalÄƒ de frecvenÈ›Äƒ RoPE",
  "embedding.load.llama.ropeFrequencyScale/subTitle": "Lungimea contextului este scalatÄƒ prin acest factor pentru a extinde contextul efectiv folosind RoPE",
  "embedding.load.llama.ropeFrequencyScale/info": "[Avansat] ModificÄƒ scalarea frecvenÈ›ei pentru codarea poziÈ›ionalÄƒ rotativÄƒ pentru a controla granularitatea codÄƒrii poziÈ›ionale",
  "embedding.load.llama.acceleration.offloadRatio/title": "DescÄƒrcare GPU",
  "embedding.load.llama.acceleration.offloadRatio/subTitle": "NumÄƒrul de straturi discrete ale modelului care vor fi procesate pe GPU pentru accelerare",
  "embedding.load.llama.acceleration.offloadRatio/info": "SetaÈ›i numÄƒrul de straturi de descÄƒrcat pe GPU.",
  "embedding.load.llama.keepModelInMemory/title": "PÄƒstreazÄƒ modelul Ã®n memorie",
  "embedding.load.llama.keepModelInMemory/subTitle": "RezervaÈ›i memorie sistemului pentru model, chiar È™i cÃ¢nd este descÄƒrcat pe GPU. ÃmbunÄƒtÄƒÈ›eÈ™te performanÈ›a, dar necesitÄƒ mai multÄƒ memorie RAM",
  "embedding.load.llama.keepModelInMemory/info": "Previne ca modelul sÄƒ fie mutat pe disc, asigurÃ¢nd un acces mai rapid Ã®n schimbul unei utilizÄƒri mai mari a memoriei RAM",
  "embedding.load.llama.tryMmap/title": "ÃncearcÄƒ mmap()",
  "embedding.load.llama.tryMmap/subTitle": "ÃmbunÄƒtÄƒÈ›eÈ™te timpul de Ã®ncÄƒrcare al modelului. Dezactivarea acestuia poate Ã®mbunÄƒtÄƒÈ›i performanÈ›a cÃ¢nd modelul este mai mare decÃ¢t memoria RAM disponibilÄƒ",
  "embedding.load.llama.tryMmap/info": "ÃncÄƒrcaÈ›i fiÈ™ierele modelului direct de pe disc Ã®n memorie",
  "embedding.load.seed/title": "SÄƒmÃ¢nÈ›Äƒ",
  "embedding.load.seed/subTitle": "SÄƒmÃ¢nÈ›a pentru generatorul de numere aleatorii folosit Ã®n generarea textului. -1 Ã®nseamnÄƒ sÄƒmÃ¢nÈ›Äƒ aleatorie",
  "embedding.load.seed/info": "SÄƒmÃ¢nÈ›Äƒ aleatorie: SeteazÄƒ sÄƒmÃ¢nÈ›a pentru generarea numerelor aleatorii pentru a asigura rezultate reproductibile",
  "presetTooltip": {
    "included/title": "Valori presetate",
    "included/description": "CÃ¢mpurile urmÄƒtoare vor fi aplicate",
    "included/empty": "Niciun cÃ¢mp al acestei presetÄƒri nu se aplicÄƒ Ã®n acest context.",
    "included/conflict": "Vi se va cere sÄƒ alegeÈ›i dacÄƒ sÄƒ aplicaÈ›i aceastÄƒ valoare",
    "separateLoad/title": "Configurare la Ã®ncÄƒrcare",
    "separateLoad/description.1": "Presetarea include, de asemenea, urmÄƒtoarea configurare la Ã®ncÄƒrcare. ConfigurÄƒrile la Ã®ncÄƒrcare sunt pentru Ã®ntregul model È™i necesitÄƒ reÃ®ncÄƒrcarea modelului pentru a intra Ã®n vigoare. ÈšineÈ›i apÄƒsat",
    "separateLoad/description.2": "pentru a aplica la",
    "separateLoad/description.3": ".",
    "excluded/title": "Este posibil sÄƒ nu se aplice",
    "excluded/description": "CÃ¢mpurile urmÄƒtoare sunt incluse Ã®n presetare, dar nu se aplicÄƒ Ã®n contextul curent.",
    "legacy/title": "Presetare veche",
    "legacy/description": "AceastÄƒ presetare este o presetare veche. Include urmÄƒtoarele cÃ¢mpuri care fie sunt gestionate automat acum, fie nu mai sunt aplicabile."
  },
  "customInputs": {
    "string": {
      "emptyParagraph": "<Gol>"
    },
    "checkboxNumeric": {
      "off": "Oprit"
    },
    "stringArray": {
      "empty": "<Gol>"
    },
    "llmPromptTemplate": {
      "type": "Tip",
      "types.jinja/label": "È˜ablon (Jinja)",
      "jinja.bosToken/label": "Token BOS",
      "jinja.eosToken/label": "Token EOS",
      "jinja.template/label": "È˜ablon",
      "jinja/error": "Parcurgerea È™ablonului Jinja a eÈ™uat: {{error}}",
      "jinja/empty": "VÄƒ rugÄƒm sÄƒ introduceÈ›i un È™ablon Jinja mai sus.",
      "jinja/unlikelyToWork": "È˜ablonul Jinja furnizat mai sus este puÈ›in probabil sÄƒ funcÈ›ioneze deoarece nu face referire la variabila \"messages\". VÄƒ rugÄƒm verificaÈ›i dacÄƒ aÈ›i introdus un È™ablon corect.",
      "types.manual/label": "Manual",
      "manual.subfield.beforeSystem/label": "Ãnainte de Sistem",
      "manual.subfield.beforeSystem/placeholder": "IntroduceÈ›i prefixul pentru sistem...",
      "manual.subfield.afterSystem/label": "DupÄƒ Sistem",
      "manual.subfield.afterSystem/placeholder": "IntroduceÈ›i sufixul pentru sistem...",
      "manual.subfield.beforeUser/label": "Ãnainte de Utilizator",
      "manual.subfield.beforeUser/placeholder": "IntroduceÈ›i prefixul pentru utilizator...",
      "manual.subfield.afterUser/label": "DupÄƒ Utilizator",
      "manual.subfield.afterUser/placeholder": "IntroduceÈ›i sufixul pentru utilizator...",
      "manual.subfield.beforeAssistant/label": "Ãnainte de Asistent",
      "manual.subfield.beforeAssistant/placeholder": "IntroduceÈ›i prefixul pentru asistent...",
      "manual.subfield.afterAssistant/label": "DupÄƒ Asistent",
      "manual.subfield.afterAssistant/placeholder": "IntroduceÈ›i sufixul pentru asistent...",
      "stopStrings/label": "È˜iruri suplimentare de oprire",
      "stopStrings/subTitle": "È˜iruri de oprire specifice È™ablonului care vor fi utilizate pe lÃ¢ngÄƒ È™irurile de oprire specificate de utilizator."
    },
    "contextLength": {
      "maxValueTooltip": "Acesta este numÄƒrul maxim de tokeni pe care modelul a fost antrenat sÄƒ Ã®i gestioneze. FaceÈ›i clic pentru a seta contextul la aceastÄƒ valoare",
      "maxValueTextStart": "Modelul suportÄƒ pÃ¢nÄƒ la",
      "maxValueTextEnd": "tokeni",
      "tooltipHint": "DeÈ™i un model poate suporta un anumit numÄƒr de tokeni, performanÈ›a poate scÄƒdea dacÄƒ resursele maÈ™inii dvs. nu pot gestiona Ã®ncÄƒrcarea - folosiÈ›i precauÈ›ie cÃ¢nd mÄƒriÈ›i aceastÄƒ valoare"
    },
    "contextOverflowPolicy": {
      "stopAtLimit": "OpreÈ™te la limitÄƒ",
      "stopAtLimitSub": "OpreÈ™te generarea odatÄƒ ce memoria modelului se umple",
      "truncateMiddle": "TrunchiazÄƒ mijlocul",
      "truncateMiddleSub": "EliminÄƒ mesajele din mijlocul conversaÈ›iei pentru a face loc celor noi. Modelul Ã®È™i va aminti totuÈ™i Ã®nceputul conversaÈ›iei",
      "rollingWindow": "FereastrÄƒ derulantÄƒ",
      "rollingWindowSub": "Modelul va primi Ã®ntotdeauna ultimele cÃ¢teva mesaje, dar poate uita Ã®nceputul conversaÈ›iei"
    },
    "llamaAccelerationOffloadRatio": {
      "max": "MAX",
      "off": "Oprit"
    }
  },
  "saveConflictResolution": {
    "title": "AlegeÈ›i care valori sÄƒ fie incluse Ã®n presetare",
    "description": "AlegeÈ›i valorile de pÄƒstrat",
    "instructions": "FaceÈ›i clic pe o valoare pentru a o include",
    "userValues": "Valoare anterioarÄƒ",
    "presetValues": "Valoare nouÄƒ",
    "confirm": "ConfirmÄƒ",
    "cancel": "AnuleazÄƒ"
  },
  "applyConflictResolution": {
    "title": "Ce valori sÄƒ pÄƒstraÈ›i?",
    "description": "AveÈ›i modificÄƒri nesalvate care se suprapun cu presetarea primitÄƒ",
    "instructions": "FaceÈ›i clic pe o valoare pentru a o pÄƒstra",
    "userValues": "Valoare curentÄƒ",
    "presetValues": "Valoare din presetarea primitÄƒ",
    "confirm": "ConfirmÄƒ",
    "cancel": "AnuleazÄƒ"
  },
  "empty": "<Gol>",
  "presets": {
    "title": "Presetare",
    "commitChanges": "ConfirmÄƒ modificÄƒrile",
    "commitChanges/description": "ConfirmÄƒ modificÄƒrile Ã®n presetare.",
    "commitChanges.manual": "CÃ¢mpuri noi detectate. VeÈ›i putea alege care modificÄƒri sÄƒ fie incluse Ã®n presetare.",
    "commitChanges.manual.hold.0": "ÈšineÈ›i",
    "commitChanges.manual.hold.1": "pentru a alege care modificÄƒri sÄƒ fie confirmate Ã®n presetare.",
    "commitChanges.saveAll.hold.0": "ÈšineÈ›i",
    "commitChanges.saveAll.hold.1": "pentru a salva toate modificÄƒrile.",
    "commitChanges.saveInPreset.hold.0": "ÈšineÈ›i",
    "commitChanges.saveInPreset.hold.1": "pentru a salva doar modificÄƒrile la cÃ¢mpurile care sunt deja incluse Ã®n presetare.",
    "commitChanges/error": "Confirmarea modificÄƒrilor Ã®n presetare a eÈ™uat.",
    "commitChanges.manual/description": "AlegeÈ›i care modificÄƒri sÄƒ fie incluse Ã®n presetare.",
    "saveAs": "SalveazÄƒ ca nou...",
    "presetNamePlaceholder": "IntroduceÈ›i un nume pentru presetare...",
    "cannotCommitChangesLegacy": "Aceasta este o presetare veche È™i nu poate fi modificatÄƒ. PuteÈ›i crea o copie folosind \"SalveazÄƒ ca nou...\".",
    "cannotCommitChangesNoChanges": "Nicio modificare de confirmat.",
    "emptyNoUnsaved": "SelectaÈ›i o presetare...",
    "emptyWithUnsaved": "Presetare nesalvatÄƒ",
    "saveEmptyWithUnsaved": "SalveazÄƒ presetarea ca...",
    "saveConfirm": "SalveazÄƒ",
    "saveCancel": "AnuleazÄƒ",
    "saving": "Se salveazÄƒ...",
    "save/error": "Salvarea presetÄƒrii a eÈ™uat.",
    "deselect": "DeselecteazÄƒ presetarea",
    "deselect/error": "Deselectarea presetÄƒrii a eÈ™uat.",
    "select/error": "Selectarea presetÄƒrii a eÈ™uat.",
    "delete/error": "È˜tergerea presetÄƒrii a eÈ™uat.",
    "discardChanges": "RenunÈ›Äƒ la nesalvat",
    "discardChanges/info": "RenunÈ›Äƒ la toate modificÄƒrile nesalvate È™i restaureazÄƒ presetarea la starea sa originalÄƒ",
    "newEmptyPreset": "CreeazÄƒ o presetare nouÄƒ È™i goalÄƒ...",
    "contextMenuSelect": "SelecteazÄƒ presetarea",
    "contextMenuDelete": "È˜terge"
  },
  "flashAttentionWarning": "Flash Attention este o caracteristicÄƒ experimentalÄƒ care poate cauza probleme la unele modele. DacÄƒ Ã®ntÃ¢mpinaÈ›i probleme, Ã®ncercaÈ›i sÄƒ o dezactivaÈ›i.",
  "seedUncheckedHint": "SÄƒmÃ¢nÈ›Äƒ aleatorie",
  "ropeFrequencyBaseUncheckedHint": "Auto",
  "ropeFrequencyScaleUncheckedHint": "Auto"
}
