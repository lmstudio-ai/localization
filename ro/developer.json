{
  "tabs/server": "Server Local",
  "tabs/extensions": "Runtime-uri LM",
  "loadSettings/title": "Încarcă setările",
  "modelSettings/placeholder": "Selectați un model pentru a-l configura",
  "loadedModels/noModels": "Niciun model încărcat",
  "serverOptions/title": "Opțiuni server",
  "serverOptions/configurableTitle": "Opțiuni configurabile",
  "serverOptions/port/hint": "Setați portul de rețea pe care serverul local îl va folosi. Implicit, LM Studio folosește portul 1234. Este posibil să fie necesar să schimbați acest port dacă este deja folosit.",
  "serverOptions/port/subtitle": "Portul de ascultare",
  "serverOptions/autostart/title": "Pornire automată a serverului",
  "serverOptions/autostart/hint": "Porniți serverul local automat când este încărcat un model",
  "serverOptions/port/integerWarning": "Numărul portului trebuie să fie un număr întreg",
  "serverOptions/port/invalidPortWarning": "Portul trebuie să fie între 1 și 65535",
  "serverOptions/cors/title": "Activează CORS",
  "serverOptions/cors/hint1": "Activarea CORS (Cross-origin Resource Sharing) permite site-urilor pe care le vizitați să trimită cereri către serverul LM Studio.",
  "serverOptions/cors/hint2": "CORS poate fi necesar atunci când se fac cereri dintr-o pagină web sau din VS Code / altă extensie.",
  "serverOptions/cors/subtitle": "Permite cereri cross-origin",
  "serverOptions/network/title": "Servește pe rețeaua locală",
  "serverOptions/network/subtitle": "Expune serverul către dispozitivele din rețea",
  "serverOptions/network/hint1": "Indică dacă se permit conexiuni de la alte dispozitive din rețea.",
  "serverOptions/network/hint2": "Dacă nu este bifat, serverul va asculta doar pe localhost.",
  "serverOptions/verboseLogging/title": "Jurnalizare detaliată",
  "serverOptions/verboseLogging/subtitle": "Activează jurnalizarea detaliată pentru serverul local",
  "serverOptions/contentLogging/title": "Înregistrează prompturile și răspunsurile",
  "serverOptions/contentLogging/subtitle": "Setări locale de înregistrare a cererilor/răspunsurilor",
  "serverOptions/contentLogging/hint": "Indică dacă prompturile și/sau răspunsurile trebuie înregistrate în fișierul de log al serverului local.",
  "serverOptions/jitModelLoading/title": "Încărcare model la momentul necesar",
  "serverOptions/jitModelLoading/hint": "Când este activat, dacă o cerere specifică un model care nu este încărcat, acesta va fi încărcat automat și folosit. În plus, endpoint-ul \"/v1/models\" va include și modelele care nu sunt încărcate încă.",
  "serverOptions/loadModel/error": "Încărcarea modelului a eșuat",
  "serverLogs/scrollToBottom": "Salt la final",
  "serverLogs/clearLogs": "Șterge jurnalele ({{shortcut}})",
  "serverLogs/openLogsFolder": "Deschide folderul cu jurnalele serverului",
  "runtimeSettings/title": "Setări runtime",
  "runtimeSettings/chooseRuntime/title": "Configurează runtime-urile",
  "runtimeSettings/chooseRuntime/description": "Selectați un runtime pentru fiecare format de model",
  "runtimeSettings/chooseRuntime/showAllVersions/label": "Afișează toate runtime-urile",
  "runtimeSettings/chooseRuntime/showAllVersions/hint": "Implicit, LM Studio afișează doar cea mai recentă versiune a fiecărui runtime compatibil. Activați această opțiune pentru a vedea toate runtime-urile disponibile.",
  "runtimeSettings/chooseRuntime/select/placeholder": "Selectați un runtime",
  "runtimeOptions/uninstall": "Dezinstalează",
  "runtimeOptions/uninstallDialog/title": "Dezinstalare {{runtimeName}}?",
  "runtimeOptions/uninstallDialog/body": "Dezinstalarea acestui runtime îl va elimina din sistem. Această acțiune este ireversibilă.",
  "runtimeOptions/uninstallDialog/body/caveats": "Unele fișiere pot fi eliminate doar după repornirea LM Studio.",
  "runtimeOptions/uninstallDialog/error": "Dezinstalarea runtime-ului a eșuat",
  "runtimeOptions/uninstallDialog/confirm": "Continuă și dezinstalează",
  "runtimeOptions/uninstallDialog/cancel": "Anulează",
  "runtimeOptions/noCompatibleRuntimes": "Nu s-au găsit runtime-uri compatibile",
  "runtimeOptions/downloadIncompatibleRuntime": "S-a constatat că acest runtime este incompatibil cu mașina dvs. Cel mai probabil nu va funcționa.",
  "runtimeOptions/noRuntimes": "Nu s-au găsit runtime-uri",
  "inferenceParams/noParams": "Nu există parametri de inferență configurabili disponibili pentru acest tip de model",
  "endpoints/openaiCompatRest/title": "Endpoint-uri suportate (asemănătoare OpenAI)",
  "endpoints/openaiCompatRest/getModels": "Listează modelele încărcate în prezent",
  "endpoints/openaiCompatRest/postCompletions": "Mod de completare text. Prezice următorul token (sau tokeni) dat un prompt. Notă: OpenAI consideră acest endpoint ca fiind 'depreciat'.",
  "endpoints/openaiCompatRest/postChatCompletions": "Completări de chat. Trimiteți istoricul chat-ului modelului pentru a prezice următorul răspuns al asistentului",
  "endpoints/openaiCompatRest/postEmbeddings": "Încapsulare text. Generează reprezentări vectoriale pentru un text dat. Primește un șir sau un array de șiruri.",
  "model.createVirtualModelFromInstance": "Salvează setările ca un nou model virtual",
  "model.createVirtualModelFromInstance/error": "Salvarea setărilor ca model virtual nou a eșuat",
  "apiConfigOptions/title": "Configurare API"
}
