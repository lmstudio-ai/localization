{
  "modelLoaderPlaceholder": "Choisissez un modèle à charger",
  "systemPromptPlaceholder": "Définir le prompt système",
  "userRoleText": "Utilisateur",
  "assistantRoleText": "Assistant",
  "addMessageButtonText": "Ajouter",
  "addMessageButtonText/toolTip": "Insérer un message dans le contexte sans déclencher de prédiction",
  "sendMessageButtonText": "Envoyer",
  "sendMessageButtonText/toolTip": "Envoyez votre invite et l'historique de conversation au modèle pour traitement",
  "ejectButtonText": "Éjecter",
  "unloadTooltip": "Éjecter le modèle de la mémoire",
  "cancelButtonText": "Annuler",
  "loadButtonText": "Charger",
  "advancedSegmentText": "Avancé",
  "chatSegmentText": "Chat",
  "chatSidebarTitle": "Chats",
  "newChatButton": "Nouveau Chat",
  "newFolderButton": "Nouveau Dossier",
  "viewModeLabel": "Mode d'affichage",
  "noChatSelected": "Aucun chat sélectionné",
  "chatViewOptions": "Options d'affichage du chat",
  "uiControls/title": "Paramètres d'affichage",
  "noChatSelectedPlaceholder": "Sélectionnez un chat",
  "unnamedChat": "Chat sans nom",
  "emptyFolder": "Le dossier est vide",

  "tokenCount": "Nombre de Tokens",
  "messageTokenCount": "Nombre de Tokens d'entrée",
  "tokenCount/hint": "Le nombre de tokens dans le message. Compté en utilisant le tokenizer du modèle actuellement sélectionné.\n\nNécessite que le modèle soit chargé.",
  "messageTokenCount/hint": "Le nombre de tokens dans le message. Compté en utilisant le tokenizer du modèle actuellement sélectionné.\n\nN'inclut **PAS** une estimation des tokens dans les pièces jointes de fichiers.",

  "notes": "Notes de conversation",
  "notes/add/first": "Ajouter une note",
  "notes/add/another": "Ajouter une autre note", 
  "notes/hint": "Enregistrez des notes dans ce chat. Les notes sont uniquement pour votre référence et ne sont pas envoyées au modèle. Tous les changements sont enregistrés automatiquement.",
  "notes/placeholder": "Tapez vos notes ici...",
  "notes/delete": "Supprimer la note",
  "notes/noteLabel": "Note",
  "notes/copyContent": "Copier le contenu de la note",

  "actions/sendMessage/error": "Échec de l'envoi du message",
  "actions/loadModel/error": "Échec du chargement du modèle",
  "actions/addFile": "[Expérimental] Joindre un fichier à ce message\n(.pdf, texte brut ou .docx)",
  "actions/changeRole": "Basculer entre les rôles Utilisateur et Assistant.\n\nCela est utile pour orienter la conversation dans une direction spécifique.\n\nPeut être utilisé pour des scénarios de 'apprentissage few-shot' ou 'd'apprentissage en contexte'",
  "actions/addImage": "Ajouter une image",
  "actions/deleteMessage": "Supprimer le message",
  "actions/deleteMessage/confirmation": "Êtes-vous sûr de vouloir supprimer ce message?",
  "actions/copyMessage": "Copier le message",
  "actions/editMessage": "Modifier le message",
  "actions/editMessage/cannotEditPreprocessed": "Impossible de modifier les messages prétraités car ils seront écrasés après l'exécution du préprocesseur. Pour modifier le message, soit : \n\n - Basculez sur le message d'origine et modifiez-le à la place, ou\n - Modifiez le préprocesseur pour qu'il produise la sortie souhaitée.",
  "actions/regenerateMessage": "Régénérer le message",
  "actions/regenerateMessage/error": "Échec de la régénération du message",
  "actions/branchChat": "Créer une branche du chat après ce message",
  "actions/branchChat/error": "Échec de la création d'une branche du chat",
  "actions/continueAssistantMessage": "Continuer le message de l'assistant",
  "actions/continueAssistantMessage/error": "Échec de la continuation du message de l'assistant",
  "actions/predictNext": "Générer une réponse IA",
  "actions/predictNext/error": "Échec de la génération de la réponse IA",
  "actions/loadLastModel": "Recharger le dernier modèle utilisé",
  "actions/loadLastModel/tooltip": "Cliquez pour charger le modèle qui a été utilisé en dernier avec ce chat:\n\n{{lastModel}}",
  "actions/loadLastModel/error": "Échec du chargement du dernier modèle utilisé",
  "actions/continueCurrentModel": "Utiliser le modèle actuel",
  "actions/continueCurrentModel/tooltip": "Modèle actuel : {{currentModel}}",
  "actions/changeToLastUsedModel": "Charger {{lastModel}}",
  "actions/changeToLastUsedModel/error": "Échec du chargement du dernier modèle utilisé",
  "actions/changeToLastUsedModel/tooltip": "Vous avez utilisé un modèle différent la dernière fois que vous avez envoyé un message dans ce chat. Cliquez pour décharger le modèle actuellement sélectionné ({{currentModel}}) et charger le modèle qui a été utilisé en dernier avec ce chat:\n\n{{lastModel}}",
  "actions/switchToLastUsedModel": "Basculer vers {{lastModel}}",
  "actions/switchToLastUsedModel/tooltip": "Cliquez pour basculer vers le modèle qui a été utilisé en dernier avec ce chat:\n\n{{lastModel}}",
  "actions/loadModel": "Charger un modèle",
  "actions/toggleViewingProcessed/currentlyFalse": "Affichage actuel du message original. Cliquez pour voir le message prétraité.",
  "actions/toggleViewingProcessed/currentlyTrue": "Affichage actuel du message prétraité. Cliquez pour voir le message original.",
  "actions/toggleViewingProcessed/hint": "Avant qu'un message ne soit envoyé au modèle, il peut être prétraité par un préprocesseur de prompt. Cliquez pour basculer entre l'affichage du message original et du message prétraité. Seul le message prétraité est envoyé au modèle.",
  "editMessageConfirm/title": "Conserver les modifications ?",
  "editMessageConfirm/message": "Vous avez modifié un message. Voulez-vous conserver ces modifications ?",
  "editMessageConfirm/keepEditing": "Continuer la modification",
  "editMessageConfirm/save": "Enregistrer",
  "editMessageConfirm/discard": "Annuler les modifications",
  "tokenCount/totalNotAvailable": "Tokens : {{current}}",
  "tokenCount/totalAvailable": "Tokens : {{current}}/{{total}}",
  "tokenCount/totalAvailablePercentage": "Le contexte est rempli à {{percentage}}%",
  "tokenCount/contextOverflow": "Le contexte non traité est plus grand que la limite maximale de tokens du modèle. Selon votre politique de débordement de contexte, le contexte peut être tronqué ou le message peut ne pas être envoyé.",
  "modelLoader/manualLoadParams/label": "Choisir manuellement les paramètres de chargement du modèle",
  "modelLoader/manualLoadParams/hint/before": "(ou maintenez ",
  "modelLoader/manualLoadParams/hint/after": ")",
  "actions/move/error": "Échec du déplacement",
  "actions/rename/error": "Échec du renommage",
  "actions/createChatAtRoot": "Nouveau Chat...",
  "actions/createChatAtRoot/error": "Échec de la création du chat à la racine",
  "actions/createFolderAtRoot": "Nouveau Dossier...",
  "actions/createFolderAtRoot/error": "Échec de la création du dossier à la racine",
  "actions/createChat/error": "Échec de la création du chat",

  "userFile/fileSizeLimit": "La taille limite du fichier est ",
  "userFile/noImageSupport": "Le modèle ne prend pas en charge l'entrée d'images",
  "userFile/errorPrefix": "Erreur - ",
  "userFile/supportedImagePrefix": "Type d'image non pris en charge - seuls ",
  "userFile/supportedImageSuffix": " sont pris en charge",
  "userFile/unsupportedFileType": "Type de fichier non pris en charge - seuls les images, PDFs et fichiers .txt sont pris en charge.",
  "userFile/maxFilesPerMessage": "Nombre maximum de fichiers par message atteint. Impossible d'ajouter plus de {{files}} fichiers. ",
  "userFile/maxFileSizePerMessage": "Taille maximale de fichier par message atteinte. Impossible d'ajouter des fichiers plus grands que {{size}}. ",
  "errorTitle": "Erreur",

  "prediction/busyModel/title": "Le modèle est occupé",
  "prediction/busyModel/message": "Veuillez attendre que le modèle termine et réessayez",
  "prediction/noModel/title": "Aucun modèle sélectionné",
  "prediction/modelLoading": "Message en attente, sera envoyé quand le modèle aura fini de charger",
  "prediction/noModel/message": "Sélectionnez un modèle pour envoyer un message",
  "prediction/unloadModel/error": "Échec du déchargement du modèle",

  "retrieval/user/processingLabel": "L'IA réfléchit...",
  "retrieval/powerUser/intermediateStepsHidden": "Étapes intermédiaires masquées. Cliquez pour développer.",
  "retrieval/actions/clickToExpand": "Cliquez pour développer les étapes intermédiaires",
  "retrieval/actions/clickToCollapse": "Cliquez pour réduire les étapes intermédiaires",

  "style": "Apparence du Chat",

  "style/viewMode/markdown": "Markdown",
  "style/viewMode/plaintext": "Texte brut",
  "style/viewMode/monospace": "Police à espacement fixe",

  "style/fontSize/label": "Taille de police",
  "style/fontSize/medium": "Par défaut",
  "style/fontSize/large": "Grande",
  "style/fontSize/small": "Petite",

  "topBarActions/duplicateChat": "Dupliquer le chat",
  "topBarActions/clearChat": "Effacer tous les messages",
  "topBarActions/clearChatConfirmation": "Êtes-vous sûr de vouloir effacer tous les messages de ce chat ?",
  "topBarActions/clearChatCancel": "Annuler",
  "topBarActions/clearChatDelete": "Tout effacer",

  "noModels.indexing": "Indexation des fichiers modèles... (cela peut prendre un moment)",
  "noModels.downloading": "Téléchargement de votre premier LLM...",
  "noModels": "Pas encore de LLM ! Téléchargez-en un pour commencer !"
}