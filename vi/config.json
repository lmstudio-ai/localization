{
  "noInstanceSelected": "Chưa chọn phiên bản mô hình",
  "resetToDefault": "Đặt lại",
  "showAdvancedSettings": "Hiển thị cài đặt nâng cao",
  "showAll": "Hiển thị tất cả",
  "basicSettings": "Cơ bản",
  "configSubtitle": "Tải hoặc lưu cấu hình sẵn và thử nghiệm với các tham số mô hình tùy chỉnh",
  "inferenceParameters/title": "Tham số Dự đoán",
  "inferenceParameters/info": "Thử nghiệm với các tham số ảnh hưởng đến dự đoán.",
  "generalParameters/title": "Chung",
  "samplingParameters/title": "Lấy mẫu",
  "basicTab": "Cơ bản",
  "advancedTab": "Nâng cao",
  "advancedTab/title": "🧪 Cấu hình Nâng cao",
  "advancedTab/expandAll": "Mở rộng tất cả",
  "advancedTab/overridesTitle": "Ghi đè Cấu hình",
  "advancedTab/noConfigsText": "Bạn không có thay đổi chưa lưu nào - chỉnh sửa giá trị ở trên để thấy ghi đè ở đây.",
  "loadInstanceFirst": "Tải mô hình để xem các tham số có thể cấu hình",
  "noListedConfigs": "Không có tham số có thể cấu hình",
  "generationParameters/info": "Thử nghiệm với các tham số cơ bản ảnh hưởng đến việc tạo văn bản.",
  "loadParameters/title": "Tải Tham số",
  "loadParameters/description": "Cài đặt để kiểm soát cách mô hình được khởi tạo và tải vào bộ nhớ.",
  "loadParameters/reload": "Tải lại để áp dụng thay đổi",
  "loadParameters/reload/error": "Không thể tải lại mô hình",
  "discardChanges": "Hủy bỏ thay đổi",
  "loadModelToSeeOptions": "Tải một mô hình để xem các tùy chọn",
  "schematicsError.title": "Cấu hình lược đồ chứa lỗi ở các trường sau:",
  "manifestSections": {
    "structuredOutput/title": "Đầu Ra Có Cấu Trúc",
    "speculativeDecoding/title": "Giải Mã Suy Đoán",
    "sampling/title": "Lấy Mẫu",
    "settings/title": "Cài Đặt",
    "toolUse/title": "Sử Dụng Công Cụ",
    "promptTemplate/title": "Mẫu Lời Nhắc"
  },

  "llm.prediction.systemPrompt/title": "Prompt Hệ Thống",
  "llm.prediction.systemPrompt/description": "Sử dụng trường này để cung cấp các hướng dẫn nền tảng cho mô hình, chẳng hạn như một tập hợp quy tắc, ràng buộc hoặc yêu cầu chung. Trường này cũng thường được gọi là \"prompt hệ thống\".",
  "llm.prediction.systemPrompt/subTitle": "Hướng dẫn cho AI",
  "llm.prediction.temperature/title": "Nhiệt độ",
  "llm.prediction.temperature/subTitle": "Mức độ ngẫu nhiên đưa vào. 0 sẽ cho kết quả giống nhau mỗi lần, trong khi giá trị cao hơn sẽ tăng tính sáng tạo và sự đa dạng",
  "llm.prediction.temperature/info": "Từ tài liệu llama.cpp: \"Giá trị mặc định là <{{dynamicValue}}>, cung cấp sự cân bằng giữa ngẫu nhiên và xác định. Ở mức cực đoan, nhiệt độ 0 sẽ luôn chọn token có khả năng xảy ra cao nhất tiếp theo, dẫn đến các kết quả giống hệt nhau trong mỗi lần chạy\"",
  "llm.prediction.llama.sampling/title": "Lấy Mẫu",
  "llm.prediction.topKSampling/title": "Lấy mẫu Top K",
  "llm.prediction.topKSampling/subTitle": "Giới hạn token tiếp theo thành một trong k token có xác suất cao nhất. Hoạt động tương tự như nhiệt độ",
  "llm.prediction.topKSampling/info": "Từ tài liệu llama.cpp:\n\nLấy mẫu Top-k là phương pháp tạo văn bản chỉ chọn token tiếp theo từ top k token có khả năng xảy ra cao nhất được mô hình dự đoán.\n\nNó giúp giảm rủi ro tạo ra các token có xác suất thấp hoặc vô nghĩa, nhưng nó cũng có thể hạn chế sự đa dạng của đầu ra.\n\nGiá trị top-k cao hơn (ví dụ, 100) sẽ xem xét nhiều token hơn và dẫn đến văn bản đa dạng hơn, trong khi giá trị thấp hơn (ví dụ, 10) sẽ tập trung vào các token có khả năng xảy ra cao nhất và tạo ra văn bản thận trọng hơn.\n\n• Giá trị mặc định là <{{dynamicValue}}>",
  "llm.prediction.llama.cpuThreads/title": "Số luồng CPU",
  "llm.prediction.llama.cpuThreads/subTitle": "Số lượng luồng CPU sẽ sử dụng trong quá trình suy luận",
  "llm.prediction.llama.cpuThreads/info": "Số lượng luồng được sử dụng trong quá trình tính toán. Tăng số luồng không phải lúc nào cũng liên quan đến hiệu suất tốt hơn. Giá trị mặc định là <{{dynamicValue}}>.",
  "llm.prediction.maxPredictedTokens/title": "Giới hạn Độ dài Phản hồi",
  "llm.prediction.maxPredictedTokens/subTitle": "Tùy chọn giới hạn độ dài phản hồi của AI",
  "llm.prediction.maxPredictedTokens/info": "Kiểm soát độ dài tối đa của phản hồi chatbot. Bật để đặt giới hạn cho độ dài tối đa của phản hồi, hoặc tắt để chatbot tự quyết định khi nào dừng lại.",
  "llm.prediction.maxPredictedTokens/inputLabel": "Độ dài phản hồi tối đa (token)",
  "llm.prediction.maxPredictedTokens/wordEstimate": "Khoảng {{maxWords}} từ",
  "llm.prediction.repeatPenalty/title": "Phạt Lặp lại",
  "llm.prediction.repeatPenalty/subTitle": "Mức độ hạn chế lặp lại cùng một token",
  "llm.prediction.repeatPenalty/info": "Từ tài liệu llama.cpp: \"Giúp ngăn mô hình tạo ra văn bản lặp lại hoặc đơn điệu.\n\nGiá trị cao hơn (ví dụ, 1.5) sẽ phạt các lặp lại mạnh mẽ hơn, trong khi giá trị thấp hơn (ví dụ, 0.9) sẽ dễ dãi hơn.\" • Giá trị mặc định là <{{dynamicValue}}>",
  "llm.prediction.minPSampling/title": "Lấy mẫu Min P",
  "llm.prediction.minPSampling/subTitle": "Xác suất cơ sở tối thiểu để một token được chọn cho đầu ra",
  "llm.prediction.minPSampling/info": "Từ tài liệu llama.cpp:\n\nXác suất tối thiểu để một token được xem xét, so với xác suất của token có khả năng xảy ra cao nhất. Phải nằm trong khoảng [0, 1].\n\n• Giá trị mặc định là <{{dynamicValue}}>",
  "llm.prediction.topPSampling/title": "Lấy mẫu Top P",
  "llm.prediction.topPSampling/subTitle": "Xác suất tích lũy tối thiểu cho các token tiếp theo có thể. Hoạt động tương tự như nhiệt độ",
  "llm.prediction.topPSampling/info": "Từ tài liệu llama.cpp:\n\nLấy mẫu top-p, còn được gọi là lấy mẫu hạt nhân, là một phương pháp tạo văn bản khác chọn token tiếp theo từ một tập hợp token có xác suất cộng lại ít nhất là p.\n\nPhương pháp này cung cấp sự cân bằng giữa đa dạng và chất lượng bằng cách xem xét cả xác suất của các token và số lượng token để lấy mẫu.\n\nGiá trị top-p cao hơn (ví dụ, 0.95) sẽ dẫn đến văn bản đa dạng hơn, trong khi giá trị thấp hơn (ví dụ, 0.5) sẽ tạo ra văn bản tập trung và thận trọng hơn. Phải nằm trong khoảng (0, 1].\n\n• Giá trị mặc định là <{{dynamicValue}}>",
  "llm.prediction.stopStrings/title": "Chuỗi Dừng",
  "llm.prediction.stopStrings/subTitle": "Các chuỗi sẽ ngăn mô hình tạo thêm token",
  "llm.prediction.stopStrings/info": "Các chuỗi cụ thể khi gặp phải sẽ dừng mô hình tạo thêm token",
  "llm.prediction.stopStrings/placeholder": "Nhập chuỗi và nhấn ⏎",
  "llm.prediction.contextOverflowPolicy/title": "Tràn Bộ nhớ Hội thoại",
  "llm.prediction.contextOverflowPolicy/subTitle": "Cách mô hình xử lý khi cuộc trò chuyện trở nên quá lớn để nó xử lý",
  "llm.prediction.contextOverflowPolicy/info": "Quyết định việc làm gì khi cuộc hội thoại vượt quá kích thước bộ nhớ làm việc của mô hình ('ngữ cảnh')",
  "llm.prediction.llama.frequencyPenalty/title": "Phạt Tần suất",
  "llm.prediction.llama.presencePenalty/title": "Phạt Sự hiện diện",
  "llm.prediction.llama.tailFreeSampling/title": "Lấy mẫu Không Đuôi",
  "llm.prediction.llama.locallyTypicalSampling/title": "Lấy mẫu Điển hình Cục bộ",
  "llm.prediction.llama.xtcProbability/title": "Xác Suất Lấy Mẫu XTC",
  "llm.prediction.llama.xtcProbability/subTitle": "Bộ lấy mẫu XTC (Loại Bỏ Các Lựa Chọn Hàng Đầu) sẽ chỉ được kích hoạt với xác suất này cho mỗi token được tạo. Lấy mẫu XTC có thể tăng cường sự sáng tạo và giảm các cụm từ sáo rỗng",
  "llm.prediction.llama.xtcProbability/info": "Lấy mẫu XTC (Loại Bỏ Các Lựa Chọn Hàng Đầu) sẽ chỉ được kích hoạt với xác suất này, cho mỗi token được tạo. Lấy mẫu XTC thường tăng cường sự sáng tạo và giảm các cụm từ sáo rỗng",
  "llm.prediction.llama.xtcThreshold/title": "Ngưỡng Lấy Mẫu XTC",
  "llm.prediction.llama.xtcThreshold/subTitle": "Ngưỡng XTC (Loại Bỏ Các Lựa Chọn Hàng Đầu). Với cơ hội `xtc-probability`, tìm kiếm các token có xác suất nằm giữa `xtc-threshold` và 0.5, và loại bỏ tất cả các token đó trừ token có xác suất thấp nhất",
  "llm.prediction.llama.xtcThreshold/info": "Ngưỡng XTC (Loại Bỏ Các Lựa Chọn Hàng Đầu). Với cơ hội `xtc-probability`, tìm kiếm các token có xác suất nằm giữa `xtc-threshold` và 0.5, và loại bỏ tất cả các token đó trừ token có xác suất thấp nhất",
  "llm.prediction.mlx.topKSampling/title": "Lấy Mẫu Top K",
  "llm.prediction.mlx.topKSampling/subTitle": "Giới hạn token tiếp theo thành một trong k token có xác suất cao nhất. Hoạt động tương tự như nhiệt độ",
  "llm.prediction.mlx.topKSampling/info": "Giới hạn token tiếp theo thành một trong k token có xác suất cao nhất. Hoạt động tương tự như nhiệt độ",
  "llm.prediction.onnx.topKSampling/title": "Lấy mẫu Top K",
  "llm.prediction.onnx.topKSampling/subTitle": "Giới hạn token tiếp theo thành một trong k token có xác suất cao nhất. Hoạt động tương tự như nhiệt độ",
  "llm.prediction.onnx.topKSampling/info": "Từ tài liệu ONNX:\n\nSố lượng token có xác suất cao nhất được giữ lại để lọc top-k\n\n• Bộ lọc này mặc định tắt",
  "llm.prediction.onnx.repeatPenalty/title": "Phạt Lặp lại",
  "llm.prediction.onnx.repeatPenalty/subTitle": "Mức độ hạn chế lặp lại cùng một token",
  "llm.prediction.onnx.repeatPenalty/info": "Giá trị cao hơn làm cho mô hình ít lặp lại chính nó",
  "llm.prediction.onnx.topPSampling/title": "Lấy mẫu Top P",
  "llm.prediction.onnx.topPSampling/subTitle": "Xác suất tích lũy tối thiểu cho các token tiếp theo có thể. Hoạt động tương tự như nhiệt độ",
  "llm.prediction.onnx.topPSampling/info": "Từ tài liệu ONNX:\n\nChỉ giữ lại những token có xác suất cao nhất với tổng xác suất đạt TopP trở lên để sinh văn bản\n\n• Bộ lọc này mặc định tắt",
  "llm.prediction.seed/title": "Seed",
  "llm.prediction.structured/title": "Đầu ra có Cấu trúc",
  "llm.prediction.structured/info": "Đầu ra có Cấu trúc",
  "llm.prediction.structured/description": "Nâng cao: bạn có thể cung cấp [JSON Schema](https://json-schema.org/learn/miscellaneous-examples) để áp đặt một định dạng đầu ra cụ thể từ mô hình. Đọc [tài liệu](https://lmstudio.ai/docs/advanced/structured-output) để tìm hiểu thêm",
  "llm.prediction.tools/title": "Sử Dụng Công Cụ",
  "llm.prediction.tools/description": "Nâng cao: bạn có thể cung cấp một danh sách công cụ tuân thủ JSON để mô hình yêu cầu các cuộc gọi. Đọc [tài liệu](https://lmstudio.ai/docs/advanced/tool-use) để tìm hiểu thêm",
  "llm.prediction.tools/serverPageDescriptionAddon": "Truyền cái này qua phần thân yêu cầu dưới dạng `tools` khi sử dụng API máy chủ",
  "llm.prediction.promptTemplate/title": "Mẫu Prompt",
  "llm.prediction.promptTemplate/subTitle": "Định dạng tin nhắn trong cuộc trò chuyện được gửi đến mô hình. Việc thay đổi điều này có thể gây ra hành vi không mong muốn - hãy đảm bảo bạn biết mình đang làm gì!",
  "llm.prediction.speculativeDecoding.numDraftTokensExact/title": "Số Lượng Token Nháp Cần Tạo",
  "llm.prediction.speculativeDecoding.numDraftTokensExact/subTitle": "Số lượng token sẽ tạo bằng mô hình nháp cho mỗi token của mô hình chính. Tìm điểm tối ưu giữa tính toán và phần thưởng",
  "llm.prediction.speculativeDecoding.minContinueDraftingProbability/title": "Ngưỡng Xác Suất Nháp Tiếp Tục",
  "llm.prediction.speculativeDecoding.minContinueDraftingProbability/subTitle": "Tiếp tục soạn thảo cho đến khi xác suất của một token giảm xuống dưới ngưỡng này. Giá trị cao hơn thường có nghĩa là rủi ro thấp hơn, phần thưởng thấp hơn",
  "llm.prediction.speculativeDecoding.minDraftLengthToConsider/title": "Kích Thước Nháp Tối Thiểu",
  "llm.prediction.speculativeDecoding.minDraftLengthToConsider/subTitle": "Các bản nháp nhỏ hơn kích thước này sẽ bị mô hình chính bỏ qua. Giá trị cao hơn thường có nghĩa là rủi ro thấp hơn, phần thưởng thấp hơn",
  "llm.prediction.speculativeDecoding.maxTokensToDraft/title": "Kích Thước Nháp Tối Đa",
  "llm.prediction.speculativeDecoding.maxTokensToDraft/subTitle": "Số lượng token tối đa cho phép trong một bản nháp. Mức trần nếu tất cả các xác suất token > ngưỡng. Giá trị thấp hơn thường có nghĩa là rủi ro thấp hơn, phần thưởng thấp hơn",
  "llm.prediction.speculativeDecoding.draftModel/title": "Mô Hình Nháp",
  "llm.prediction.reasoning.parsing/title": "Phân Tích Phần Lý Luận",
  "llm.prediction.reasoning.parsing/subTitle": "Cách phân tích các phần lý luận trong đầu ra của mô hình",

  "llm.load.contextLength/title": "Độ dài Ngữ cảnh",
  "llm.load.contextLength/subTitle": "Số lượng token tối đa mà mô hình có thể xử lý trong một lời nhắc. Xem các tùy chọn Tràn Cuộc Trò Chuyện trong \"Tham số Suy Luận\" để biết thêm cách quản lý điều này",
  "llm.load.contextLength/info": "Chỉ định số lượng tối đa token mà mô hình có thể xem xét một lúc, ảnh hưởng đến mức độ ngữ cảnh mà nó giữ lại trong quá trình xử lý",
  "llm.load.contextLength/warning": "Đặt giá trị cao cho độ dài ngữ cảnh có thể ảnh hưởng đáng kể đến việc sử dụng bộ nhớ",
  "llm.load.seed/title": "Seed",
  "llm.load.seed/subTitle": "Hạt giống cho bộ tạo số ngẫu nhiên được sử dụng trong tạo văn bản. -1 là ngẫu nhiên",
  "llm.load.seed/info": "Seed ngẫu nhiên: Đặt giá trị seed để tạo số ngẫu nhiên nhằm đảm bảo kết quả có thể lặp lại",

  "llm.load.llama.evalBatchSize/title": "Kích thước Lô Đánh giá",
  "llm.load.llama.evalBatchSize/subTitle": "Số lượng token đầu vào được xử lý cùng một lúc. Tăng giá trị này sẽ cải thiện hiệu suất nhưng tốn bộ nhớ hơn",
  "llm.load.llama.evalBatchSize/info": "Đặt số lượng ví dụ được xử lý cùng lúc trong một lô trong quá trình đánh giá, ảnh hưởng đến tốc độ và sử dụng bộ nhớ",
  "llm.load.llama.ropeFrequencyBase/title": "Cơ sở Tần suất RoPE",
  "llm.load.llama.ropeFrequencyBase/subTitle": "Tần số cơ sở tùy chỉnh cho nhúng vị trí quay (RoPE). Tăng giá trị này có thể cho phép hiệu suất tốt hơn ở các độ dài ngữ cảnh cao",
  "llm.load.llama.ropeFrequencyBase/info": "[Nâng cao] Điều chỉnh tần số cơ bản cho Mã hóa Vị trí Quay, ảnh hưởng đến cách thông tin vị trí được nhúng",
  "llm.load.llama.ropeFrequencyScale/title": "Thang đo Tần suất RoPE",
  "llm.load.llama.ropeFrequencyScale/subTitle": "Độ dài ngữ cảnh được chia tỷ lệ theo hệ số này để mở rộng ngữ cảnh hiệu quả bằng cách sử dụng RoPE",
  "llm.load.llama.ropeFrequencyScale/info": "[Nâng cao] Điều chỉnh thang đo tần số cho Mã hóa Vị trí Quay để kiểm soát độ chi tiết mã hóa vị trí",
  "llm.load.llama.acceleration.offloadRatio/title": "Chuyển Tải GPU",
  "llm.load.llama.acceleration.offloadRatio/subTitle": "Số lượng lớp mô hình rời rạc để tính toán trên GPU để tăng tốc GPU",
  "llm.load.llama.acceleration.offloadRatio/info": "Đặt số lượng lớp sẽ chuyển tải sang GPU.",
  "llm.load.llama.flashAttention/title": "Tăng tốc Chú ý",
  "llm.load.llama.flashAttention/subTitle": "Giảm sử dụng bộ nhớ và thời gian tạo trên một số mô hình",
  "llm.load.llama.flashAttention/info": "Tăng tốc cơ chế chú ý để xử lý nhanh hơn và hiệu quả hơn",
  "llm.load.numExperts/title": "Số Lượng Chuyên Gia",
  "llm.load.numExperts/subTitle": "Số lượng chuyên gia sẽ sử dụng trong mô hình",
  "llm.load.numExperts/info": "Số lượng chuyên gia sẽ sử dụng trong mô hình",
  "llm.load.llama.keepModelInMemory/title": "Giữ Mô hình trong Bộ nhớ",
  "llm.load.llama.keepModelInMemory/subTitle": "Dự trữ bộ nhớ hệ thống cho mô hình, ngay cả khi đã chuyển sang GPU. Cải thiện hiệu suất nhưng yêu cầu nhiều RAM hệ thống hơn",
  "llm.load.llama.keepModelInMemory/info": "Ngăn mô hình khỏi bị hoán đổi ra đĩa, đảm bảo truy cập nhanh hơn với chi phí sử dụng RAM cao hơn",
  "llm.load.llama.useFp16ForKVCache/title": "Sử dụng FP16 cho Bộ nhớ Cache KV",
  "llm.load.llama.useFp16ForKVCache/info": "Giảm sử dụng bộ nhớ bằng cách lưu trữ bộ nhớ cache ở độ chính xác nửa (FP16)",
  "llm.load.llama.tryMmap/title": "Thử mmap()",
  "llm.load.llama.tryMmap/subTitle": "Cải thiện thời gian tải mô hình. Vô hiệu hóa tính năng này có thể cải thiện hiệu suất khi mô hình lớn hơn RAM hệ thống khả dụng",
  "llm.load.llama.tryMmap/info": "Tải tệp mô hình trực tiếp từ đĩa vào bộ nhớ",
  "llm.load.llama.cpuThreadPoolSize/title": "Kích Thước Nhóm Luồng CPU",
  "llm.load.llama.cpuThreadPoolSize/subTitle": "Số lượng luồng CPU sẽ cấp phát cho nhóm luồng được sử dụng để tính toán mô hình",
  "llm.load.llama.cpuThreadPoolSize/info": "Số lượng luồng CPU sẽ cấp phát cho nhóm luồng được sử dụng để tính toán mô hình. Việc tăng số lượng luồng không phải lúc nào cũng tương quan với hiệu suất tốt hơn. Mặc định là <{{dynamicValue}}>.",
  "llm.load.llama.kCacheQuantizationType/title": "Loại Lượng Tử Hóa Bộ Đệm K",
  "llm.load.llama.kCacheQuantizationType/subTitle": "Giá trị thấp hơn giảm sử dụng bộ nhớ nhưng có thể giảm chất lượng. Hiệu ứng thay đổi đáng kể giữa các mô hình.",
  "llm.load.llama.vCacheQuantizationType/title": "Loại Lượng Tử Hóa Bộ Đệm V",
  "llm.load.llama.vCacheQuantizationType/subTitle": "Giá trị thấp hơn giảm sử dụng bộ nhớ nhưng có thể giảm chất lượng. Hiệu ứng thay đổi đáng kể giữa các mô hình.",
  "llm.load.llama.vCacheQuantizationType/turnedOnWarning": "⚠️ Bạn phải tắt giá trị này nếu Tăng tốc Chú ý không được bật",
  "llm.load.llama.vCacheQuantizationType/disabledMessage": "Chỉ có thể bật khi Tăng tốc Chú ý được bật",
  "llm.load.llama.vCacheQuantizationType/invalidF32MetalState": "⚠️ Bạn phải tắt Tăng tốc Chú ý khi sử dụng F32",
  "llm.load.mlx.kvCacheBits/title": "Lượng Tử Hóa Bộ Đệm KV",
  "llm.load.mlx.kvCacheBits/subTitle": "Số bit mà bộ đệm KV nên được lượng tử hóa thành",
  "llm.load.mlx.kvCacheBits/info": "Số bit mà bộ đệm KV nên được lượng tử hóa thành",
  "llm.load.mlx.kvCacheBits/turnedOnWarning": "Cài đặt Độ Dài Ngữ Cảnh bị bỏ qua khi sử dụng Lượng Tử Hóa Bộ Đệm KV",
  "llm.load.mlx.kvCacheGroupSize/title": "Lượng Tử Hóa Bộ Đệm KV: Kích Thước Nhóm",
  "llm.load.mlx.kvCacheGroupSize/subTitle": "Kích thước nhóm trong quá trình lượng tử hóa cho bộ đệm KV. Kích thước nhóm lớn hơn giảm sử dụng bộ nhớ nhưng có thể giảm chất lượng",
  "llm.load.mlx.kvCacheGroupSize/info": "Số bit mà bộ đệm KV nên được lượng tử hóa thành",
  "llm.load.mlx.kvCacheQuantizationStart/title": "Lượng Tử Hóa Bộ Đệm KV: Bắt đầu lượng tử hóa khi ctx vượt quá độ dài này",
  "llm.load.mlx.kvCacheQuantizationStart/subTitle": "Ngưỡng độ dài ngữ cảnh để bắt đầu lượng tử hóa bộ đệm KV",
  "llm.load.mlx.kvCacheQuantizationStart/info": "Ngưỡng độ dài ngữ cảnh để bắt đầu lượng tử hóa bộ đệm KV",
  "llm.load.mlx.kvCacheQuantization/title": "Lượng Tử Hóa Bộ Đệm KV",
  "llm.load.mlx.kvCacheQuantization/subTitle": "Lượng tử hóa bộ đệm KV của mô hình. Điều này có thể dẫn đến việc tạo nhanh hơn và dấu chân bộ nhớ thấp hơn,\nvới chi phí chất lượng đầu ra của mô hình.",
  "llm.load.mlx.kvCacheQuantization/bits/title": "Bit lượng tử hóa bộ đệm KV",
  "llm.load.mlx.kvCacheQuantization/bits/tooltip": "Số bit để lượng tử hóa bộ đệm KV thành",
  "llm.load.mlx.kvCacheQuantization/bits/bits": "Bit",
  "llm.load.mlx.kvCacheQuantization/groupSize/title": "Chiến lược kích thước nhóm",
  "llm.load.mlx.kvCacheQuantization/groupSize/accuracy": "Độ chính xác",
  "llm.load.mlx.kvCacheQuantization/groupSize/balanced": "Cân bằng",
  "llm.load.mlx.kvCacheQuantization/groupSize/speedy": "Nhanh",
  "llm.load.mlx.kvCacheQuantization/groupSize/tooltip": "Nâng cao: Cấu hình 'kích thước nhóm matmul' đã lượng tử hóa\n\n• Độ chính xác = kích thước nhóm 32\n• Cân bằng = kích thước nhóm 64\n• Nhanh = kích thước nhóm 128\n",
  "llm.load.mlx.kvCacheQuantization/quantizedStart/title": "Bắt đầu lượng tử hóa khi ctx đạt đến độ dài này",
  "llm.load.mlx.kvCacheQuantization/quantizedStart/tooltip": "Khi ngữ cảnh đạt đến số lượng token này,\nbắt đầu lượng tử hóa bộ đệm KV",

  "embedding.load.contextLength/title": "Độ dài Ngữ cảnh",
  "embedding.load.contextLength/subTitle": "Số lượng token tối đa mà mô hình có thể xử lý trong một lời nhắc. Xem các tùy chọn Tràn Cuộc Trò Chuyện trong \"Tham số Suy Luận\" để biết thêm cách quản lý điều này",
  "embedding.load.contextLength/info": "Chỉ định số lượng tối đa token mà mô hình có thể xem xét một lúc, ảnh hưởng đến mức độ ngữ cảnh mà nó giữ lại trong quá trình xử lý",
  "embedding.load.llama.ropeFrequencyBase/title": "Cơ sở Tần suất RoPE",
  "embedding.load.llama.ropeFrequencyBase/subTitle": "Tần số cơ sở tùy chỉnh cho nhúng vị trí quay (RoPE). Tăng giá trị này có thể cho phép hiệu suất tốt hơn ở các độ dài ngữ cảnh cao",
  "embedding.load.llama.ropeFrequencyBase/info": "[Nâng cao] Điều chỉnh tần số cơ bản cho Mã hóa Vị trí Quay, ảnh hưởng đến cách thông tin vị trí được nhúng",
  "embedding.load.llama.evalBatchSize/title": "Kích thước Lô Đánh giá",
  "embedding.load.llama.evalBatchSize/subTitle": "Số lượng token đầu vào được xử lý cùng một lúc. Tăng giá trị này sẽ cải thiện hiệu suất nhưng tốn bộ nhớ hơn",
  "embedding.load.llama.evalBatchSize/info": "Đặt số lượng token được xử lý cùng lúc trong một lô trong quá trình đánh giá",
  "embedding.load.llama.ropeFrequencyScale/title": "Thang đo Tần suất RoPE",
  "embedding.load.llama.ropeFrequencyScale/subTitle": "Độ dài ngữ cảnh được chia tỷ lệ theo hệ số này để mở rộng ngữ cảnh hiệu quả bằng cách sử dụng RoPE",
  "embedding.load.llama.ropeFrequencyScale/info": "[Nâng cao] Điều chỉnh thang đo tần số cho Mã hóa Vị trí Quay để kiểm soát độ chi tiết mã hóa vị trí",
  "embedding.load.llama.acceleration.offloadRatio/title": "Chuyển Tải GPU",
  "embedding.load.llama.acceleration.offloadRatio/subTitle": "Số lượng lớp mô hình rời rạc để tính toán trên GPU để tăng tốc GPU",
  "embedding.load.llama.acceleration.offloadRatio/info": "Đặt số lượng lớp sẽ chuyển tải sang GPU.",
  "embedding.load.llama.keepModelInMemory/title": "Giữ Mô hình trong Bộ nhớ",
  "embedding.load.llama.keepModelInMemory/subTitle": "Dự trữ bộ nhớ hệ thống cho mô hình, ngay cả khi đã chuyển sang GPU. Cải thiện hiệu suất nhưng yêu cầu nhiều RAM hệ thống hơn",
  "embedding.load.llama.keepModelInMemory/info": "Ngăn mô hình khỏi bị hoán đổi ra đĩa, đảm bảo truy cập nhanh hơn với chi phí sử dụng RAM cao hơn",
  "embedding.load.llama.tryMmap/title": "Thử mmap()",
  "embedding.load.llama.tryMmap/subTitle": "Cải thiện thời gian tải mô hình. Tắt tính năng này có thể cải thiện hiệu suất khi mô hình lớn hơn RAM hệ thống khả dụng",
  "embedding.load.llama.tryMmap/info": "Tải tệp mô hình trực tiếp từ đĩa vào bộ nhớ",
  "embedding.load.seed/title": "Seed",
  "embedding.load.seed/subTitle": "Hạt giống cho bộ tạo số ngẫu nhiên được sử dụng trong tạo văn bản. -1 là hạt giống ngẫu nhiên",

  "embedding.load.seed/info": "Seed ngẫu nhiên: Đặt giá trị seed để tạo số ngẫu nhiên để đảm bảo kết quả có thể lặp lại",

  "presetTooltip": {
    "included/title": "Giá Trị Đặt Trước",
    "included/description": "Các trường sau sẽ được áp dụng",
    "included/empty": "Không có trường nào của cài đặt trước này áp dụng trong ngữ cảnh này.",
    "included/conflict": "Bạn sẽ được yêu cầu chọn xem có áp dụng giá trị này không",
    "separateLoad/title": "Cấu Hình Thời Gian Tải",
    "separateLoad/description.1": "Cài đặt trước cũng bao gồm cấu hình thời gian tải sau. Cấu hình thời gian tải là toàn mô hình và yêu cầu tải lại mô hình để có hiệu lực. Giữ",
    "separateLoad/description.2": "để áp dụng cho",
    "separateLoad/description.3": ".",
    "excluded/title": "Có thể không áp dụng",
    "excluded/description": "Các trường sau được bao gồm trong cài đặt trước nhưng không áp dụng trong ngữ cảnh hiện tại.",
    "legacy/title": "Cài Đặt Trước Cũ",
    "legacy/description": "Cài đặt trước này là một cài đặt trước cũ. Nó bao gồm các trường sau hiện đã được xử lý tự động hoặc không còn áp dụng.",
    "button/publish": "Xuất Bản Lên Hub",
    "button/pushUpdate": "Đẩy Thay Đổi Lên Hub",
    "button/export": "Xuất"
  },

  "customInputs": {
    "string": {
      "emptyParagraph": "<Trống>"
    },
    "checkboxNumeric": {
      "off": "TẮT"
    },
    "llamaCacheQuantizationType": {
      "off": "TẮT"
    },
    "mlxKvCacheBits": {
      "off": "TẮT"
    },
    "stringArray": {
      "empty": "<Trống>"
    },
    "llmPromptTemplate": {
      "type": "Loại",
      "types.jinja/label": "Mẫu (Jinja)",
      "jinja.bosToken/label": "Token BOS",
      "jinja.eosToken/label": "Token EOS",
      "jinja.template/label": "Mẫu",
      "jinja/error": "Không thể phân tích mẫu Jinja: {{error}}",
      "jinja/empty": "Vui lòng nhập mẫu Jinja bên trên.",
      "jinja/unlikelyToWork": "Mẫu Jinja bạn cung cấp ở trên khó có thể hoạt động vì nó không tham chiếu biến \"messages\". Vui lòng kiểm tra lại xem bạn đã nhập đúng mẫu chưa.",
      "types.manual/label": "Thủ Công",
      "manual.subfield.beforeSystem/label": "Trước Hệ Thống",
      "manual.subfield.beforeSystem/placeholder": "Nhập tiền tố Hệ Thống...",
      "manual.subfield.afterSystem/label": "Sau Hệ Thống",
      "manual.subfield.afterSystem/placeholder": "Nhập hậu tố Hệ Thống...",
      "manual.subfield.beforeUser/label": "Trước Người Dùng",
      "manual.subfield.beforeUser/placeholder": "Nhập tiền tố Người Dùng...",
      "manual.subfield.afterUser/label": "Sau Người Dùng",
      "manual.subfield.afterUser/placeholder": "Nhập hậu tố Người Dùng...",
      "manual.subfield.beforeAssistant/label": "Trước Trợ Lý",
      "manual.subfield.beforeAssistant/placeholder": "Nhập tiền tố Trợ Lý...",
      "manual.subfield.afterAssistant/label": "Sau Trợ Lý",
      "manual.subfield.afterAssistant/placeholder": "Nhập hậu tố Trợ Lý...",
      "stopStrings/label": "Chuỗi Dừng Bổ Sung",
      "stopStrings/subTitle": "Các chuỗi dừng cụ thể của mẫu sẽ được sử dụng ngoài các chuỗi dừng do người dùng chỉ định."
    },
    "contextLength": {
      "maxValueTooltip": "Đây là số lượng token tối đa mà mô hình được huấn luyện để xử lý. Nhấn để đặt ngữ cảnh thành giá trị này",
      "maxValueTextStart": "Mô hình hỗ trợ lên đến",
      "maxValueTextEnd": "token",
      "tooltipHint": "Mặc dù một mô hình có thể hỗ trợ đến một số lượng token nhất định, hiệu suất có thể giảm sút nếu tài nguyên máy của bạn không thể xử lý tải - hãy cẩn thận khi tăng giá trị này"
    },
    "contextOverflowPolicy": {
      "stopAtLimit": "Dừng ở Giới Hạn",
      "stopAtLimitSub": "Dừng tạo khi bộ nhớ của mô hình đầy",
      "truncateMiddle": "Cắt Giữa",
      "truncateMiddleSub": "Xóa tin nhắn từ giữa cuộc trò chuyện để tạo chỗ cho các tin nhắn mới hơn. Mô hình vẫn sẽ nhớ phần đầu cuộc trò chuyện",
      "rollingWindow": "Cửa Sổ Trượt",
      "rollingWindowSub": "Mô hình sẽ luôn nhận được vài tin nhắn gần đây nhất nhưng có thể quên phần đầu cuộc trò chuyện"
    },
    "llamaAccelerationOffloadRatio": {
      "max": "TỐI ĐA",
      "off": "TẮT"
    },
    "llamaAccelerationSplitStrategy": {
      "evenly": "Đều",
      "favorMainGpu": "Ưu Tiên GPU Chính"
    },
    "speculativeDecodingDraftModel": {
      "readMore": "Đọc cách hoạt động",
      "placeholder": "Chọn một mô hình nháp tương thích",
      "noCompatible": "Không tìm thấy mô hình nháp tương thích với lựa chọn mô hình hiện tại của bạn",
      "stillLoading": "Đang xác định các mô hình nháp tương thích...",
      "notCompatible": "Mô hình nháp đã chọn (<draft/>) không tương thích với lựa chọn mô hình hiện tại (<current/>).",
      "off": "TẮT",
      "loadModelToSeeOptions": "Tải mô hình <keyboard-shortcut /> để xem các tùy chọn tương thích",
      "compatibleWithNumberOfModels": "Được khuyến nghị cho ít nhất {{dynamicValue}} mô hình của bạn",
      "recommendedForSomeModels": "Được khuyến nghị cho một số mô hình",
      "recommendedForLlamaModels": "Được khuyến nghị cho các mô hình Llama",
      "recommendedForQwenModels": "Được khuyến nghị cho các mô hình Qwen",
      "onboardingModal": {
        "introducing": "Giới thiệu",
        "speculativeDecoding": "Giải Mã Suy Đoán",
        "firstStepBody": "Tăng tốc suy luận cho các mô hình <custom-span>llama.cpp</custom-span> và <custom-span>MLX</custom-span>",
        "secondStepTitle": "Tăng Tốc Suy Luận Với Giải Mã Suy Đoán",
        "secondStepBody": "Giải Mã Suy Đoán là một kỹ thuật liên quan đến sự hợp tác của hai mô hình:\n - Một mô hình \"chính\" lớn hơn\n - Một mô hình \"nháp\" nhỏ hơn\n\nTrong quá trình tạo, mô hình nháp nhanh chóng đề xuất các token để mô hình chính lớn hơn xác minh. Việc xác minh các token là một quá trình nhanh hơn nhiều so với việc thực sự tạo ra chúng, đây là nguồn gốc của việc tăng tốc. **Nói chung, sự khác biệt về kích thước giữa mô hình chính và mô hình nháp càng lớn thì tốc độ càng tăng cao**.\n\nĐể duy trì chất lượng, mô hình chính chỉ chấp nhận các token phù hợp với những gì nó tự tạo ra, cho phép chất lượng phản hồi của mô hình lớn hơn với tốc độ suy luận nhanh hơn. Cả hai mô hình phải có cùng một từ vựng.",
        "draftModelRecommendationsTitle": "Đề xuất mô hình nháp",
        "basedOnCurrentModels": "Dựa trên các mô hình hiện tại của bạn",
        "close": "Đóng",
        "next": "Tiếp theo",
        "done": "Hoàn thành"
      },
      "speculativeDecodingLoadModelToSeeOptions": "Vui lòng tải một mô hình trước <model-badge /> ",
      "errorEngineNotSupported": "Giải mã suy đoán yêu cầu phiên bản {{minVersion}} trở lên của engine {{engineName}}. Vui lòng cập nhật engine (<key/>) và tải lại mô hình để sử dụng tính năng này.",
      "errorEngineNotSupported/noKey": "Giải mã suy đoán yêu cầu phiên bản {{minVersion}} trở lên của engine {{engineName}}. Vui lòng cập nhật engine và tải lại mô hình để sử dụng tính năng này."
    },
    "llmReasoningParsing": {
      "startString/label": "Chuỗi Bắt Đầu",
      "startString/placeholder": "Nhập chuỗi bắt đầu...",
      "endString/label": "Chuỗi Kết Thúc",
      "endString/placeholder": "Nhập chuỗi kết thúc..."
    }
  },
  "saveConflictResolution": {
    "title": "Chọn giá trị để đưa vào Đặt Trước",
    "description": "Chọn và lựa chọn giá trị để giữ lại",
    "instructions": "Nhấn vào một giá trị để đưa vào",
    "userValues": "Giá Trị Trước Đó",
    "presetValues": "Giá Trị Mới",
    "confirm": "Xác Nhận",
    "cancel": "Hủy"
  },
  "applyConflictResolution": {
    "title": "Giữ giá trị nào?",
    "description": "Bạn có các thay đổi chưa được cam kết trùng lặp với Cài Đặt Trước sắp tới",
    "instructions": "Nhấn vào một giá trị để giữ lại",
    "userValues": "Giá Trị Hiện Tại",
    "presetValues": "Giá Trị Đặt Trước Sắp Tới",
    "confirm": "Xác Nhận",
    "cancel": "Hủy"
  },
  "empty": "<Trống>",
  "noModelSelected": "Chưa chọn mô hình nào",
  "apiIdentifier.label": "Mã Định Danh API",
  "apiIdentifier.hint": "Tùy chọn cung cấp một mã định danh cho mô hình này. Mã này sẽ được sử dụng trong các yêu cầu API. Để trống để sử dụng mã định danh mặc định.",
  "idleTTL.label": "Tự Động Dỡ Tải Nếu Rảnh (TTL)",
  "idleTTL.hint": "Nếu được đặt, mô hình sẽ tự động được dỡ tải sau khi không hoạt động trong khoảng thời gian đã chỉ định.",
  "idleTTL.mins": "phút",

  "presets": {
    "title": "Cài Đặt Trước",
    "commitChanges": "Lưu Thay Đổi",
    "commitChanges/description": "Lưu các thay đổi của bạn vào cài đặt trước.",
    "commitChanges.manual": "Đã phát hiện trường mới. Bạn sẽ có thể chọn những thay đổi nào sẽ đưa vào cài đặt trước.",
    "commitChanges.manual.hold.0": "Giữ",
    "commitChanges.manual.hold.1": "để chọn những thay đổi nào sẽ lưu vào cài đặt trước.",
    "commitChanges.saveAll.hold.0": "Giữ",
    "commitChanges.saveAll.hold.1": "để lưu tất cả thay đổi.",
    "commitChanges.saveInPreset.hold.0": "Giữ",
    "commitChanges.saveInPreset.hold.1": "để chỉ lưu các thay đổi vào các trường đã có trong cài đặt trước.",
    "commitChanges/error": "Không thể lưu thay đổi vào cài đặt trước.",
    "commitChanges.manual/description": "Chọn những thay đổi nào sẽ đưa vào cài đặt trước.",
    "saveAs": "Lưu Thành Mới...",
    "presetNamePlaceholder": "Nhập tên cho cài đặt trước...",
    "cannotCommitChangesLegacy": "Đây là cài đặt trước cũ và không thể sửa đổi. Bạn có thể tạo bản sao bằng cách sử dụng \"Lưu Thành Mới...\".",
    "cannotCommitChangesNoChanges": "Không có thay đổi nào để lưu.",
    "emptyNoUnsaved": "Chọn một cài đặt trước...",
    "emptyWithUnsaved": "Cài Đặt Trước Chưa Lưu",
    "saveEmptyWithUnsaved": "Lưu Cài Đặt Trước Thành...",
    "saveConfirm": "Lưu",
    "saveCancel": "Hủy",
    "saving": "Đang lưu...",
    "save/error": "Không thể lưu cài đặt trước.",
    "deselect": "Bỏ Chọn Cài Đặt Trước",
    "deselect/error": "Không thể bỏ chọn cài đặt trước.",
    "select/error": "Không thể chọn cài đặt trước.",
    "delete/error": "Không thể xóa cài đặt trước.",
    "discardChanges": "Hủy Bỏ Thay Đổi Chưa Lưu",
    "discardChanges/info": "Hủy bỏ tất cả các thay đổi chưa được cam kết và khôi phục cài đặt trước về trạng thái ban đầu",
    "newEmptyPreset": "+ Cài Đặt Trước Mới",
    "importPreset": "Nhập",
    "contextMenuSelect": "Áp Dụng Cài Đặt Trước",
    "contextMenuDelete": "Xóa...",
    "contextMenuShare": "Xuất Bản...",
    "contextMenuOpenInHub": "Xem trên Hub",
    "contextMenuPushChanges": "Đẩy thay đổi lên Hub",
    "contextMenuPushingChanges": "Đang đẩy...",
    "contextMenuPushedChanges": "Đã đẩy thay đổi",
    "contextMenuExport": "Xuất Tệp",
    "contextMenuRevealInExplorer": "Hiện trong File Explorer",
    "contextMenuRevealInFinder": "Hiện trong Finder",
    "share": {
      "title": "Xuất Bản Cài Đặt Trước",
      "action": "Chia sẻ cài đặt trước của bạn để người khác tải xuống, thích và phân nhánh",
      "presetOwnerLabel": "Chủ sở hữu",
      "uploadAs": "Cài đặt trước của bạn sẽ được tạo thành {{name}}",
      "presetNameLabel": "Tên Cài Đặt Trước",
      "descriptionLabel": "Mô Tả (tùy chọn)",
      "loading": "Đang xuất bản...",
      "success": "Đã Đẩy Cài Đặt Trước Thành Công",
      "presetIsLive": "<preset-name /> hiện đã có trên Hub!",
      "close": "Đóng",
      "confirmViewOnWeb": "Xem trên web",
      "confirmCopy": "Sao chép URL",
      "confirmCopied": "Đã sao chép!",
      "pushedToHub": "Cài đặt trước của bạn đã được đẩy lên Hub",
      "descriptionPlaceholder": "Nhập mô tả...",
      "willBePublic": "Việc xuất bản cài đặt trước của bạn sẽ khiến nó trở thành công khai",
      "publicSubtitle": "Cài đặt trước của bạn là <custom-bold>Công khai</custom-bold>. Những người khác có thể tải xuống và phân nhánh nó trên lmstudio.ai",
      "confirmShareButton": "Xuất Bản",
      "error": "Không thể xuất bản cài đặt trước",
      "createFreeAccount": "Tạo tài khoản miễn phí trong Hub để xuất bản cài đặt trước"
    },
    "update": {
      "title": "Đẩy Thay Đổi Lên Hub",
      "title/success": "Đã Cập Nhật Cài Đặt Trước Thành Công",
      "subtitle": "Thay đổi <custom-preset-name /> và đẩy chúng lên Hub",
      "descriptionLabel": "Mô Tả",
      "descriptionPlaceholder": "Nhập mô tả...",
      "loading": "Đang đẩy...",
      "cancel": "Hủy",
      "createFreeAccount": "Tạo tài khoản miễn phí trong Hub để xuất bản cài đặt trước",
      "error": "Không thể đẩy cập nhật",
      "confirmUpdateButton": "Đẩy"
    },
    "import": {
      "title": "Nhập Cài Đặt Trước Từ Tệp",
      "dragPrompt": "Kéo và thả tệp JSON cài đặt trước hoặc <custom-link>chọn từ máy tính của bạn</custom-link>",
      "remove": "Xóa",
      "cancel": "Hủy",
      "importPreset_zero": "Nhập Cài Đặt Trước",
      "importPreset_one": "Nhập Cài Đặt Trước",
      "importPreset_other": "Nhập {{count}} Cài Đặt Trước",
      "selectDialog": {
        "title": "Chọn Tệp Cài Đặt Trước (.json)",
        "button": "Nhập"
      },
      "error": "Không thể nhập cài đặt trước",
      "resultsModal": {
        "titleSuccessSection_one": "Đã nhập thành công 1 cài đặt trước",
        "titleSuccessSection_other": "Đã nhập thành công {{count}} cài đặt trước",
        "titleFailSection_zero": "",
        "titleFailSection_one": "({{count}} thất bại)",
        "titleFailSection_other": "({{count}} thất bại)",
        "titleAllFailed": "Không thể nhập cài đặt trước",
        "importMore": "Nhập Thêm",
        "close": "Hoàn Thành",
        "successBadge": "Thành Công",
        "alreadyExistsBadge": "Cài đặt trước đã tồn tại",
        "errorBadge": "Lỗi",
        "invalidFileBadge": "Tệp không hợp lệ",
        "otherErrorBadge": "Không thể nhập cài đặt trước",
        "errorViewDetailsButton": "Xem Chi Tiết",
        "seeError": "Xem Lỗi",
        "noName": "Không có tên cài đặt trước",
        "useInChat": "Sử dụng trong Trò Chuyện"
      },
      "importFromUrl": {
        "button": "Nhập từ URL...",
        "title": "Nhập từ URL",
        "back": "Nhập từ Tệp...",
        "action": "Dán URL LM Studio Hub của cài đặt trước bạn muốn nhập bên dưới",
        "invalidUrl": "URL không hợp lệ. Vui lòng đảm bảo bạn đang dán đúng URL LM Studio Hub.",
        "tip": "Bạn có thể cài đặt cài đặt trước trực tiếp bằng nút {{buttonName}} trong LM Studio Hub",
        "confirm": "Nhập",
        "cancel": "Hủy",
        "loading": "Đang nhập...",
        "error": "Không thể tải xuống cài đặt trước."
      }
    },
    "download": {
      "title": "Tải <preset-name /> từ LM Studio Hub",
      "subtitle": "Lưu <custom-name /> vào các cài đặt trước của bạn. Làm như vậy bạn sẽ có thể sử dụng cài đặt trước này trong ứng dụng",
      "button": "Tải",
      "button/loading": "Đang tải...",
      "cancel": "Hủy",
      "error": "Không thể tải xuống cài đặt trước."
    },
    "inclusiveness": {
      "speculativeDecoding": "Bao gồm trong Cài Đặt Trước"
    }
  },

  "flashAttentionWarning": "Tăng Tốc Chú Ý là một tính năng thử nghiệm có thể gây ra sự cố với một số mô hình. Nếu bạn gặp sự cố, hãy thử tắt nó đi.",
  "llamaKvCacheQuantizationWarning": "Lượng Tử Hóa Bộ Đệm KV là một tính năng thử nghiệm có thể gây ra sự cố với một số mô hình. Tăng Tốc Chú Ý phải được bật để lượng tử hóa bộ đệm V. Nếu bạn gặp sự cố, hãy đặt lại về mặc định \"F16\".",

  "seedUncheckedHint": "Hạt Giống Ngẫu Nhiên",
  "ropeFrequencyBaseUncheckedHint": "Tự động",
  "ropeFrequencyScaleUncheckedHint": "Tự động",

  "hardware": {
    "advancedGpuSettings": "Cài Đặt GPU Nâng Cao",
    "advancedGpuSettings.info": "Nếu bạn không chắc chắn, hãy để chúng ở giá trị mặc định",
    "advancedGpuSettings.reset": "Đặt lại về mặc định",
    "environmentVariables": {
      "title": "Biến Môi Trường",
      "description": "Các biến môi trường hoạt động trong suốt thời gian tồn tại của mô hình.",
      "key.placeholder": "Chọn biến...",
      "value.placeholder": "Giá trị"
    },
    "mainGpu": {
      "title": "GPU Chính",
      "description": "GPU được ưu tiên cho việc tính toán mô hình.",
      "placeholder": "Chọn GPU chính..."
    },
    "splitStrategy": {
      "title": "Chiến Lược Chia Tách",
      "description": "Cách chia tách tính toán mô hình trên các GPU.",
      "placeholder": "Chọn chiến lược chia tách..."
    }
  }
}
