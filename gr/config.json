{
  "noInstanceSelected": "Δεν έχει επιλεγεί κάποιο μοντέλο",
  "resetToDefault": "Επαναφορά",
  "showAdvancedSettings": "Εμφάνιση προχωρημένων ρυθμίσεων",
  "showAll": "Εμφάνιση όλων",
  "basicSettings": "Βασικά",
  "configSubtitle": "Φορτώστε ή αποθηκεύστε προεπιλογές και πειραματιστείτε με παρακάμψεις παραμέτρων μοντέλου",
  "inferenceParameters/title": "Παράμετροι προβλέψεων",
  "inferenceParameters/info": "Πειραματιστείτε με παραμέτρους που επηρεάζουν την πρόβλεψη.",
  "generalParameters/title": "Γενικά",
  "samplingParameters/title": "Δειγματοληψία",
  "basicTab": "Βασικά",
  "advancedTab": "Προχωρημένα",
  "advancedTab/title": "🧪 Προχωρημένη Διαμόρφωση",
  "advancedTab/expandAll": "Ανάπτυξη όλων",
  "advancedTab/overridesTitle": "Παρακάμψεις Ρυθμίσεων",
  "advancedTab/noConfigsText": "Δεν έχετε μη αποθηκευμένες αλλαγές - επεξεργαστείτε τις παραπάνω τιμές για να δείτε τις παρακάμψεις εδώ.",
  "loadInstanceFirst": "Φορτώστε ένα μοντέλο για να δείτε τις παραμέτρους που μπορούν να ρυθμιστούν",
  "noListedConfigs": "Δεν υπάρχουν παραμετροποιήσιμες ρυθμίσεις",
  "generationParameters/info": "Πειραματιστείτε με βασικές παραμέτρους που επηρεάζουν τη δημιουργία κειμένου.",
  "loadParameters/title": "Παράμετροι φόρτωσης",
  "loadParameters/description": "Η αλλαγή αυτών των παραμέτρων απαιτεί επαναφόρτωση του μοντέλου",
  "loadParameters/reload": "Επαναφόρτωση για την εφαρμογή αλλαγών στις παραμέτρους φόρτωσης",
  "loadParameters/reload/error": "Αποτυχία επαναφόρτωσης του μοντέλου",
  "discardChanges": "Απόρριψη αλλαγών",
  "loadModelToSeeOptions": "Φορτώστε ένα μοντέλο για να δείτε τις επιλογές",
  "schematicsError.title": "Τα σχήματα διαμόρφωσης περιέχουν σφάλματα στα ακόλουθα πεδία:",
  "manifestSections": {
    "structuredOutput/title": "Δομημένη Έξοδος",
    "speculativeDecoding/title": "Εικονική Αποκωδικοποίηση",
    "sampling/title": "Δειγματοληψία",
    "settings/title": "Ρυθμίσεις",
    "toolUse/title": "Χρήση Εργαλείων",
    "promptTemplate/title": "Πρότυπο Prompt",
    "customFields/title": "Προσαρμοσμένα Πεδία"
  },
  
  "llm.prediction.systemPrompt/title": "Prompt Συστήματος",
  "llm.prediction.systemPrompt/description": "Χρησιμοποιήστε αυτό το πεδίο για να παρέχετε οδηγίες παρασκηνίου στο μοντέλο, όπως ένα σύνολο κανόνων, περιορισμών ή γενικών απαιτήσεων.",
  "llm.prediction.systemPrompt/subTitle": "Οδηγίες για την τεχνητή νοημοσύνη",
  "llm.prediction.systemPrompt/openEditor": "Editor",
  "llm.prediction.systemPrompt/closeEditor": "Κλείσιμο Editor",
  "llm.prediction.systemPrompt/openedEditor": "Άνοιξε στον Editor...",
  "llm.prediction.systemPrompt/edit": "Επεξεργασία Prompt Συστήματος...",
  "llm.prediction.systemPrompt/addInstructionsWithMore": "Προσθήκη οδηγιών...",
  "llm.prediction.systemPrompt/addInstructions": "Προσθήκη οδηγιών",
  "llm.prediction.temperature/title": "Θερμοκρασία",
  "llm.prediction.temperature/subTitle": "Πόση τυχαιότητα να εισαχθεί. 0 θα δώσει πάντα το ίδιο αποτέλεσμα, ενώ υψηλότερες τιμές αυξάνουν τη δημιουργικότητα και την ποικιλία.",
  "llm.prediction.temperature/info": "Από τα έγγραφα βοήθειας του llama.cpp: \"Η προεπιλεγμένη τιμή είναι <{{dynamicValue}}>, η οποία παρέχει ισορροπία μεταξύ τυχαιότητας και ντετερμινισμού. Στο άκρο, μια θερμοκρασία 0 θα επιλέγει πάντα το πιο πιθανό επόμενο token, οδηγώντας σε ίδιες εξόδους κάθε φορά.\"",
  "llm.prediction.llama.sampling/title": "Δειγματοληψία",
  "llm.prediction.topKSampling/title": "Κορυφαία K Δειγματοληψία",
  "llm.prediction.topKSampling/subTitle": "Περιορίζει την επιλογή του επόμενου token σε ένα από τα top-k πιο πιθανά tokens. Λειτουργεί παρόμοια με τη θερμοκρασία.",
  "llm.prediction.topKSampling/info": "Από τα έγγραφα βοήθειας του llama.cpp:\n\nΗ Top-k δειγματοληψία είναι μια μέθοδος παραγωγής κειμένου που επιλέγει το επόμενο token μόνο από τα top k πιο πιθανά tokens που προβλέπει το μοντέλο.\n\nΒοηθά στη μείωση του κινδύνου παραγωγής ασυνάρτητων ή χαμηλής πιθανότητας tokens, αλλά μπορεί επίσης να περιορίσει την ποικιλία του κειμένου.\n\nΜια υψηλότερη τιμή για το top-k (π.χ. 100) θα εξετάσει περισσότερα tokens και θα δώσει πιο ποικίλο κείμενο, ενώ μια χαμηλότερη τιμή (π.χ. 10) θα επικεντρωθεί στα πιο πιθανά tokens και θα παράγει πιο συντηρητικό κείμενο.\n\n• Η προεπιλεγμένη τιμή είναι <{{dynamicValue}}>",
  "llm.prediction.llama.cpuThreads/title": "Νήματα CPU",
  "llm.prediction.llama.cpuThreads/subTitle": "Αριθμός νημάτων CPU για χρήση κατά την εκτέλεση",
  "llm.prediction.llama.cpuThreads/info": "Ο αριθμός νημάτων που θα χρησιμοποιηθούν για τον υπολογισμό. Η αύξηση των νημάτων δεν οδηγεί πάντα σε καλύτερη απόδοση. Η προεπιλεγμένη τιμή είναι <{{dynamicValue}}>.",
  "llm.prediction.maxPredictedTokens/title": "Όριο Μήκους Απάντησης",
  "llm.prediction.maxPredictedTokens/subTitle": "Προαιρετικά περιορίστε το μήκος της απάντησης του AI",
  "llm.prediction.maxPredictedTokens/info": "Ελέγξτε το μέγιστο μήκος της απάντησης του chatbot. Ενεργοποιήστε για να ορίσετε όριο ή απενεργοποιήστε για να αποφασίζει το chatbot πότε να σταματήσει.",
  "llm.prediction.maxPredictedTokens/inputLabel": "Μέγιστο μήκος απάντησης (tokens)",
  "llm.prediction.maxPredictedTokens/wordEstimate": "Περίπου {{maxWords}} λέξεις", 
  "llm.prediction.repeatPenalty/title": "Ποινή Επανάληψης",
  "llm.prediction.repeatPenalty/subTitle": "Πόσο να αποθαρρύνεται η επανάληψη του ίδιου token",
  "llm.prediction.repeatPenalty/info": "Από τα έγγραφα βοήθειας του llama.cpp: \"Βοηθά στην αποτροπή δημιουργίας επαναλαμβανόμενου ή μονότονου κειμένου.\n\nΜια υψηλότερη τιμή (π.χ. 1.5) θα τιμωρήσει τις επαναλήψεις πιο έντονα, ενώ μια χαμηλότερη τιμή (π.χ. 0.9) θα είναι πιο επιεικής.\" • Η προεπιλεγμένη τιμή είναι <{{dynamicValue}}>",
  "llm.prediction.minPSampling/title": "Ελάχιστη P Δειγματοληψία",
  "llm.prediction.minPSampling/subTitle": "Ελάχιστη βασική πιθανότητα για να επιλεγεί ένα token για έξοδο",
  "llm.prediction.minPSampling/info": "Από τα έγγραφα βοήθειας του llama.cpp:\n\nΗ ελάχιστη πιθανότητα για να θεωρηθεί ένα token, σε σχέση με την πιθανότητα του πιο πιθανού token. Πρέπει να είναι μεταξύ [0, 1].\n\n• Η προεπιλεγμένη τιμή είναι <{{dynamicValue}}>",
  "llm.prediction.topPSampling/title": "Top P Δειγματοληψία",
  "llm.prediction.topPSampling/subTitle": "Ελάχιστη σωρευτική πιθανότητα για τα πιθανά επόμενα tokens. Λειτουργεί παρόμοια με τη θερμοκρασία",
  "llm.prediction.topPSampling/info": "Από τα έγγραφα βοήθειας του llama.cpp:\n\nΗ Top-p δειγματοληψία, επίσης γνωστή ως nucleus sampling, είναι μια μέθοδος παραγωγής κειμένου που επιλέγει το επόμενο token από ένα υποσύνολο tokens που μαζί έχουν σωρευτική πιθανότητα τουλάχιστον p.\n\nΑυτή η μέθοδος παρέχει ισορροπία μεταξύ ποικιλίας και ποιότητας, λαμβάνοντας υπόψη τόσο τις πιθανότητες των tokens όσο και τον αριθμό των tokens από τα οποία επιλέγεται.\n\nΜια υψηλότερη τιμή για το top-p (π.χ. 0.95) θα οδηγήσει σε πιο ποικίλο κείμενο, ενώ μια χαμηλότερη τιμή (π.χ. 0.5) θα παράγει πιο συγκεντρωμένο και συντηρητικό κείμενο. Πρέπει να είναι εντός (0, 1].\n\n• Η προεπιλεγμένη τιμή είναι <{{dynamicValue}}>",
  "llm.prediction.stopStrings/title": "Συμβολοσειρές Τερματισμού",
  "llm.prediction.stopStrings/subTitle": "Συμβολοσειρές που θα σταματήσουν το μοντέλο από την παραγωγή περισσότερων tokens",
  "llm.prediction.stopStrings/info": "Συγκεκριμένες συμβολοσειρές που, όταν εμφανιστούν, θα σταματήσουν το μοντέλο από το να παράγει περισσότερα tokens",
  "llm.prediction.stopStrings/placeholder": "Εισάγετε μια συμβολοσειρά και πατήστε ⏎",
  "llm.prediction.contextOverflowPolicy/title": "Υπερχείλιση Πλαισίου Συμφραζομένων",
  "llm.prediction.contextOverflowPolicy/subTitle": "Πώς πρέπει να συμπεριφέρεται το μοντέλο όταν η συνομιλία μεγαλώνει πολύ για να τη χειριστεί",
  "llm.prediction.contextOverflowPolicy/info": "Αποφασίστε τι να γίνει όταν η συνομιλία ξεπεράσει το μέγεθος της μνήμης εργασίας του μοντέλου ('context')",
  "llm.prediction.llama.frequencyPenalty/title": "Ποινή Συχνότητας",
  "llm.prediction.llama.presencePenalty/title": "Ποινή Παρουσίας",
  "llm.prediction.llama.tailFreeSampling/title": "Tail-Free Δειγματοληψία",
  "llm.prediction.llama.locallyTypicalSampling/title": "Τοπικά Τυπική Δειγματοληψία",
  "llm.prediction.llama.xtcProbability/title": "Πιθανότητα XTC Δειγματοληψίας",
  "llm.prediction.llama.xtcProbability/subTitle": "Ο sampler XTC (Exclude Top Choices) ενεργοποιείται μόνο με αυτή την πιθανότητα ανά token. Η XTC δειγματοληψία μπορεί να ενισχύσει τη δημιουργικότητα και να μειώσει τα κλισέ",
  "llm.prediction.llama.xtcProbability/info": "Η XTC (Exclude Top Choices) δειγματοληψία ενεργοποιείται μόνο με αυτή την πιθανότητα ανά παραγόμενο token. Συνήθως ενισχύει τη δημιουργικότητα και μειώνει τα κλισέ",
  "llm.prediction.llama.xtcThreshold/title": "Κατώφλι XTC Δειγματοληψίας",
  "llm.prediction.llama.xtcThreshold/subTitle": "Κατώφλι XTC (Exclude Top Choices). Με πιθανότητα `xtc-probability`, αναζητά tokens με πιθανότητες μεταξύ `xtc-threshold` και 0.5, και αφαιρεί όλα εκτός από το λιγότερο πιθανό",
  "llm.prediction.llama.xtcThreshold/info": "Κατώφλι XTC (Exclude Top Choices). Με πιθανότητα `xtc-probability`, αναζητά tokens με πιθανότητες μεταξύ `xtc-threshold` και 0.5, και αφαιρεί όλα εκτός από το λιγότερο πιθανό",
  "llm.prediction.mlx.topKSampling/title": "Top K Δειγματοληψία",
  "llm.prediction.mlx.topKSampling/subTitle": "Περιορίζει το επόμενο token σε ένα από τα top-k πιο πιθανά tokens. Λειτουργεί παρόμοια με τη θερμοκρασία",
  "llm.prediction.mlx.topKSampling/info": "Περιορίζει το επόμενο token σε ένα από τα top-k πιο πιθανά tokens. Λειτουργεί παρόμοια με τη θερμοκρασία",
  "llm.prediction.onnx.topKSampling/title": "Top K Δειγματοληψία",
  "llm.prediction.onnx.topKSampling/subTitle": "Περιορίζει το επόμενο token σε ένα από τα top-k πιο πιθανά tokens. Λειτουργεί παρόμοια με τη θερμοκρασία",
  "llm.prediction.onnx.topKSampling/info": "Από τα έγγραφα ONNX:\n\nΑριθμός tokens με την υψηλότερη πιθανότητα που διατηρούνται για top-k φίλτρο\n\n• Αυτό το φίλτρο είναι απενεργοποιημένο από προεπιλογή",
  "llm.prediction.onnx.repeatPenalty/title": "Ποινή Επανάληψης",
  "llm.prediction.onnx.repeatPenalty/subTitle": "Πόσο να αποθαρρύνεται η επανάληψη του ίδιου token",
  "llm.prediction.onnx.repeatPenalty/info": "Μια υψηλότερη τιμή αποθαρρύνει το μοντέλο από το να επαναλαμβάνεται",
  "llm.prediction.onnx.topPSampling/title": "Top P Δειγματοληψία",
  "llm.prediction.onnx.topPSampling/subTitle": "Ελάχιστη σωρευτική πιθανότητα για τα πιθανά επόμενα tokens. Λειτουργεί παρόμοια με τη θερμοκρασία",
  "llm.prediction.onnx.topPSampling/info": "Από τα έγγραφα ONNX:\n\nΜόνο τα πιο πιθανά tokens που μαζί έχουν πιθανότητα >= TopP διατηρούνται για παραγωγή\n\n• Αυτό το φίλτρο είναι απενεργοποιημένο από προεπιλογή",
  "llm.prediction.seed/title": "Σπόρος (Seed)",
  "llm.prediction.structured/title": "Δομημένη Έξοδος",
  "llm.prediction.structured/info": "Δομημένη Έξοδος",
  "llm.prediction.structured/description": "Για προχωρημένους: μπορείτε να παρέχετε ένα [JSON Schema](https://json-schema.org/learn/miscellaneous-examples) για να επιβάλετε συγκεκριμένη μορφή εξόδου από το μοντέλο. Διαβάστε την [τεκμηρίωση](https://lmstudio.ai/docs/advanced/structured-output) για περισσότερα",
  "llm.prediction.tools/title": "Χρήση Εργαλείων",
  "llm.prediction.tools/description": "Για προχωρημένους: μπορείτε να παρέχετε μια συμβατή με JSON λίστα εργαλείων για να ζητά το μοντέλο κλήσεις. Διαβάστε την [τεκμηρίωση](https://lmstudio.ai/docs/advanced/tool-use) για περισσότερα",
  "llm.prediction.tools/serverPageDescriptionAddon": "Περάστε αυτό στο request body ως `tools` όταν χρησιμοποιείτε το server API",
  "llm.prediction.promptTemplate/title": "Πρότυπο Prompt",
  "llm.prediction.promptTemplate/subTitle": "Η μορφή με την οποία στέλνονται τα μηνύματα στο μοντέλο. Η αλλαγή μπορεί να προκαλέσει απρόβλεπτη συμπεριφορά - βεβαιωθείτε ότι ξέρετε τι κάνετε!",
  "llm.prediction.speculativeDecoding.numDraftTokensExact/title": "Tokens Προσχεδίου για Παραγωγή",
  "llm.prediction.speculativeDecoding.numDraftTokensExact/subTitle": "Αριθμός tokens που παράγονται από το draft μοντέλο ανά token του κύριου μοντέλου. Βρείτε τη σωστή ισορροπία υπολογισμού και ανταμοιβής",
  "llm.prediction.speculativeDecoding.minContinueDraftingProbability/title": "Κατώφλι Πιθανότητας Συνέχισης Σχεδίου",
  "llm.prediction.speculativeDecoding.minContinueDraftingProbability/subTitle": "Συνεχίστε το σχέδιο μέχρι η πιθανότητα ενός token να πέσει κάτω από αυτό το όριο. Υψηλότερες τιμές συνήθως σημαίνουν χαμηλότερο ρίσκο, χαμηλότερη ανταμοιβή",
  "llm.prediction.speculativeDecoding.minDraftLengthToConsider/title": "Ελάχιστο Μέγεθος Προσχεδίου",
  "llm.prediction.speculativeDecoding.minDraftLengthToConsider/subTitle": "Προσχέδια μικρότερα από αυτό αγνοούνται από το κύριο μοντέλο. Υψηλότερες τιμές συνήθως σημαίνουν χαμηλότερο ρίσκο, χαμηλότερη ανταμοιβή",
  "llm.prediction.speculativeDecoding.maxTokensToDraft/title": "Μέγιστο Μέγεθος Προσχεδίου",
  "llm.prediction.speculativeDecoding.maxTokensToDraft/subTitle": "Μέγιστος αριθμός tokens που επιτρέπεται σε ένα προσχέδιο. Όριο εάν όλες οι πιθανότητες tokens είναι > κατώφλι. Χαμηλότερες τιμές συνήθως σημαίνουν χαμηλότερο ρίσκο, χαμηλότερη ανταμοιβή",
  "llm.prediction.speculativeDecoding.draftModel/title": "Μοντέλο Προσχεδίου",
  "llm.prediction.reasoning.parsing/title": "Ανάλυση Τμήματος Λογικής",
  "llm.prediction.reasoning.parsing/subTitle": "Πώς να αναλυθούν τμήματα λογικής στην έξοδο του μοντέλου",

"llm.load.mainGpu/title": "Κύρια GPU",
  "llm.load.mainGpu/subTitle": "Η GPU που θα δοθεί προτεραιότητα για τον υπολογισμό του μοντέλου",
  "llm.load.mainGpu/placeholder": "Επιλέξτε κύρια GPU...",
  "llm.load.splitStrategy/title": "Στρατηγική Διαχωρισμού",
  "llm.load.splitStrategy/subTitle": "Πώς να διαχωριστεί ο υπολογισμός του μοντέλου σε πολλές GPUs",
  "llm.load.splitStrategy/placeholder": "Επιλέξτε στρατηγική διαχωρισμού...",
  "llm.load.offloadKVCacheToGpu/title": "Μεταφορά KV Cache στη Μνήμη GPU",
  "llm.load.offloadKVCacheToGpu/subTitle": "Μεταφέρει την KV cache στη μνήμη GPU. Βελτιώνει την απόδοση αλλά απαιτεί περισσότερη μνήμη GPU",
  "load.gpuStrictVramCap/title": "Περιορισμός Μεταφοράς Μοντέλου στη Μνήμη Αφιερωμένης GPU",
  "load.gpuStrictVramCap.customSubTitleOff": "OFF: Επιτρέπεται τα βάρη μοντέλα να μεταφορτωθούν στην κοινόχρηστη μνήμη εάν η αφιερωμένη μνήμη GPU είναι πλήρης",
  "load.gpuStrictVramCap.customSubTitleOn": "ON: Το σύστημα θα περιορίσει τη μεταφόρτωση των βαρών του μοντέλου μόνο στην αποκλειστική μνήμη GPU και στη μνήμη RAM. Το περιβάλλον μπορεί να εξακολουθεί να χρησιμοποιεί κοινόχρηστη μνήμη",
  "load.gpuStrictVramCap.customGpuOffloadWarning": "Η μεταφορά του μοντέλου περιορίζεται στη μνήμη αφιερωμένης GPU. Ο πραγματικός αριθμός των μεταφερόμενων layers μπορεί να διαφέρει",
  "load.allGpusDisabledWarning": "Όλες οι GPUs είναι επί του παρόντος απενεργοποιημένες. Ενεργοποιήστε τουλάχιστον μία για μεταφορά",

  "llm.load.contextLength/title": "Μήκος Συμφραζομένων",
  "llm.load.contextLength/subTitle": "Ο μέγιστος αριθμός tokens που μπορεί να λάβει υπόψη το μοντέλο σε ένα prompt. Δείτε τις επιλογές Διαχείρισης Συμφραζομένων κάτω από \"Παράμετροι inference\" για περισσότερους τρόπους ελέγχου",
  "llm.load.contextLength/info": "Καθορίζει τον μέγιστο αριθμό tokens που μπορεί να εξετάσει το μοντέλο ταυτόχρονα, επηρεάζοντας πόσο context διατηρεί κατά την επεξεργασία",
  "llm.load.contextLength/warning": "Η ρύθμιση υψηλής τιμής για το μήκος συμφραζομένων μπορεί να επηρεάσει σημαντικά τη χρήση μνήμης",
  "llm.load.seed/title": "Seed",
  "llm.load.seed/subTitle": "Το seed για τον γεννήτορα τυχαίων αριθμών που χρησιμοποιείται στην παραγωγή κειμένου. -1 σημαίνει τυχαίο",
  "llm.load.seed/info": "Τυχαίο Seed: Καθορίζει το seed για τη δημιουργία τυχαίων αριθμών ώστε τα αποτελέσματα να είναι αναπαραγώγιμα",
  "llm.load.numCpuExpertLayersRatio/title": "Αναγκαστική Τοποθέτηση Expert Weights στο CPU",
  "llm.load.numCpuExpertLayersRatio/subTitle": "Αν θα τοποθετηθούν τα MoE expert weights στη RAM του CPU. Εξοικονομεί VRAM και μπορεί να είναι ταχύτερο από μερική μεταφορά σε GPU. Δεν συνιστάται αν το μοντέλο χωράει ολόκληρο στη VRAM.",
  "llm.load.numCpuExpertLayersRatio/info": "Καθορίζει αν όλα τα MoE expert layers θα τοποθετηθούν στη RAM του CPU. Τα attention layers παραμένουν στην GPU, εξοικονομώντας VRAM ενώ η inference παραμένει σχετικά γρήγορη",

  "llm.load.llama.evalBatchSize/title": "Μέγεθος Batch Αξιολόγησης",
  "llm.load.llama.evalBatchSize/subTitle": "Αριθμός tokens εισόδου που επεξεργάζονται ταυτόχρονα. Η αύξηση βελτιώνει την απόδοση με κόστος τη χρήση μνήμης",
  "llm.load.llama.evalBatchSize/info": "Καθορίζει τον αριθμό παραδειγμάτων που επεξεργάζονται μαζί σε ένα batch κατά την αξιολόγηση, επηρεάζοντας την ταχύτητα και τη χρήση μνήμης",
  "llm.load.llama.ropeFrequencyBase/title": "Βασική Συχνότητα RoPE",
  "llm.load.llama.ropeFrequencyBase/subTitle": "Προσαρμοσμένη βασική συχνότητα για τα Rotary Positional Embeddings (RoPE). Η αύξηση μπορεί να βελτιώσει την απόδοση σε μεγάλα context lengths",
  "llm.load.llama.ropeFrequencyBase/info": "[Για προχωρημένους] Προσαρμόζει τη βασική συχνότητα του Rotary Positional Encoding, επηρεάζοντας τον τρόπο ενσωμάτωσης της θέσης",
  "llm.load.llama.ropeFrequencyScale/title": "Κλίμακα Συχνότητας RoPE",
  "llm.load.llama.ropeFrequencyScale/subTitle": "Το μήκος συμφραζομένων κλιμακώνεται με αυτόν τον συντελεστή για επέκταση του αποτελεσματικού context μέσω RoPE",
  "llm.load.llama.ropeFrequencyScale/info": "[Για προχωρημένους] Τροποποιεί την κλίμακα συχνότητας του Rotary Positional Encoding για έλεγχο της λεπτομέρειας της κωδικοποίησης θέσης",
  "llm.load.llama.acceleration.offloadRatio/title": "Μεταφορά Υπολογισμών σε GPU",
  "llm.load.llama.acceleration.offloadRatio/subTitle": "Αριθμός διακριτών layers του μοντέλου που υπολογίζονται στη GPU για επιτάχυνση",
  "llm.load.llama.acceleration.offloadRatio/info": "Ορίστε τον αριθμό layers που θα μεταφερθούν στη GPU",
  "llm.load.llama.flashAttention/title": "Flash Attention",
  "llm.load.llama.flashAttention/subTitle": "Μειώνει τη χρήση μνήμης και τον χρόνο παραγωγής σε ορισμένα μοντέλα",
  "llm.load.llama.flashAttention/info": "Επιταχύνει τους μηχανισμούς attention για ταχύτερη και αποδοτικότερη επεξεργασία",
  "llm.load.numExperts/title": "Αριθμός Experts",
  "llm.load.numExperts/subTitle": "Αριθμός experts που θα χρησιμοποιηθούν στο μοντέλο",
  "llm.load.numExperts/info": "Ο αριθμός experts που θα χρησιμοποιηθούν στο μοντέλο",
  "llm.load.llama.keepModelInMemory/title": "Διατήρηση Μοντέλου στη Μνήμη",
  "llm.load.llama.keepModelInMemory/subTitle": "Δεσμεύει μνήμη συστήματος για το μοντέλο, ακόμη και όταν μεταφέρεται στη GPU. Βελτιώνει την απόδοση αλλά απαιτεί περισσότερη RAM",
  "llm.load.llama.keepModelInMemory/info": "Αποτρέπει τη μεταφορά του μοντέλου στον δίσκο, εξασφαλίζοντας ταχύτερη πρόσβαση με κόστος αυξημένη χρήση RAM",
  "llm.load.llama.useFp16ForKVCache/title": "Χρήση FP16 για KV Cache",
  "llm.load.llama.useFp16ForKVCache/info": "Μειώνει τη χρήση μνήμης αποθηκεύοντας την cache σε half-precision (FP16)",
  "llm.load.llama.tryMmap/title": "Χρήση mmap()",
  "llm.load.llama.tryMmap/subTitle": "Βελτιώνει τον χρόνο φόρτωσης του μοντέλου. Η απενεργοποίηση μπορεί να βελτιώσει την απόδοση όταν το μοντέλο είναι μεγαλύτερο από τη διαθέσιμη RAM",
  "llm.load.llama.tryMmap/info": "Φορτώνει τα αρχεία του μοντέλου απευθείας από τον δίσκο στη μνήμη",
  "llm.load.llama.cpuThreadPoolSize/title": "Μέγεθος Thread Pool CPU",
  "llm.load.llama.cpuThreadPoolSize/subTitle": "Αριθμός νημάτων CPU που δεσμεύονται στο thread pool για υπολογισμούς του μοντέλου",
  "llm.load.llama.cpuThreadPoolSize/info": "Ο αριθμός νημάτων CPU που δεσμεύονται στο thread pool για τον υπολογισμό του μοντέλου. Η αύξηση των νημάτων δεν συνεπάγεται πάντα καλύτερη απόδοση. Η προεπιλογή είναι <{{dynamicValue}}>.",
  "llm.load.llama.kCacheQuantizationType/title": "Τύπος Ποσοτικοποίησης K Cache",
  "llm.load.llama.kCacheQuantizationType/subTitle": "Χαμηλότερες τιμές μειώνουν τη χρήση μνήμης αλλά μπορεί να μειώσουν την ποιότητα. Το αποτέλεσμα διαφέρει σημαντικά ανά μοντέλο",
  "llm.load.llama.vCacheQuantizationType/title": "Τύπος Ποσοτικοποίησης V Cache",
  "llm.load.llama.vCacheQuantizationType/subTitle": "Χαμηλότερες τιμές μειώνουν τη χρήση μνήμης αλλά μπορεί να μειώσουν την ποιότητα. Το αποτέλεσμα διαφέρει σημαντικά ανά μοντέλο",
  "llm.load.llama.vCacheQuantizationType/turnedOnWarning": "⚠️ Πρέπει να απενεργοποιήσετε αυτή την επιλογή αν το Flash Attention δεν είναι ενεργό",
  "llm.load.llama.vCacheQuantizationType/disabledMessage": "Μπορεί να ενεργοποιηθεί μόνο όταν το Flash Attention είναι ενεργό",
  "llm.load.llama.vCacheQuantizationType/invalidF32MetalState": "⚠️ Πρέπει να απενεργοποιήσετε το Flash Attention όταν χρησιμοποιείτε F32",
  "llm.load.mlx.kvCacheBits/title": "Ποσοτικοποίηση KV Cache",
  "llm.load.mlx.kvCacheBits/subTitle": "Αριθμός bits στα οποία θα ποσοτικοποιηθεί η KV cache",
  "llm.load.mlx.kvCacheBits/info": "Αριθμός bits στα οποία θα ποσοτικοποιηθεί η KV cache",
  "llm.load.mlx.kvCacheBits/turnedOnWarning": "Η ρύθμιση Μήκους Συμφραζομένων αγνοείται όταν χρησιμοποιείται ποσοτικοποίηση KV Cache",
  "llm.load.mlx.kvCacheGroupSize/title": "Ποσοτικοποίηση KV Cache: Μέγεθος Ομάδας",
  "llm.load.mlx.kvCacheGroupSize/subTitle": "Μέγεθος ομάδας κατά την ποσοτικοποίηση της KV cache. Μεγαλύτερο μέγεθος ομάδας μειώνει τη χρήση μνήμης αλλά μπορεί να μειώσει την ποιότητα",
  "llm.load.mlx.kvCacheGroupSize/info": "Μέγεθος ομάδας για την ποσοτικοποίηση της KV cache",
  "llm.load.mlx.kvCacheQuantizationStart/title": "Ποσοτικοποίηση KV Cache: Έναρξη",
  "llm.load.mlx.kvCacheQuantizationStart/subTitle": "Όριο μήκους context για την έναρξη ποσοτικοποίησης της KV cache",
  "llm.load.mlx.kvCacheQuantizationStart/info": "Όριο μήκους context για την έναρξη ποσοτικοποίησης της KV cache",
  "llm.load.mlx.kvCacheQuantization/title": "Ποσοτικοποίηση KV Cache",
  "llm.load.mlx.kvCacheQuantization/subTitle": "Ποσοτικοποιεί την KV cache του μοντέλου. Μπορεί να οδηγήσει σε ταχύτερη παραγωγή και μικρότερη χρήση μνήμης,\nμε κόστος την ποιότητα της εξόδου",
  "llm.load.mlx.kvCacheQuantization/bits/title": "Bits Ποσοτικοποίησης KV Cache",
  "llm.load.mlx.kvCacheQuantization/bits/tooltip": "Αριθμός bits για την ποσοτικοποίηση της KV cache",
  "llm.load.mlx.kvCacheQuantization/bits/bits": "Bits",
  "llm.load.mlx.kvCacheQuantization/groupSize/title": "Στρατηγική Μεγέθους Ομάδας",
  "llm.load.mlx.kvCacheQuantization/groupSize/accuracy": "Ακρίβεια",
  "llm.load.mlx.kvCacheQuantization/groupSize/balanced": "Ισορροπημένο",
  "llm.load.mlx.kvCacheQuantization/groupSize/speedy": "Γρήγορο",
  "llm.load.mlx.kvCacheQuantization/groupSize/tooltip": "Για προχωρημένους: Ρύθμιση 'matmul group size' για ποσοτικοποίηση\n\n• Ακρίβεια = μέγεθος ομάδας 32\n• Ισορροπημένο = μέγεθος ομάδας 64\n• Γρήγορο = μέγεθος ομάδας 128\n",
  "llm.load.mlx.kvCacheQuantization/quantizedStart/title": "Έναρξη ποσοτικοποίησης όταν το context φτάσει αυτό το μήκος",
  "llm.load.mlx.kvCacheQuantization/quantizedStart/tooltip": "Όταν το context φτάσει αυτόν τον αριθμό tokens,\nξεκινά η ποσοτικοποίηση της KV cache",

  "embedding.load.contextLength/title": "Μήκος Συμφραζομένων",
  "embedding.load.contextLength/subTitle": "Ο μέγιστος αριθμός tokens που μπορεί να λάβει υπόψη το μοντέλο σε ένα prompt. Δείτε τις επιλογές Υπερχείλισης Συνομιλίας στις «Παραμέτρους inference» για περισσότερους τρόπους διαχείρισης",
  "embedding.load.contextLength/info": "Καθορίζει τον μέγιστο αριθμό tokens που μπορεί να εξετάσει το μοντέλο ταυτόχρονα, επηρεάζοντας πόσο context διατηρεί κατά την επεξεργασία",
  "embedding.load.llama.ropeFrequencyBase/title": "Βασική Συχνότητα RoPE",
  "embedding.load.llama.ropeFrequencyBase/subTitle": "Προσαρμοσμένη βασική συχνότητα για τα Rotary Positional Embeddings (RoPE). Η αύξηση μπορεί να βελτιώσει την απόδοση σε μεγάλα μήκη context",
  "embedding.load.llama.ropeFrequencyBase/info": "[Για προχωρημένους] Προσαρμόζει τη βασική συχνότητα του Rotary Positional Encoding, επηρεάζοντας τον τρόπο ενσωμάτωσης της θέσης",
  "embedding.load.llama.evalBatchSize/title": "Μέγεθος Batch Αξιολόγησης",
  "embedding.load.llama.evalBatchSize/subTitle": "Αριθμός tokens εισόδου που επεξεργάζονται ταυτόχρονα. Η αύξηση βελτιώνει την απόδοση με κόστος τη χρήση μνήμης",
  "embedding.load.llama.evalBatchSize/info": "Καθορίζει τον αριθμό tokens που επεξεργάζονται μαζί σε ένα batch κατά την αξιολόγηση",
  "embedding.load.llama.ropeFrequencyScale/title": "Κλίμακα Συχνότητας RoPE",
  "embedding.load.llama.ropeFrequencyScale/subTitle": "Το μήκος context κλιμακώνεται με αυτόν τον συντελεστή για επέκταση του αποτελεσματικού context μέσω RoPE",
  "embedding.load.llama.ropeFrequencyScale/info": "[Για προχωρημένους] Τροποποιεί την κλίμακα συχνότητας του Rotary Positional Encoding για έλεγχο της λεπτομέρειας της κωδικοποίησης θέσης",
  "embedding.load.llama.acceleration.offloadRatio/title": "Μεταφορά Υπολογισμών σε GPU",
  "embedding.load.llama.acceleration.offloadRatio/subTitle": "Αριθμός διακριτών layers του μοντέλου που υπολογίζονται στη GPU για επιτάχυνση",
  "embedding.load.llama.acceleration.offloadRatio/info": "Ορίστε τον αριθμό layers που θα μεταφερθούν στη GPU",
  "embedding.load.llama.keepModelInMemory/title": "Διατήρηση Μοντέλου στη Μνήμη",
  "embedding.load.llama.keepModelInMemory/subTitle": "Δεσμεύει μνήμη συστήματος για το μοντέλο, ακόμη και όταν μεταφέρεται στη GPU. Βελτιώνει την απόδοση αλλά απαιτεί περισσότερη RAM",
  "embedding.load.llama.keepModelInMemory/info": "Αποτρέπει τη μεταφορά του μοντέλου στον δίσκο, εξασφαλίζοντας ταχύτερη πρόσβαση με κόστος αυξημένη χρήση RAM",
  "embedding.load.llama.tryMmap/title": "Χρήση mmap()",
  "embedding.load.llama.tryMmap/subTitle": "Βελτιώνει τον χρόνο φόρτωσης του μοντέλου. Η απενεργοποίηση μπορεί να βελτιώσει την απόδοση όταν το μοντέλο είναι μεγαλύτερο από τη διαθέσιμη RAM",
  "embedding.load.llama.tryMmap/info": "Φορτώνει τα αρχεία του μοντέλου απευθείας από τον δίσκο στη μνήμη",
  "embedding.load.seed/title": "Σπόρος (Seed)",
  "embedding.load.seed/subTitle": "Το seed για τον γεννήτορα τυχαίων αριθμών που χρησιμοποιείται στην παραγωγή κειμένου. -1 σημαίνει τυχαίο seed",

  "embedding.load.seed/info": "Τυχαίο Seed: Καθορίζει το seed για τη δημιουργία τυχαίων αριθμών, ώστε να διασφαλίζονται αναπαραγώγιμα αποτελέσματα",

  "presetTooltip": {
    "included/title": "Τιμές Προεπιλογής",
    "included/description": "Τα ακόλουθα πεδία θα εφαρμοστούν",
    "included/empty": "Κανένα πεδίο αυτής της προεπιλογής δεν εφαρμόζεται σε αυτό το πλαίσιο.",
    "included/conflict": "Θα σας ζητηθεί να επιλέξετε εάν θα εφαρμόσετε αυτή την τιμή",
    "separateLoad/title": "Διαμόρφωση Χρόνου Φόρτωσης",
    "separateLoad/description.1": "Η προεπιλογή περιλαμβάνει επίσης την ακόλουθη διαμόρφωση χρόνου φόρτωσης. Οι διαμορφώσεις χρόνου φόρτωσης είναι καθολικές για το μοντέλο και απαιτούν επαναφόρτωση του μοντέλου για να τεθούν σε ισχύ. Κρατήστε",
    "separateLoad/description.2": "για να εφαρμόσετε στο",
    "separateLoad/description.3": ".",
    "excluded/title": "Ενδέχεται να μην εφαρμοστούν",
    "excluded/description": "Τα ακόλουθα πεδία περιλαμβάνονται στην προεπιλογή αλλά δεν εφαρμόζονται στο τρέχον πλαίσιο.",
    "legacy/title": "Προεπιλογή Κληρονομιάς",
    "legacy/description": "Αυτή η προεπιλογή είναι προεπιλογή κληρονομιάς. Περιλαμβάνει τα ακόλουθα πεδία τα οποία είτε χειρίζονται αυτόματα τώρα, είτε δεν είναι πλέον εφαρμόσιμα.",
    "button/publish": "Δημοσίευση στο Hub",
    "button/pushUpdate": "Αποστολή Αλλαγών στο Hub",
    "button/noChangesToPush": "Δεν υπάρχουν αλλαγές για αποστολή",
    "button/export": "Εξαγωγή",
    "hubLabel": "Προεπιλογή από το Hub από {{user}}",
    "ownHubLabel": "Η προεπιλογή σας από το Hub"
  },

  "customInputs": {
    "string": {
      "emptyParagraph": "<Empty>"
    },
    "checkboxNumeric": {
      "off": "OFF"
    },
    "llamaCacheQuantizationType": {
      "off": "OFF"
    },
    "mlxKvCacheBits": {
      "off": "OFF"
    },
    "stringArray": {
      "empty": "<Empty>"
    },
    "llmPromptTemplate": {
      "type": "Τύπος",
      "types.jinja/label": "Πρότυπο (Jinja)",
      "jinja.bosToken/label": "BOS Token",
      "jinja.eosToken/label": "EOS Token",
      "jinja.template/label": "Πρότυπο",
      "jinja/error": "Αποτυχία ανάλυσης προτύπου Jinja: {{error}}",
      "jinja/empty": "Παρακαλώ εισάγετε ένα πρότυπο Jinja παραπάνω.",
      "jinja/unlikelyToWork": "Το πρότυπο Jinja που παρείχατε παραπάνω είναι απίθανο να λειτουργήσει καθώς δεν αναφέρεται στη μεταβλητή \"messages\". Παρακαλώ ελέγξτε ξανά εάν έχετε εισάγει ένα σωστό πρότυπο.",
      "types.manual/label": "Χειροκίνητο",
      "manual.subfield.beforeSystem/label": "Πριν το Σύστημα",
      "manual.subfield.beforeSystem/placeholder": "Εισάγετε πρόθεμα Συστήματος...",
      "manual.subfield.afterSystem/label": "Μετά το Σύστημα",
      "manual.subfield.afterSystem/placeholder": "Εισάγετε επίθεμα Συστήματος...",
      "manual.subfield.beforeUser/label": "Πριν τον Χρήστη",
      "manual.subfield.beforeUser/placeholder": "Εισάγετε πρόθεμα Χρήστη...",
      "manual.subfield.afterUser/label": "Μετά τον Χρήστη",
      "manual.subfield.afterUser/placeholder": "Εισάγετε επίθεμα Χρήστη...",
      "manual.subfield.beforeAssistant/label": "Πριν τον Βοηθό",
      "manual.subfield.beforeAssistant/placeholder": "Εισάγετε πρόθεμα Βοηθού...",
      "manual.subfield.afterAssistant/label": "Μετά τον Βοηθό",
      "manual.subfield.afterAssistant/placeholder": "Εισάγετε επίθεμα Βοηθού...",
      "stopStrings/label": "Επιπλέον Συμβολοσειρές Τερματισμού",
      "stopStrings/subTitle": "Συμβολοσειρές τερματισμού ειδικές για το πρότυπο που θα χρησιμοποιηθούν επιπλέον των συμβολοσειρών τερματισμού που καθορίζονται από τον χρήστη."
    },
    "contextLength": {
      "maxValueTooltip": "Αυτό είναι το μέγιστο αριθμός tokens που εκπαιδεύτηκε το μοντέλο να χειρίζεται. Κάντε κλικ για να ορίσετε το context σε αυτή την τιμή",
      "maxValueTextStart": "Το μοντέλο υποστηρίζει μέχρι",
      "maxValueTextEnd": "tokens",
      "tooltipHint": "Ενώ ένα μοντέλο μπορεί να υποστηρίζει μέχρι έναν ορισμένο αριθμό tokens, η απόδοση μπορεί να επιδεινωθεί εάν οι πόροι του μηχανήματός σας δεν μπορούν να χειριστούν το φορτίο - χρησιμοποιήστε προσοχή κατά την αύξηση αυτής της τιμής"
    },
    "contextOverflowPolicy": {
      "stopAtLimit": "Σταμάτα στο Όριο",
      "stopAtLimitSub": "Σταμάτα τη δημιουργία μόλις η μνήμη του μοντέλου γεμίσει",
      "truncateMiddle": "Αποκοπή Μέσης",
      "truncateMiddleSub": "Αφαιρεί μηνύματα από τη μέση της συνομιλίας για να κάνει χώρο για νεότερα. Το μοντέλο θα θυμάται ακόμα την αρχή της συνομιλίας",
      "rollingWindow": "Κυλιόμενο Παράθυρο",
      "rollingWindowSub": "Το μοντέλο θα λαμβάνει πάντα τα πιο πρόσφατα μηνύματα αλλά μπορεί να ξεχάσει την αρχή της συνομιλίας"
    },
    "llamaAccelerationOffloadRatio": {
      "max": "MAX",
      "off": "OFF"
    },
    "gpuSplitStrategy": {
      "evenly": "Ομοιόμορφα",
      "favorMainGpu": "Προτίμηση Κύριας GPU"
    },
    "speculativeDecodingDraftModel": {
      "readMore": "Διαβάστε πώς λειτουργεί",
      "placeholder": "Επιλέξτε ένα συμβατό μοντέλο draft",
      "noCompatible": "Δεν βρέθηκαν συμβατά μοντέλα draft για την τρέχουσα επιλογή μοντέλου σας",
      "stillLoading": "Αναγνώριση συμβατών μοντέλων draft...",
      "notCompatible": "Το επιλεγμένο μοντέλο draft (<draft/>) δεν είναι συμβατό με την τρέχουσα επιλογή μοντέλου (<current/>).",
      "off": "OFF",
      "loadModelToSeeOptions": "Φορτώστε το μοντέλο <keyboard-shortcut /> για να δείτε συμβατές επιλογές",
      "compatibleWithNumberOfModels": "Συνιστάται για τουλάχιστον {{dynamicValue}} από τα μοντέλα σας",
      "recommendedForSomeModels": "Συνιστάται για ορισμένα μοντέλα",
      "recommendedForLlamaModels": "Συνιστάται για μοντέλα Llama",
      "recommendedForQwenModels": "Συνιστάται για μοντέλα Qwen",
      "onboardingModal": {
        "introducing": "Εισαγωγή",
        "speculativeDecoding": "Εικονική Αποκωδικοποίηση (Speculative Decoding)",
        "firstStepBody": "Επιτάχυνση inference για μοντέλα <custom-span>llama.cpp</custom-span> και <custom-span>MLX</custom-span>",
        "secondStepTitle": "Επιτάχυνση Inference με Speculative Decoding",
        "secondStepBody": "Το Speculative Decoding είναι μια τεχνική που περιλαμβάνει τη συνεργασία δύο μοντέλων:\n - Ένα μεγαλύτερο \"κύριο\" μοντέλο\n - Ένα μικρότερο \"draft\" μοντέλο\n\nΚατά τη δημιουργία, το draft μοντέλο προτείνει γρήγορα tokens για το μεγαλύτερο κύριο μοντέλο να επαληθεύσει. Η επαλήθευση tokens είναι μια πολύ πιο γρήγορη διαδικασία από το να τα δημιουργήσει πραγματικά, η οποία είναι η πηγή των κερδών ταχύτητας. **Γενικά, όσο μεγαλύτερη η διαφορά μεγέθους μεταξύ του κύριου μοντέλου και του draft μοντέλου, τόσο μεγαλύτερη η επιτάχυνση**.\n\nΓια να διατηρηθεί η ποιότητα, το κύριο μοντέλο αποδέχεται μόνο tokens που ευθυγραμμίζονται με αυτό που θα είχε δημιουργήσει μόνο του, επιτρέποντας την ποιότητα απόκρισης του μεγαλύτερου μοντέλου σε ταχύτερες ταχύτητες inference. Και τα δύο μοντέλα πρέπει να μοιράζονται το ίδιο λεξιλόγιο.",
        "draftModelRecommendationsTitle": "Συστάσεις μοντέλων draft",
        "basedOnCurrentModels": "Βασισμένο στα τρέχοντα μοντέλα σας",
        "close": "Κλείσιμο",
        "next": "Επόμενο",
        "done": "Ολοκληρώθηκε"
      },
      "speculativeDecodingLoadModelToSeeOptions": "Παρακαλώ φορτώστε πρώτα ένα μοντέλο <model-badge /> ",
      "errorEngineNotSupported": "Το Speculative decoding απαιτεί τουλάχιστον έκδοση {{minVersion}} της μηχανής {{engineName}}. Παρακαλώ ενημερώστε τη μηχανή (<key/>) και επαναφορτώστε το μοντέλο για να χρησιμοποιήσετε αυτή τη λειτουργία.",
      "errorEngineNotSupported/noKey": "Το Speculative decoding απαιτεί τουλάχιστον έκδοση {{minVersion}} της μηχανής {{engineName}}. Παρακαλώ ενημερώστε τη μηχανή και επαναφορτώστε το μοντέλο για να χρησιμοποιήσετε αυτή τη λειτουργία."
    },
    "llmReasoningParsing": {
      "startString/label": "Αρχική Συμβολοσειρά",
      "startString/placeholder": "Εισάγετε την αρχική συμβολοσειρά...",
      "endString/label": "Τελική Συμβολοσειρά",
      "endString/placeholder": "Εισάγετε την τελική συμβολοσειρά..."
    }
  },
  "saveConflictResolution": {
    "title": "Επιλέξτε ποιες τιμές να συμπεριληφθούν στην Προεπιλογή",
    "description": "Επιλέξτε ποιες τιμές να διατηρήσετε",
    "instructions": "Κάντε κλικ σε μια τιμή για να την συμπεριλάβετε",
    "userValues": "Προηγούμενη Τιμή",
    "presetValues": "Νέα Τιμή",
    "confirm": "Επιβεβαίωση",
    "cancel": "Ακύρωση"
  },
  "applyConflictResolution": {
    "title": "Ποιες τιμές να διατηρηθούν;",
    "description": "Έχετε αλλαγές που δεν έχουν δεσμευτεί και επικαλύπτονται με την εισερχόμενη Προεπιλογή",
    "instructions": "Κάντε κλικ σε μια τιμή για να την διατηρήσετε",
    "userValues": "Τρέχουσα Τιμή",
    "presetValues": "Εισερχόμενη Τιμή Προεπιλογής",
    "confirm": "Επιβεβαίωση",
    "cancel": "Ακύρωση"
  },
  "empty": "<Empty>",
  "noModelSelected": "Δεν έχουν επιλεγεί μοντέλα",
  "apiIdentifier.label": "Αναγνωριστικό API",
  "apiIdentifier.hint": "Προαιρετικά παρέχετε ένα αναγνωριστικό για αυτό το μοντέλο. Αυτό θα χρησιμοποιηθεί σε αιτήσεις API. Αφήστε κενό για να χρησιμοποιήσετε το προεπιλεγμένο αναγνωριστικό.",
  "idleTTL.label": "Αυτόματη Εκφόρτωση Αν Αδρανής (TTL)",
  "idleTTL.hint": "Αν οριστεί, το μοντέλο θα εκφορτωθεί αυτόματα μετά από αδράνεια για τον καθορισμένο χρόνο.",
  "idleTTL.mins": "λεπτά",

  "presets": {
    "title": "Προεπιλογή",
    "saveChanges": "Αποθήκευση",
    "saveChanges/description": "Αποθηκεύστε τις αλλαγές σας στην προεπιλογή.",
    "saveChanges.manual": "Εντοπίστηκαν νέα πεδία. Θα μπορείτε να επιλέξετε ποιες αλλαγές να συμπεριληφθούν στην προεπιλογή.",
    "saveChanges.manual.hold.0": "Κρατήστε",
    "saveChanges.manual.hold.1": "για να επιλέξετε ποιες αλλαγές να αποθηκευτούν στην προεπιλογή.",
    "saveChanges.saveAll.hold.0": "Κρατήστε",
    "saveChanges.saveAll.hold.1": "για να αποθηκεύσετε όλες τις αλλαγές.",
    "saveChanges.saveInPreset.hold.0": "Κρατήστε",
    "saveChanges.saveInPreset.hold.1": "για να αποθηκεύσετε μόνο αλλαγές σε πεδία που είναι ήδη συμπεριληφμένα στην προεπιλογή.",
    "saveChanges/error": "Αποτυχία αποθήκευσης αλλαγών στην προεπιλογή.",
    "saveChanges.manual/description": "Επιλέξτε ποιες αλλαγές να συμπεριληφθούν στην προεπιλογή.",
    "saveAs": "Αποθήκευση Ως Νέα...",
    "presetNamePlaceholder": "Εισάγετε ένα όνομα για την προεπιλογή...",
    "cannotCommitChangesLegacy": "Αυτή είναι μια παλιά προεπιλογή και δεν μπορεί να τροποποιηθεί. Μπορείτε να δημιουργήσετε ένα αντίγραφο χρησιμοποιώντας \"Αποθήκευση Ως Νέα...\".",
    "cannotSaveChangesNoChanges": "Δεν υπάρχουν αλλαγές για αποθήκευση.",
    "emptyNoUnsaved": "Επιλέξτε μια Προεπιλογή...",
    "emptyWithUnsaved": "Μη Αποθηκευμένη Προεπιλογή",
    "saveEmptyWithUnsaved": "Αποθήκευση Προεπιλογής Ως...",
    "saveConfirm": "Αποθήκευση",
    "saveCancel": "Ακύρωση",
    "saving": "Αποθήκευση...",
    "save/error": "Αποτυχία αποθήκευσης προεπιλογής.",
    "deselect": "Αποεπιλογή Προεπιλογής",
    "deselect/error": "Αποτυχία αποεπιλογής προεπιλογής.",
    "select/error": "Αποτυχία επιλογής προεπιλογής.",
    "delete/error": "Αποτυχία διαγραφής προεπιλογής.",
    "discardChanges": "Απόρριψη Μη Αποθηκευμένων",
    "discardChanges/info": "Απόρριψη όλων των μη αποθηκευμένων αλλαγών και επαναφορά της προεπιλογής στην αρχική της κατάσταση",
    "newEmptyPreset": "+ Νέα Προεπιλογή",
    "importPreset": "Εισαγωγή",
    "contextMenuCopyIdentifier": "Αντιγραφή Αναγνωριστικού Προεπιλογής",
    "contextMenuSelect": "Εφαρμογή Προεπιλογής",
    "contextMenuDelete": "Διαγραφή...",
    "contextMenuShare": "Δημοσίευση...",
    "contextMenuOpenInHub": "Προβολή στον Ιστό",
    "contextMenuPullFromHub": "Τραβήξτε Τελευταία",
    "contextMenuPushChanges": "Ώθηση Αλλαγών στον Hub",
    "contextMenuPushingChanges": "Ώθηση...",
    "contextMenuPushedChanges": "Οι αλλαγές ωθήθηκαν",
    "contextMenuExport": "Εξαγωγή Αρχείου",
    "contextMenuRevealInExplorer": "Αποκάλυψη στον Εξερευνητή Αρχείων",
    "contextMenuRevealInFinder": "Αποκάλυψη στον Finder",
    "share": {
      "title": "Δημοσίευση Προεπιλογής",
      "action": "Μοιραστείτε την προεπιλογή σας για να μπορούν άλλοι να την κατεβάσουν, να την αρέσουν και να την διακλαδώσουν",
      "presetOwnerLabel": "Ιδιοκτήτης",
      "uploadAs": "Η προεπιλογή σας θα δημιουργηθεί ως {{name}}",
      "presetNameLabel": "Όνομα Προεπιλογής",
      "descriptionLabel": "Περιγραφή (προαιρετική)",
      "loading": "Δημοσίευση...",
      "success": "Η Προεπιλογή Ωθήθηκε Επιτυχώς",
      "presetIsLive": "<preset-name /> είναι τώρα ζωντανή στον Hub!",
      "close": "Κλείσιμο",
      "confirmViewOnWeb": "Προβολή στον ιστό",
      "confirmCopy": "Αντιγραφή URL",
      "confirmCopied": "Αντιγράφηκε!",
      "pushedToHub": "Η προεπιλογή σας ωθήθηκε στον Hub",
      "descriptionPlaceholder": "Εισάγετε μια περιγραφή...",
      "willBePublic": "Αυτή η προεπιλογή θα είναι δημόσια. Οποιοσδήποτε στο διαδίκτυο θα μπορεί να την δει.",
      "willBePrivate": "Μόνο εσείς θα μπορείτε να δείτε αυτή την προεπιλογή",
      "willBeOrgVisible": "Αυτή η προεπιλογή θα είναι ορατή σε όλους στην οργάνωση.",
      "publicSubtitle": "Η προεπιλογή σας είναι <custom-bold>Δημόσια</custom-bold>. Άλλοι μπορούν να την κατεβάσουν και να την διακλαδώσουν στο lmstudio.ai",
      "privateUsageReached": "Το όριο αριθμού ιδιωτικών προεπιλογών έφτασε.",
      "continueInBrowser": "Συνέχεια στον Περιηγητή",
      "confirmShareButton": "Δημοσίευση",
      "error": "Αποτυχία δημοσίευσης προεπιλογής",
      "createFreeAccount": "Δημιουργήστε έναν δωρεάν λογαριασμό στον Hub για να δημοσιεύσετε προεπιλογές"
    },
    "update": {
      "title": "Ώθηση Αλλαγών στον Hub",
      "title/success": "Η Προεπιλογή Ενημερώθηκε Επιτυχώς",
      "subtitle": "Κάντε αλλαγές στο <custom-preset-name /> και ωθήστε τις στον Hub",
      "descriptionLabel": "Περιγραφή",
      "descriptionPlaceholder": "Εισάγετε μια περιγραφή...",
      "loading": "Ώθηση...",
      "cancel": "Ακύρωση",
      "createFreeAccount": "Δημιουργήστε έναν δωρεάν λογαριασμό στον Hub για να δημοσιεύσετε προεπιλογές",
      "error": "Αποτυχία ώθησης ενημέρωσης",
      "confirmUpdateButton": "Ώθηση"
    },
    "resolve": {
      "title": "Επίλυση συγκρούσεων...",
      "tooltip": "Ανοίξτε ένα modal για να επιλύσετε διαφορές με την έκδοση του Hub"
    },
    "loginToManage": {
      "title": "Σύνδεση για διαχείριση..."
    },
    "downloadFromHub": {
      "title": "Λήψη",
      "downloading": "Λήψη...",
      "success": "Λήφθηκε!",
      "error": "Αποτυχία λήψης"
    },
    "push": {
      "title": "Ώθηση αλλαγών",
      "pushing": "Ώθηση...",
      "success": "Ωθήθηκε",
      "tooltip": "Ωθήστε τις τοπικές σας αλλαγές στην απομακρυσμένη έκδοση που φιλοξενείται στον Hub",
      "error": "Αποτυχία ώθησης"
    },
    "saveAsNewModal": {
      "title": "Ωπα! Δεν βρέθηκε η προεπιλογή στον Hub",
      "confirmSaveAsNewDescription": "Θέλετε να δημοσιεύσετε αυτή την προεπιλογή ως νέα;",
      "confirmButton": "Δημοσίευση ως Νέα"
    },
    "pull": {
      "title": "Τραβήξτε Τελευταία",
      "error": "Αποτυχία τραβήγματος",
      "contextMenuErrorMessage": "Αποτυχία τραβήγματος",
      "success": "Τραβήχτηκε",
      "pulling": "Τραβώντας...",
      "upToDate": "Ενημερωμένο!",
      "unsavedChangesModal": {
        "title": "Έχετε μη αποθηκευμένες αλλαγές.",
        "bodyContent": "Το τράβηγμα από απομακρυσμένο θα αντικαταστήσει τις μη αποθηκευμένες αλλαγές σας. Συνέχεια;",
        "confirmButton": "Αντικατάσταση Μη Αποθηκευμένων Αλλαγών"
      }
    },
    "import": {
      "title": "Εισαγωγή Προεπιλογής από Αρχείο",
      "dragPrompt": "Σύρετε και αφήστε αρχεία προεπιλογής (.tar.gz ή preset.json) ή <custom-link>επιλέξτε από τον υπολογιστή σας</custom-link>",
      "remove": "Αφαίρεση",
      "cancel": "Ακύρωση",
      "importPreset_zero": "Εισαγωγή Προεπιλογής",
      "importPreset_one": "Εισαγωγή Προεπιλογής",
      "importPreset_other": "Εισαγωγή {{count}} Προεπιλογών",
      "selectDialog": {
        "title": "Επιλέξτε Αρχείο Προεπιλογής (preset.json ή .tar.gz)",
        "button": "Εισαγωγή"
      },
      "error": "Αποτυχία εισαγωγής προεπιλογής",
      "resultsModal": {
        "titleSuccessSection_one": "Εισήχθη 1 προεπιλογή επιτυχώς",
        "titleSuccessSection_other": "Εισήχθησαν {{count}} προεπιλογές επιτυχώς",
        "titleFailSection_zero": "",
        "titleFailSection_one": "({{count}} απέτυχε)",
        "titleFailSection_other": "({{count}} απέτυχαν)",
        "titleAllFailed": "Αποτυχία εισαγωγής προεπιλογών",
        "importMore": "Εισαγωγή Περισσότερων",
        "close": "Ολοκληρώθηκε",
        "successBadge": "Επιτυχία",
        "alreadyExistsBadge": "Η προεπιλογή υπάρχει ήδη",
        "errorBadge": "Σφάλμα",
        "invalidFileBadge": "Μη έγκυρο αρχείο",
        "otherErrorBadge": "Αποτυχία εισαγωγής προεπιλογής",
        "errorViewDetailsButton": "Προβολή Λεπτομερών",
        "seeError": "Δείτε τα Σφάλμα",
        "noName": "Χωρίς όνομα προεπιλογής",
        "useInChat": "Χρήση σε Συνομιλία"
      },
      "importFromUrl": {
        "button": "Εισαγωγή από URL...",
        "title": "Εισαγωγή από URL",
        "back": "Εισαγωγή από Αρχείο...",
        "action": "Επικολλήστε το URL του LM Studio Hub της προεπιλογής που θέλετε να εισάγετε παρακάτω",
        "invalidUrl": "Μη έγκυρο URL. Παρακαλώ βεβαιωθείτε ότι επικολλάτε ένα σωστό URL του LM Studio Hub.",
        "tip": "Μπορείτε να εγκαταστήσετε την προεπιλογή απευθείας με το κουμπί {{buttonName}} στο LM Studio Hub",
        "confirm": "Εισαγωγή",
        "cancel": "Ακύρωση",
        "loading": "Εισαγωγή...",
        "error": "Αποτυχία λήψης προεπιλογής."
      }
    },
    "download": {
      "title": "Τραβήξτε <preset-name /> από LM Studio Hub",
      "subtitle": "Αποθηκεύστε <custom-name /> στις προεπιλογές σας. Κάνοντας αυτό θα σας επιτρέψει να χρησιμοποιήσετε αυτή την προεπιλογή στην εφαρμογή",
      "button": "Τραβήξτε",
      "button/loading": "Τραβώντας...",
      "cancel": "Ακύρωση",
      "error": "Αποτυχία λήψης προεπιλογής."
    },
    "inclusiveness": {
      "speculativeDecoding": "Συμπερίληψη στην Προεπιλογή"
    }
  },

  "flashAttentionWarning": "Το Flash Attention είναι μια πειραματική λειτουργία που μπορεί να προκαλέσει προβλήματα με ορισμένα μοντέλα. Αν αντιμετωπίσετε προβλήματα, δοκιμάστε να το απενεργοποιήσετε.",
  "llamaKvCacheQuantizationWarning": "Η Κβαντοποίηση KV Cache είναι μια πειραματική λειτουργία που μπορεί να προκαλέσει προβλήματα με ορισμένα μοντέλα. Το Flash Attention πρέπει να είναι ενεργοποιημένο για κβαντοποίηση V cache. Αν αντιμετωπίσετε προβλήματα, επαναφέρετε στην προεπιλεγμένη \"F16\".",

  "seedUncheckedHint": "Τυχαίο Seed",
  "ropeFrequencyBaseUncheckedHint": "Αυτόματο",
  "ropeFrequencyScaleUncheckedHint": "Αυτόματο",

  "hardware": {
    "environmentVariables": "Μεταβλητές Περιβάλλοντος",
    "environmentVariables.info": "Αν δεν είστε σίγουροι, αφήστε τα στις προεπιλεγμένες τιμές",
    "environmentVariables.reset": "Επαναφορά στην προεπιλεγμένη",

    "gpus.information": "Διαμορφώστε τις μονάδες επεξεργασίας γραφικών (GPUs) που εντοπίστηκαν στον υπολογιστή σας",
    "gpuSettings": {
      "editMaxCapacity": "Επεξεργασία Μέγιστης Χωρητικότητας",
      "hideEditMaxCapacity": "Απόκρυψη Επεξεργασίας Μέγιστης Χωρητικότητας",
      "allOffWarning": "Όλες οι GPUs είναι απενεργοποιημένες ή απενεργοποιημένες, βεβαιωθείτε ότι υπάρχει κάποια κατανομή GPU για να ενεργοποιήσετε τη φόρτωση μοντέλων",
      "split": {
        "title": "Στρατηγική",
        "placeholder": "Επιλέξτε κατανομή μνήμης GPU",
        "options": {
          "generalDescription": "Διαμορφώστε πώς τα μοντέλα θα φορτωθούν στις GPUs σας",
          "evenly": {
            "title": "Διαχωρισμός ομοιόμορφα",
            "description": "Κατανείμετε τη μνήμη ομοιόμορφα μεταξύ GPUs"
          },
          "priorityOrder": {
            "title": "Σειρά προτεραιότητας",
            "description": "Σύρετε για αναδιάταξη προτεραιότητας. Το σύστημα θα προσπαθήσει να κατανείμει περισσότερα στις GPUs που αναφέρονται πρώτα"
          },
          "custom": {
            "title": "Προσαρμοσμένο",
            "description": "Κατανείμετε τη μνήμη",
            "maxAllocation": "Μέγιστη Κατανομή"
          }
        }
      },
      "deviceId.info": "Μοναδικό αναγνωριστικό για αυτή τη συσκευή",
      "changesOnlyAffectNewlyLoadedModels": "Οι αλλαγές θα επηρεάσουν μόνο τα νεοφορτωμένα μοντέλα",
      "toggleGpu": "Ενεργοποίηση/Απενεργοποίηση GPU"
    }
  },

  "load.gpuSplitConfig/title": "Διαμόρφωση Διαχωρισμού GPU",
  "envVars/title": "Ορισμός Μεταβλητής Περιβάλλοντος",
  "envVars": {
    "select": {
      "placeholder": "Επιλέξτε μια μεταβλητή περιβάλλοντος...",
      "noOptions": "Δεν υπάρχουν διαθέσιμες περισσότερες μεταβλητές περιβάλλοντος",
      "filter": {
        "placeholder": "Φιλτράρισμα αποτελεσμάτων αναζήτησης",
        "resultsFound_zero": "Δεν βρέθηκαν αποτελέσματα",
        "resultsFound_one": "Βρέθηκε 1 αποτέλεσμα",
        "resultsFound_other": "Βρέθηκαν {{count}} αποτελέσματα"
      }
    },
    "inputValue": {
      "placeholder": "Εισάγετε μια τιμή"
    },
    "values": {
      "title": "Τρέχουσες Τιμές"
    }
  }
}