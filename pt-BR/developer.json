{
    "tabs/server": "Servidor Local",
    "tabs/extensions": "Tempos de Execu√ß√£o",
    "loadSettings/title": "Configura√ß√µes de carregamento",
    "modelSettings/placeholder": "Selecione um modelo para configur√°-lo",

    "loadedModels/noModels": "Nenhum modelo carregado",

    "serverOptions/title": "Op√ß√µes do Servidor",
    "serverOptions/configurableTitle": "Op√ß√µes Configur√°veis",
    "serverOptions/port/hint": "Defina qual porta de rede o servidor local usar√°. Por padr√£o, o LM Studio usa a porta 1234. Voc√™ pode precisar mudar isso se a porta j√° estiver em uso.",
    "serverOptions/port/subtitle": "A porta para escutar",
    "serverOptions/autostart/title": "Auto-iniciar servidor",
    "serverOptions/autostart/hint": "Ligar automaticamente o servidor de LLMs locais do LM Studio ao iniciar o aplicativo ou servi√ßo",
    "serverOptions/port/integerWarning": "N√∫mero da porta deve ser um inteiro",
    "serverOptions/port/invalidPortWarning": "Porta deve ser entre 1 e 65535",
    "serverOptions/cors/title": "Ativar CORS",
    "serverOptions/cors/hint1": "Ativar CORS (Cross-origin Resource Sharing) permitiria que sites que voc√™ visita fa√ßam requisi√ß√µes ao servidor LM Studio.",
    "serverOptions/cors/hint2": "CORS pode ser necess√°rio ao fazer requisi√ß√µes de uma p√°gina web ou extens√£o VS Code / outras.",
    "serverOptions/cors/subtitle": "Permitir requisi√ß√µes cross-origin",
    "serverOptions/network/title": "Servir na Rede Local",
    "serverOptions/network/subtitle": "Expor servidor a dispositivos na rede",
    "serverOptions/network/hint1": "Se deve permitir conex√µes de outros dispositivos na rede.",
    "serverOptions/network/hint2": "Se n√£o marcado, o servidor escutar√° apenas em localhost.",
    "serverOptions/verboseLogging/title": "Registros Detalhados",
    "serverOptions/verboseLogging/subtitle": "Ativar registros detalhados para o servidor local",
    "serverOptions/contentLogging/title": "Logar Prompts e Respostas",
    "serverOptions/contentLogging/subtitle": "Configura√ß√µes de registro de requisi√ß√£o / resposta local",
    "serverOptions/contentLogging/hint": "Se deve logar prompts e/ou a resposta no arquivo de registro do servidor local.",
    "serverOptions/redactContent/title": "Ocultar Conte√∫do",
    "serverOptions/redactContent/hint": "Quando ativado, previne que dados sens√≠veis, como o conte√∫do das requisi√ß√µes e respostas, sejam logados.",
    "serverOptions/logIncomingTokens/title": "Logar Tokens Recebidos",
    "serverOptions/logIncomingTokens/hint": "Se deve logar cada token conforme eles est√£o sendo gerados.",
    "serverOptions/fileLoggingMode/title": "Modo de Registro de Arquivo",
    "serverOptions/fileLoggingMode/off/title": "DESLIGADO",
    "serverOptions/fileLoggingMode/off/hint": "N√£o criar arquivos de registro",
    "serverOptions/fileLoggingMode/succinct/title": "Sucinto",
    "serverOptions/fileLoggingMode/succinct/hint": "Logar o mesmo conte√∫do que no console. Requisi√ß√µes longas ser√£o truncadas.",
    "serverOptions/fileLoggingMode/full/title": "Completo",
    "serverOptions/fileLoggingMode/full/hint": "N√£o truncar requisi√ß√µes longas.",
    "serverOptions/jitModelLoading/title": "Carregamento de Modelo Just-in-Time",
    "serverOptions/jitModelLoading/hint": "Quando ativado, se uma requisi√ß√£o especificar um modelo que n√£o est√° carregado, ele ser√° automaticamente carregado e usado. Al√©m disso, o vetor \"/v1/models\" tamb√©m incluir√° modelos que ainda n√£o est√£o carregados.",
    "serverOptions/loadModel/error": "Falha ao carregar modelo",
    "serverOptions/jitModelLoadingTTL/title": "Auto descarregar modelos JIT n√£o usados",
    "serverOptions/jitModelLoadingTTL/hint": "Um modelo que foi carregado Just-in-time (JIT) para servir uma requisi√ß√£o de API ser√° automaticamente descarregado ap√≥s ficar sem uso por alguma dura√ß√£o (TTL).",
    "serverOptions/jitModelLoadingTTL/ttl/label": "TTL m√°x. ocioso",
    "serverOptions/jitModelLoadingTTL/ttl/unit": "minutos",
    "serverOptions/unloadPreviousJITModelOnLoad/title": "Manter Apenas √öltimo Modelo JIT Carregado",
    "serverOptions/unloadPreviousJITModelOnLoad/hint": "Garantir no m√°ximo 1 modelo carregado via JIT a qualquer momento (descarrega modelo anterior)",
    "serverOptions/allowMcp/title": "Permitir MCP Remoto",
    "serverOptions/allowMcp/hint": "Permitir usar MCPs que n√£o est√£o no seu mcp.json. Essas conex√µes MCP s√£o ef√™meras, existindo apenas enquanto durar a requisi√ß√£o. No momento, apenas MCPs remotos s√£o suportados.",
    "serverOptions/allowMcp/mode/off": "Desligado",
    "serverOptions/allowMcp/mode/off/hint": "N√£o permitir requisi√ß√µes do servidor usarem MCP",
    "serverOptions/allowMcp/mode/remote": "Remoto",
    "serverOptions/allowMcp/mode/remote/hint": "Permitir conex√£o a servidores MCP remotos",

    "serverOptions/start/error": "Falha ao iniciar o servidor",
    "serverOptions/stop/error": "Falha ao parar o servidor",

    "serverLogs/scrollToBottom": "Pular para o final",
    "serverLogs/clearLogs": "Limpar registros ({{shortcut}})",
    "serverLogs/openLogsFolder": "Abrir pasta de registros do servidor",

    "runtimeSettings/title": "Configura√ß√µes de Tempo de Execu√ß√£o",
    "runtimeSettings/chooseRuntime/title": "Sele√ß√µes",
    "runtimeSettings/chooseRuntime/description": "Selecione um motor para usar para cada formato de modelo",
    "runtimeSettings/chooseRuntime/showAllVersions/label": "Mostrar todos os pacotes de extens√£o",
    "runtimeSettings/chooseRuntime/showAllVersions/hint": "Por padr√£o, o LM Studio mostra apenas a √∫ltima vers√£o de cada pacote de extens√£o. Ative esta op√ß√£o para ver todos os pacotes de extens√£o dispon√≠veis.",
    "runtimeSettings/chooseRuntime/select/placeholder": "Selecione um motor",

    "runtimeSettings/chooseFrameworks/title": "Frameworks",
    "runtimeSettings/chooseFrameworks/description": "Selecione um framework para usar para cada funcionalidade",
    "runtimeSettings/chooseFramework/documentParser/builtIn/label": "Analisador integrado",
    "runtimeSettings/chooseFramework/documentParser/select/label": "Analisador de Documento",
    "runtimeSettings/chooseFramework/documentParser/select/placeholder": "Selecione um analisador de documento",
    "runtimeOptions/uninstall": "Desinstalar",
    "runtimeOptions/uninstallDialog/title": "Desinstalar {{runtimeName}}?",
    "runtimeOptions/uninstallDialog/body": "Desinstalar este tempo de execu√ß√£o ir√° remov√™-lo do sistema. Esta a√ß√£o √© irrevers√≠vel.",
    "runtimeOptions/uninstallDialog/body/caveats": "Alguns arquivos podem ser removidos apenas ap√≥s o LM Studio ser reiniciado.",
    "runtimeOptions/uninstallDialog/error": "Falha ao desinstalar o tempo de execu√ß√£o",
    "runtimeOptions/uninstallDialog/confirm": "Continuar e Desinstalar",
    "runtimeOptions/uninstallDialog/cancel": "Cancelar",
    "runtimeOptions/noCompatibleRuntimes": "Nenhum tempo de execu√ß√£o compat√≠vel encontrado",
    "runtimeOptions/downloadIncompatibleRuntime": "Este tempo de execu√ß√£o foi determinado como incompat√≠vel com sua m√°quina. Provavelmente n√£o funcionar√°.",
    "runtimeOptions/noRuntimes": "Nenhum tempo de execu√ß√£o encontrado",

    "runtimes": {
        "manageLMRuntimes": "Gerenciar Tempos de Execu√ß√£o de LM",
        "includeOlderRuntimeVersions": "Incluir vers√µes mais antigas",
        "dismiss": "Dispensar",
        "updateAvailableToast": {
            "title": "Atualiza√ß√£o de Tempo de Execu√ß√£o de LM Dispon√≠vel!"
        },
        "updatedToast": {
            "title": " ‚úÖ Tempo de Execu√ß√£o de LM Atualizado: {{runtime}} ‚Üí v{{version}}",
            "preferencesUpdated": "Modelos {{compatibilityTypes}} carregados recentemente usar√£o o tempo de execu√ß√£o atualizado."
        },
        "noAvx2ErrorMessage": "Todos os Tempos de Execu√ß√£o de LM atualmente requerem uma CPU com suporte AVX2",
        "downloadableRuntimes": {
            "runtimeExtensionPacks": "Pacotes de Extens√£o de Tempo de Execu√ß√£o",
            "refresh": "Atualizar",
            "refreshing": "Atualizando...",
            "filterSegment": {
                "compatibleOnly": "Apenas Compat√≠veis",
                "all": "Todos"
            },
            "card": {
                "releaseNotes": "Notas da Vers√£o",
                "latestVersionInstalled": "√öltima Vers√£o Instalada",
                "updateAvailable": "Atualiza√ß√£o Dispon√≠vel"
            }
        },
        "installedRuntimes": {
            "manage": {
                "title": "Gerenciar Tempos de Execu√ß√£o Ativos"
            },
            "dropdownOptions": {
                "installedVersions": "Gerenciar Vers√µes",
                "close": "Fechar"
            },
            "tabs": {
                "all": "Todos",
                "frameworks": "Meus Frameworks",
                "engines": "Meus Motores"
            },
            "detailsModal": {
                "installedVersions": "Vers√µes instaladas para {{runtimeName}}",
                "manifestJsonTitle": "Manifesto JSON (avan√ßado)",
                "releaseNotesTitle": "Notas da Vers√£o",
                "noReleaseNotes": "Nenhuma nota de vers√£o dispon√≠vel para esta vers√£o",
                "back": "Voltar",
                "close": "Fechar"
            },
            "noEngines": "Nenhum motor instalado",
            "noFrameworks": "Nenhum framework instalado"
        }
    },
    "inferenceParams/noParams": "Nenhum par√¢metro de infer√™ncia configur√°vel dispon√≠vel para este tipo de modelo",
    "quickDocs": {
        "tabChipTitle": "Docs do Desenvolvedor",
        "newToolUsePopover": "Trechos de C√≥digo agora est√£o dispon√≠veis aqui em \"Docs do Desenvolvedor\". Clique aqui para come√ßar com uso de ferramentas!",
        "newToolUsePopoverTitle": "üìö Docs do Desenvolvedor",
        "learnMore": "‚ÑπÔ∏è üëæ Para saber mais sobre vetores do servidor local LM Studio, visite a [documenta√ß√£o](https://lmstudio.ai/docs).",
        "helloWorld": {
            "title": "Ol√°, Mundo!"
        },
        "chat": {
            "title": "Conversa"
        },
        "structuredOutput": {
            "title": "Sa√≠da Estruturada"
        },
        "imageInput": {
            "title": "Entrada de Imagem"
        },
        "embeddings": {
            "title": "Vetoriza√ß√£o"
        },
        "toolUse": {
            "title": "Uso de Ferramentas",
            "tab": {
                "saveAsPythonFile": "Salvar como arquivo Python",
                "runTheScript": "Rodar o script:",
                "savePythonFileCopyPaste": "Salvar como arquivo Python para um comando copiar-e-colar"
            }
        },
        "newBadge": "Novo"
    },

    "endpoints/openaiCompatRest/title": "Vetores suportados{{extra}}",
    "endpoints/openaiCompatRest/segmentedLabel": "Tipo-OpenAI",
    "endpoints/openaiCompatRest/getModels": "Listar os modelos carregados atualmente",
    "endpoints/openaiCompatRest/postCompletions": "Modo de Completar Texto. Prediz o(s) pr√≥ximo(s) token(s) dado um prompt. Nota: OpenAI considera este vetor 'depreciado'.",
    "endpoints/openaiCompatRest/postChatCompletions": "Completar Conversa. Envia um hist√≥rico de conversa para o modelo predizer a pr√≥xima resposta do assistente",
    "endpoints/openaiCompatRest/postEmbeddings": "Vetoriza√ß√£o de Texto. Gera vetores de texto para uma entrada fornecida. Aceita uma string ou array de strings.",
    "endpoints/openaiCompatRest/postResponses": "Interface avan√ßada para gerar respostas de modelo. Crie intera√ß√µes com estado passando o id de respostas anteriores como entrada para a pr√≥xima.",
    "endpoints/lmStudioRest/segmentedLabel": "LM Studio",
    "endpoints/lmStudioRestV1/getModels": "Listar modelos dispon√≠veis",
    "endpoints/lmStudioRestV1/postModelsLoad": "Carregar um modelo com op√ß√µes",
    "endpoints/lmStudioRestV1/postModelsDownload": "Baixar um modelo",
    "endpoints/lmStudioRestV1/postChat": "Conversa com um modelo. Suporta conversas multi-turnos com estado e MCP",
    "endpoints/lmStudioRestV1/getModelsDownloadStatus": "Obter o status de um download de modelo",
    "model.createVirtualModelFromInstance": "Salvar Configura√ß√µes como um Novo Modelo Virtual",
    "model.createVirtualModelFromInstance/error": "Falha ao salvar configura√ß√µes como um novo modelo virtual",

    "model": {
        "toolUseSectionTitle": "Uso de Ferramentas",
        "toolUseDescription": "Este modelo foi detectado como treinado para uso de ferramentas\n\nAbra <custom-link>docs do desenvolvedor</custom-link> para mais informa√ß√µes"
    },

    "apiConfigOptions/title": "Configura√ß√£o da API"
}