{
  "tabs/server": "Servidor Local",
  "tabs/extensions": "Tempos de Execu√ß√£o",
  "loadSettings/title": "Carregar configura√ß√µes",
  "modelSettings/placeholder": "Selecione um modelo para configurar",

  "loadedModels/noModels": "Nenhum modelo carregado",

  "serverOptions/title": "Op√ß√µes do Servidor",
  "serverOptions/configurableTitle": "Op√ß√µes Configur√°veis",
  "serverOptions/port/hint": "Defina a porta de rede que o servidor local usar√°. Por padr√£o, o LM Studio usa a porta 1234. Pode ser necess√°rio alterar se a porta j√° estiver em uso.",
  "serverOptions/port/subtitle": "A porta em que o servidor ir√° operar",
  "serverOptions/autostart/title": "Iniciar servidor automaticamente",
  "serverOptions/autostart/hint": "Inicia o servidor local de LLMs do LM Studio automaticamente na inicializa√ß√£o do aplicativo ou servi√ßo.",
  "serverOptions/port/integerWarning": "O n√∫mero da porta deve ser um inteiro",
  "serverOptions/port/invalidPortWarning": "A porta deve estar entre 1 e 65535",
  "serverOptions/cors/title": "Habilitar CORS",
  "serverOptions/cors/hint1": "Habilitar o CORS (Compartilhamento de Recursos de Origem Cruzada) permite que sites que voc√™ visita fa√ßam requisi√ß√µes ao servidor do LM Studio.",
  "serverOptions/cors/hint2": "O CORS pode ser necess√°rio ao fazer requisi√ß√µes a partir de uma p√°gina web, do VS Code ou de outras extens√µes.",
  "serverOptions/cors/subtitle": "Permitir requisi√ß√µes de origem cruzada",
  "serverOptions/network/title": "Servir na Rede Local",
  "serverOptions/network/subtitle": "Expor o servidor a dispositivos na mesma rede",
  "serverOptions/network/hint1": "Permite conex√µes de outros dispositivos na rede.",
  "serverOptions/network/hint2": "Se desmarcado, o servidor aceitar√° conex√µes apenas de localhost.",
  "serverOptions/verboseLogging/title": "Registros Detalhados",
  "serverOptions/verboseLogging/subtitle": "Habilita registros detalhados para o servidor local",
  "serverOptions/contentLogging/title": "Registrar Prompts e Respostas",
  "serverOptions/contentLogging/subtitle": "Configura√ß√µes de registro para requisi√ß√µes/respostas locais",
  "serverOptions/contentLogging/hint": "Define se os prompts e/ou respostas devem ser registrados no arquivo de registro do servidor local.",
  "serverOptions/fileLoggingMode/title": "Modo de Registro em Arquivo",
  "serverOptions/fileLoggingMode/off/title": "DESLIGADO",
  "serverOptions/fileLoggingMode/off/hint": "N√£o criar arquivos de registro",
  "serverOptions/fileLoggingMode/succinct/title": "Sucinto",
  "serverOptions/fileLoggingMode/succinct/hint": "Registra o mesmo conte√∫do do console. Requisi√ß√µes longas ser√£o truncadas.",
  "serverOptions/fileLoggingMode/full/title": "Completo",
  "serverOptions/fileLoggingMode/full/hint": "N√£o truncar requisi√ß√µes longas.",
  "serverOptions/jitModelLoading/title": "Carregamento de Modelo Just-in-Time (JIT)",
  "serverOptions/jitModelLoading/hint": "Quando habilitado, se uma requisi√ß√£o especificar um modelo que n√£o est√° carregado, ele ser√° carregado e usado automaticamente. Al√©m disso, o endpoint \"/v1/models\" incluir√° modelos que ainda n√£o foram carregados.",
  "serverOptions/loadModel/error": "Falha ao carregar o modelo",
  "serverOptions/jitModelLoadingTTL/title": "Descarregar automaticamente modelos JIT n√£o utilizados",
  "serverOptions/jitModelLoadingTTL/hint": "Um modelo carregado via Just-in-Time (JIT) para uma requisi√ß√£o de API ser√° descarregado automaticamente ap√≥s um per√≠odo de inatividade (TTL).",
  "serverOptions/jitModelLoadingTTL/ttl/label": "TTL m√°ximo de inatividade",
  "serverOptions/jitModelLoadingTTL/ttl/unit": "minutos",
  "serverOptions/unloadPreviousJITModelOnLoad/title": "Manter Apenas o √öltimo Modelo Carregado via JIT",
  "serverOptions/unloadPreviousJITModelOnLoad/hint": "Garante que no m√°ximo 1 modelo carregado via JIT permane√ßa na mem√≥ria por vez (descarrega o modelo anterior).",

  "serverLogs/scrollToBottom": "Rolar para o final",
  "serverLogs/clearLogs": "Limpar registros ({{shortcut}})",
  "serverLogs/openLogsFolder": "Abrir pasta de registros do servidor",

  "runtimeSettings/title": "Configura√ß√µes de Tempo de Execu√ß√£o",
  "runtimeSettings/chooseRuntime/title": "Sele√ß√µes Padr√£o",
  "runtimeSettings/chooseRuntime/description": "Selecione um tempo de execu√ß√£o padr√£o para cada formato de modelo",
  "runtimeSettings/chooseRuntime/showAllVersions/label": "Mostrar todos os tempos de execu√ß√£o",
  "runtimeSettings/chooseRuntime/showAllVersions/hint": "Por padr√£o, o LM Studio mostra apenas a vers√£o mais recente de cada tempo de execu√ß√£o compat√≠vel. Habilite para ver todos.",
  "runtimeSettings/chooseRuntime/select/placeholder": "Selecione um Tempo de Execu√ß√£o",

  "runtimeOptions/uninstall": "Desinstalar",
  "runtimeOptions/uninstallDialog/title": "Desinstalar {{runtimeName}}?",
  "runtimeOptions/uninstallDialog/body": "Desinstalar este tempo de execu√ß√£o o remover√° do sistema. Esta a√ß√£o √© irrevers√≠vel.",
  "runtimeOptions/uninstallDialog/body/caveats": "Alguns arquivos podem ser removidos apenas ap√≥s a reinicializa√ß√£o do LM Studio.",
  "runtimeOptions/uninstallDialog/error": "Falha ao desinstalar o tempo de execu√ß√£o",
  "runtimeOptions/uninstallDialog/confirm": "Continuar e Desinstalar",
  "runtimeOptions/uninstallDialog/cancel": "Cancelar",
  "runtimeOptions/noCompatibleRuntimes": "Nenhum tempo de execu√ß√£o compat√≠vel encontrado",
  "runtimeOptions/downloadIncompatibleRuntime": "Este tempo de execu√ß√£o foi determinado como incompat√≠vel com sua m√°quina. Provavelmente n√£o funcionar√°.",
  "runtimeOptions/noRuntimes": "Nenhum tempo de execu√ß√£o encontrado",

  "runtimes": {
    "manageLMRuntimes": "Gerenciar Tempos de Execu√ß√£o de LM",
    "includeOlderRuntimeVersions": "Incluir vers√µes mais antigas",
    "dismiss": "Dispensar",
    "updateAvailableToast": {
      "title": "Atualiza√ß√£o de Tempo de Execu√ß√£o de LM Dispon√≠vel!"
    },
    "updatedToast": {
      "title": " ‚úÖ Tempo de Execu√ß√£o de LM Atualizado: {{runtime}} ‚Üí v{{version}}",
      "preferencesUpdated": "Modelos do tipo {{compatibilityTypes}} rec√©m-carregados usar√£o o tempo de execu√ß√£o atualizado."
    },
    "noAvx2ErrorMessage": "Todos os Tempos de Execu√ß√£o de LM atualmente requerem uma CPU com suporte a AVX2.",
    "downloadableRuntimes": {
      "runtimeExtensionPacks": "Pacotes de Extens√£o de Tempo de Execu√ß√£o",
      "refresh": "Atualizar",
      "refreshing": "Atualizando...",
      "filterSegment": {
        "compatibleOnly": "Apenas Compat√≠veis",
        "all": "Todos"
      },
      "card": {
        "releaseNotes": "Notas da Vers√£o",
        "latestVersionInstalled": "√öltima Vers√£o Instalada",
        "updateAvailable": "Atualiza√ß√£o Dispon√≠vel"
      }
    },
    "installedRuntimes": {
      "manage": {
        "title": "Gerenciar Tempos de Execu√ß√£o Ativos"
      },
      "dropdownOptions": {
        "installedVersions": "Gerenciar Vers√µes",
        "close": "Fechar"
      },
      "tabs": {
        "all": "Todos",
        "frameworks": "Meus Frameworks",
        "engines": "Meus Motores"
      },
      "detailsModal": {
        "installedVersions": "Vers√µes instaladas para {{runtimeName}}",
        "manifestJsonTitle": "Manifesto JSON (avan√ßado)",
        "releaseNotesTitle": "Notas da Vers√£o",
        "noReleaseNotes": "Nenhuma nota de vers√£o dispon√≠vel para esta vers√£o",
        "back": "Voltar",
        "close": "Fechar"
      },
      "noEngines": "Nenhum motor instalado",
      "noFrameworks": "Nenhum framework instalado"
    }
  },

  "inferenceParams/noParams": "Nenhum par√¢metro de infer√™ncia configur√°vel dispon√≠vel para este tipo de modelo",

  "quickDocs": {
    "tabChipTitle": "Docs R√°pidos",
    "newToolUsePopover": "Trechos de c√≥digo agora est√£o dispon√≠veis aqui em \"Docs R√°pidos\". Clique aqui para come√ßar a usar ferramentas!",
    "newToolUsePopoverTitle": "üìö Docs R√°pidos",
    "learnMore": "‚ÑπÔ∏è üëæ Para saber mais sobre os endpoints do servidor local do LM Studio, visite a [documenta√ß√£o](https://lmstudio.ai/docs).",
    "helloWorld": {
      "title": "Ol√°, Mundo!"
    },
    "chat": {
      "title": "Chat"
    },
    "structuredOutput": {
      "title": "Sa√≠da Estruturada"
    },
    "imageInput": {
      "title": "Entrada de Imagem"
    },
    "embeddings": {
      "title": "Embeddings"
    },
    "toolUse": {
      "title": "Uso de Ferramentas",
      "tab": {
        "saveAsPythonFile": "Salvar como arquivo Python",
        "runTheScript": "Execute o script:",
        "savePythonFileCopyPaste": "Salvar como arquivo Python para um comando de copiar e colar"
      }
    },
    "newBadge": "Novo"
  },

  "endpoints/openaiCompatRest/title": "Endpoints suportados (padr√£o OpenAI)",
  "endpoints/openaiCompatRest/getModels": "Lista os modelos carregados atualmente",
  "endpoints/openaiCompatRest/postCompletions": "Modo de Conclus√£o de Texto. Prev√™ os pr√≥ximos tokens a partir de um prompt. Nota: A OpenAI considera este endpoint 'obsoleto'.",
  "endpoints/openaiCompatRest/postChatCompletions": "Conclus√£o de Conversa. Envia um hist√≥rico de conversa para o modelo prever a pr√≥xima resposta do assistente.",
  "endpoints/openaiCompatRest/postEmbeddings": "Embedding de Texto. Gera embeddings de texto para uma entrada. Aceita uma string ou uma lista de strings.",

  "model.createVirtualModelFromInstance": "Salvar Configura√ß√µes como um Novo Modelo Virtual",
  "model.createVirtualModelFromInstance/error": "Falha ao salvar as configura√ß√µes como um novo modelo virtual",

  "model": {
    "toolUseSectionTitle": "Uso de Ferramentas",
    "toolUseDescription": "Este modelo foi treinado para o uso de ferramentas.\n\nAbra os <custom-link>Docs R√°pidos</custom-link> para mais informa√ß√µes."
  },

  "apiConfigOptions/title": "Configura√ß√£o da API"
}
