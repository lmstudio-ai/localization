{
	"noInstanceSelected": "Ingen modellinstans vald",
	"resetToDefault": "√Öterst√§ll",
	"showAdvancedSettings": "Visa avancerade inst√§llningar",
	"showAll": "Alla",
	"basicSettings": "Grundl√§ggande",
	"configSubtitle": "Ladda eller spara f√∂rinst√§llningar och experimentera med modellparametrar",
	"inferenceParameters/title": "Prediktionsparametrar",
	"inferenceParameters/info": "Experimentera med parametrar som p√•verkar prediktionen.",
	"generalParameters/title": "Allm√§nt",
	"samplingParameters/title": "Sampling",
	"basicTab": "Grundl√§ggande",
	"advancedTab": "Avancerat",
	"advancedTab/title": "üß™ Avancerad konfiguration",
	"advancedTab/expandAll": "Expandera alla",
	"advancedTab/overridesTitle": "Anpassade konfigurationer",
	"advancedTab/noConfigsText": "Du har inga osparade √§ndringar - redigera v√§rden ovan f√∂r att se anpassade konfigurationer h√§r.",
	"loadInstanceFirst": "Ladda en modell f√∂r att visa konfigurerbara parametrar",
	"noListedConfigs": "Inga konfigurerbara parametrar",
	"generationParameters/info": "Experimentera med grundl√§ggande parametrar som p√•verkar textgenerering.",
	"loadParameters/title": "Ladda parametrar",
	"loadParameters/description": "Inst√§llningar f√∂r att kontrollera hur modellen initieras och laddas i minnet.",
	"loadParameters/reload": "Ladda om f√∂r att till√§mpa √§ndringar",
	"loadParameters/reload/error": "Misslyckades med att ladda om modellen",
	"discardChanges": "√Öngra √§ndringar",
	"loadModelToSeeOptions": "Ladda en modell f√∂r att se alternativ",
	"schematicsError.title": "Konfigurationsschemat inneh√•ller fel i f√∂ljande f√§lt:",
	"manifestSections": {
		"structuredOutput/title": "Strukturerad utdata",
		"speculativeDecoding/title": "Spekulativ avkodning",
		"sampling/title": "Sampling",
		"settings/title": "Inst√§llningar",
		"toolUse/title": "Verktygsanv√§ndning",
		"promptTemplate/title": "Promptmall",
		"customFields/title": "Anpassade f√§lt"
  },

	"llm.prediction.systemPrompt/title": "Systemprompt",
	"llm.prediction.systemPrompt/description": "Anv√§nd detta f√§lt f√∂r att ge bakgrundsinstruktioner till modellen, s√•som en upps√§ttning regler, begr√§nsningar eller allm√§nna krav.",
	"llm.prediction.systemPrompt/subTitle": "Riktlinjer f√∂r AI:n",
	"llm.prediction.systemPrompt/openEditor": "Redigerare",
	"llm.prediction.systemPrompt/closeEditor": "St√§ng redigerare",
	"llm.prediction.systemPrompt/openedEditor": "√ñppnad i redigerare...",
	"llm.prediction.temperature/title": "Temperatur",
	"llm.prediction.temperature/subTitle": "Hur mycket slumpm√§ssighet som ska introduceras. 0 ger samma resultat varje g√•ng, medan h√∂gre v√§rden √∂kar kreativiteten och variationen",
	"llm.prediction.temperature/info": "Fr√•n llama.cpp hj√§lpdokumentation: \"Standardv√§rdet √§r <{{dynamicValue}}>, vilket ger en balans mellan slumpm√§ssighet och determinism. I extrema fall kommer en temperatur p√• 0 alltid att v√§lja den mest sannolika n√§sta token, vilket leder till identiska utdata vid varje k√∂rning\"",
	"llm.prediction.llama.sampling/title": "Sampling",
	"llm.prediction.topKSampling/title": "Top K Sampling",
	"llm.prediction.topKSampling/subTitle": "Begr√§nsar n√§sta token till en av de top-k mest sannolika token. Fungerar liknande som temperatur",
	"llm.prediction.topKSampling/info": "Fr√•n llama.cpp hj√§lpdokumentation:\n\nTop-k sampling √§r en textgenereringsmetod som v√§ljer n√§sta tecken endast fr√•n de k mest sannolika som modellen f√∂rutsp√•r.\n\nDet hj√§lper till att minska risken f√∂r att generera l√•g-sannolikhet eller nonsens-tecken, men kan ocks√• begr√§nsa m√•ngfalden i utdata.\n\nEtt h√∂gre v√§rde f√∂r top-k (t.ex. 100) kommer att √∂verv√§ga fler tecken och leda till mer varierad text, medan ett l√§gre v√§rde (t.ex. 10) fokuserar p√• de mest sannolika och genererar mer konservativ text.\n\n‚Ä¢ Standardv√§rdet √§r <{{dynamicValue}}>",
	"llm.prediction.llama.cpuThreads/title": "CPU-tr√•dar",
	"llm.prediction.llama.cpuThreads/subTitle": "Antal CPU-tr√•dar att anv√§nda vid inferens",
	"llm.prediction.llama.cpuThreads/info": "Antalet tr√•dar som anv√§nds vid ber√§kning. Att √∂ka antalet tr√•dar ger inte alltid b√§ttre prestanda. Standardv√§rdet √§r <{{dynamicValue}}>.",
	"llm.prediction.maxPredictedTokens/title": "Begr√§nsa svarsl√§ngd",
	"llm.prediction.maxPredictedTokens/subTitle": "Valfritt begr√§nsa l√§ngden p√• AI:s svar",
	"llm.prediction.maxPredictedTokens/info": "Kontrollera maxl√§ngden p√• chatbotens svar. Sl√• p√• f√∂r att st√§lla in en gr√§ns f√∂r maxl√§ngden p√• ett svar, eller sl√• av f√∂r att l√•ta chatboten best√§mma n√§r den ska sluta.",
	"llm.prediction.maxPredictedTokens/inputLabel": "Maximal svarsl√§ngd (token)",
	"llm.prediction.maxPredictedTokens/wordEstimate": "Cirka {{maxWords}} ord",
	"llm.prediction.repeatPenalty/title": "Upprepningskontroll",
	"llm.prediction.repeatPenalty/subTitle": "Hur mycket upprepningar av samma token ska begr√§nsas",
	"llm.prediction.repeatPenalty/info": "Fr√•n llama.cpp hj√§lpdokument: \"Hj√§lper till att f√∂rhindra att modellen genererar repetitiv eller monoton text.\n\nEtt h√∂gre v√§rde (t.ex. 1.5) kommer att straffa upprepningar starkare, medan ett l√§gre v√§rde (t.ex. 0.9) kommer att vara mer f√∂rl√•tande.\" ‚Ä¢ Standardv√§rdet √§r <{{dynamicValue}}>",
	"llm.prediction.minPSampling/title": "Min P Sampling",
	"llm.prediction.minPSampling/subTitle": "Minsta basprobabilitet f√∂r en token att v√§ljas f√∂r utdata",
	"llm.prediction.minPSampling/info": "Fr√•n llama.cpp hj√§lpdokument:\n\nDen minsta sannolikheten f√∂r en token att √∂verv√§gas, relativt sannolikheten f√∂r den mest sannolika token. M√•ste vara i [0, 1].\n\n‚Ä¢ Standardv√§rdet √§r <{{dynamicValue}}>",
	"llm.prediction.topPSampling/title": "Top P Sampling",
	"llm.prediction.topPSampling/subTitle": "Minsta kumulativa sannolikhet f√∂r de m√∂jliga n√§sta token. Fungerar liknande som temperatur",
	"llm.prediction.topPSampling/info": "Fr√•n llama.cpp hj√§lpdokument:\n\nTop-p sampling, √§ven k√§nd som nucleus sampling, √§r en annan textgenereringsmetod som v√§ljer n√§sta token fr√•n en delm√§ngd av token som tillsammans har en kumulativ sannolikhet p√• minst p.\n\nDenna metod ger en balans mellan m√•ngfald och kvalitet genom att √∂verv√§ga b√•de sannolikheterna f√∂r token och antalet token att v√§lja fr√•n.\n\nEtt h√∂gre v√§rde f√∂r top-p (t.ex. 0.95) kommer att leda till mer varierad text, medan ett l√§gre v√§rde (t.ex. 0.5) kommer att generera mer fokuserad och konservativ text. M√•ste vara i (0, 1].\n\n‚Ä¢ Standardv√§rdet √§r <{{dynamicValue}}>",
	"llm.prediction.stopStrings/title": "Stoppstr√§ngar",
	"llm.prediction.stopStrings/subTitle": "Str√§ngar som ska stoppa modellen fr√•n att generera fler token",
	"llm.prediction.stopStrings/info": "Specifika str√§ngar som n√§r de p√•tr√§ffas kommer att stoppa modellen fr√•n att generera fler token",
	"llm.prediction.stopStrings/placeholder": "Ange en str√§ng och tryck p√• ‚èé",
	"llm.prediction.contextOverflowPolicy/title": "Kontext√∂verfl√∂d",
	"llm.prediction.contextOverflowPolicy/subTitle": "Hur modellen ska bete sig n√§r konversationen blir f√∂r stor f√∂r att hantera",
	"llm.prediction.contextOverflowPolicy/info": "Best√§m vad som ska g√∂ras n√§r konversationen √∂verskrider storleken p√• modellens arbetsminne ('kontext')",
	"llm.prediction.llama.frequencyPenalty/title": "Frekvensbegr√§nsning",
	"llm.prediction.llama.presencePenalty/title": "N√§rvarobegr√§nsning",
	"llm.prediction.llama.tailFreeSampling/title": "Tail-Free Sampling",
	"llm.prediction.llama.locallyTypicalSampling/title": "Lokalt typisk sampling",
	"llm.prediction.llama.xtcProbability/title": "XTC-sannolikhet",
	"llm.prediction.llama.xtcProbability/subTitle": "XTC (Exclude Top Choices) sampling aktiveras endast med denna sannolikhet per genererat tecken. XTC sampling kan √∂ka kreativiteten och minska klich√©er",
	"llm.prediction.llama.xtcProbability/info": "XTC (Exclude Top Choices) sampling aktiveras endast med denna sannolikhet per genererat tecken. XTC sampling √∂kar vanligtvis kreativiteten och minskar klich√©er",
	"llm.prediction.llama.xtcThreshold/title": "XTC-tr√∂skel",
	"llm.prediction.llama.xtcThreshold/subTitle": "XTC (Exclude Top Choices) tr√∂skel. Med en chans p√• `xtc-probability`, s√∂k efter tecken med sannolikheter mellan `xtc-threshold` och 0.5, och ta bort alla utom det minst sannolika",
	"llm.prediction.llama.xtcThreshold/info": "XTC (Exclude Top Choices) tr√∂skel. Med en chans p√• `xtc-probability`, s√∂k efter tecken med sannolikheter mellan `xtc-threshold` och 0.5, och ta bort alla utom det minst sannolika",
	"llm.prediction.mlx.topKSampling/title": "Top K Sampling",
	"llm.prediction.mlx.topKSampling/subTitle": "Begr√§nsar n√§sta tecken till en av de k mest sannolika. Fungerar liknande som temperatur",
	"llm.prediction.mlx.topKSampling/info": "Begr√§nsar n√§sta tecken till en av de k mest sannolika. Fungerar liknande som temperatur",
	"llm.prediction.onnx.topKSampling/title": "Top K Sampling",
	"llm.prediction.onnx.topKSampling/subTitle": "Begr√§nsar n√§sta token till en av de top-k mest sannolika token. Fungerar liknande som temperatur",
	"llm.prediction.onnx.topKSampling/info": "Fr√•n ONNX-dokumentation:\n\nAntal h√∂gsta sannolikhetsvokabul√§rtoken att beh√•lla f√∂r top-k-filtrering\n\n‚Ä¢ Detta filter √§r avst√§ngt som standard",
	"llm.prediction.onnx.repeatPenalty/title": "Upprepningskontroll",
	"llm.prediction.onnx.repeatPenalty/subTitle": "Hur mycket upprepningar av samma token ska begr√§nsas",
	"llm.prediction.onnx.repeatPenalty/info": "Ett h√∂gre v√§rde avskr√§cker modellen fr√•n att upprepa sig sj√§lv",
	"llm.prediction.onnx.topPSampling/title": "Top P Sampling",
	"llm.prediction.onnx.topPSampling/subTitle": "Minsta kumulativa sannolikhet f√∂r de m√∂jliga n√§sta token. Fungerar liknande som temperatur",
	"llm.prediction.onnx.topPSampling/info": "Fr√•n ONNX-dokumentation:\n\nEndast de mest sannolika token med sannolikheter som tillsammans uppg√•r till TopP eller h√∂gre beh√•lls f√∂r generering\n\n‚Ä¢ Detta filter √§r avst√§ngt som standard",
	"llm.prediction.seed/title": "Seed",
	"llm.prediction.structured/title": "Strukturerad utdata",
	"llm.prediction.structured/info": "Strukturerad utdata",
	"llm.prediction.structured/description": "Avancerat: du kan tillhandah√•lla ett JSON-schema f√∂r att uppr√§tth√•lla ett specifikt utdataformat fr√•n modellen. L√§s [dokumentationen](https://lmstudio.ai/docs/advanced/structured-output) f√∂r att l√§ra dig mer",
	"llm.prediction.promptTemplate/title": "Promptmall",
	"llm.prediction.promptTemplate/subTitle": "Formatet i vilket meddelanden i chatten skickas till modellen. Att √§ndra detta kan introducera ov√§ntat beteende - se till att du vet vad du g√∂r!",
	"llm.load.contextLength/title": "Kontextl√§ngd",
	"llm.load.contextLength/subTitle": "Det maximala antalet token som modellen kan hantera i en prompt. Se alternativen f√∂r kontext√∂verfl√∂d under \"Prediktionsparametrar\" f√∂r fler s√§tt att hantera detta",
	"llm.load.contextLength/info": "Anger det maximala antalet token som modellen kan √∂verv√§ga samtidigt, vilket p√•verkar hur mycket kontext den beh√•ller under bearbetning",
	"llm.load.contextLength/warning": "Att st√§lla in ett h√∂gt v√§rde f√∂r kontextl√§ngd kan avsev√§rt p√•verka minnesanv√§ndningen",
	"llm.load.seed/title": "Seed",
	"llm.load.seed/subTitle": "Seed f√∂r slumptalsgeneratorn som anv√§nds vid textgenerering. -1 √§r slumpm√§ssig",
	"llm.load.seed/info": "Slumpm√§ssig Seed: St√§ller in seed f√∂r slumptalsgenerering f√∂r att s√§kerst√§lla reproducerbara resultat",
	
	"llm.load.llama.evalBatchSize/title": "Utv√§rderingsbatchstorlek",
	"llm.load.llama.evalBatchSize/subTitle": "Antal inmatningstokens att bearbeta √•t g√•ngen. Att √∂ka detta √∂kar prestandan men kr√§ver mer minne",
	"llm.load.llama.evalBatchSize/info": "Anger antalet exempel som bearbetas tillsammans i en batch under utv√§rdering, vilket p√•verkar hastighet och minnesanv√§ndning",
	"llm.load.llama.ropeFrequencyBase/title": "RoPE-frekvensbas",
	"llm.load.llama.ropeFrequencyBase/subTitle": "Anpassad basfrekvens f√∂r roterande positionsinb√§ddningar (RoPE). Att √∂ka detta kan ge b√§ttre prestanda vid h√∂ga kontextl√§ngder",
	"llm.load.llama.ropeFrequencyBase/info": "[Avancerat] Justerar basfrekvensen f√∂r Rotary Positional Encoding, vilket p√•verkar hur positionsinformation b√§ddas in",
	"llm.load.llama.ropeFrequencyScale/title": "RoPE-frekvensskalning",
	"llm.load.llama.ropeFrequencyScale/subTitle": "Kontextl√§ngden skalas med denna faktor f√∂r att f√∂rl√§nga effektiv kontext med RoPE",
	"llm.load.llama.ropeFrequencyScale/info": "[Avancerat] √Ñndrar skalningen av frekvensen f√∂r Rotary Positional Encoding f√∂r att styra granulariteten i positionsinb√§ddningen",
	"llm.load.llama.acceleration.offloadRatio/title": "GPU-offload",
	"llm.load.llama.acceleration.offloadRatio/subTitle": "Antal diskreta modellager att ber√§kna p√• GPU f√∂r GPU-acceleration",
	"llm.load.llama.acceleration.offloadRatio/info": "St√§ll in antalet lager som ska avlastas till GPU:n.",
	"llm.load.llama.flashAttention/title": "Flash Attention",
	"llm.load.llama.flashAttention/subTitle": "Minskar minnesanv√§ndning och genereringstid f√∂r vissa modeller",
	"llm.load.llama.flashAttention/info": "Snabbar upp attention-mekanismer f√∂r snabbare och effektivare bearbetning",
	"llm.load.numExperts/title": "Antal experter",
	"llm.load.numExperts/subTitle": "Antal experter att anv√§nda i modellen",
	"llm.load.numExperts/info": "Antalet experter att anv√§nda i modellen",
	"llm.load.llama.keepModelInMemory/title": "Beh√•ll modell i minnet",
	"llm.load.llama.keepModelInMemory/subTitle": "Reservera systemminne f√∂r modellen, √§ven n√§r den avlastas till GPU. F√∂rb√§ttrar prestanda men kr√§ver mer system-RAM",
	"llm.load.llama.keepModelInMemory/info": "F√∂rhindrar att modellen byts ut till disk, vilket s√§kerst√§ller snabbare √•tkomst p√• bekostnad av h√∂gre RAM-anv√§ndning",
	"llm.load.llama.useFp16ForKVCache/title": "Anv√§nd FP16 f√∂r KV-cache",
	"llm.load.llama.useFp16ForKVCache/info": "Minskar minnesanv√§ndningen genom att lagra cache i halvprecision (FP16)",
	"llm.load.llama.tryMmap/title": "F√∂rs√∂k med mmap()",
	"llm.load.llama.tryMmap/subTitle": "F√∂rb√§ttrar inl√§sningstiden f√∂r modellen. Att inaktivera detta kan f√∂rb√§ttra prestandan n√§r modellen √§r st√∂rre √§n tillg√§ngligt systemminne",
	"llm.load.llama.tryMmap/info": "L√§s in modellfiler direkt fr√•n disk till minne",
	"llm.load.llama.cpuThreadPoolSize/title": "CPU-tr√•dpoolstorlek",
	"llm.load.llama.cpuThreadPoolSize/subTitle": "Antal CPU-tr√•dar att tilldela tr√•dpoolen som anv√§nds f√∂r modellber√§kning",
	"llm.load.llama.cpuThreadPoolSize/info": "Antal CPU-tr√•dar att tilldela tr√•dpoolen som anv√§nds f√∂r modellber√§kning. Att √∂ka antalet tr√•dar ger inte alltid b√§ttre prestanda. Standardv√§rdet √§r <{{dynamicValue}}>",
	"llm.load.llama.kCacheQuantizationType/title": "K-cache-kvantiseringstyp",
	"llm.load.llama.kCacheQuantizationType/subTitle": "L√§gre v√§rden minskar minnesanv√§ndningen men kan f√∂rs√§mra kvaliteten. Effekten varierar mycket mellan modeller.",
	"llm.load.llama.vCacheQuantizationType/title": "V-cache-kvantiseringstyp",
	"llm.load.llama.vCacheQuantizationType/subTitle": "L√§gre v√§rden minskar minnesanv√§ndningen men kan f√∂rs√§mra kvaliteten. Effekten varierar mycket mellan modeller.",
	"llm.load.llama.vCacheQuantizationType/turnedOnWarning": "‚ö†Ô∏è Du m√•ste inaktivera detta v√§rde om Flash Attention inte √§r aktiverat",
	"llm.load.llama.vCacheQuantizationType/disabledMessage": "Kan endast aktiveras n√§r Flash Attention √§r aktiverat",
	"llm.load.llama.vCacheQuantizationType/invalidF32MetalState": "‚ö†Ô∏è Du m√•ste inaktivera Flash Attention n√§r du anv√§nder F32",
	"llm.load.mlx.kvCacheBits/title": "KV-cache-kvantisering",
	"llm.load.mlx.kvCacheBits/subTitle": "Antal bitar som KV-cachen ska kvantiseras till",
	"llm.load.mlx.kvCacheBits/info": "Antal bitar som KV-cachen ska kvantiseras till",
	"llm.load.mlx.kvCacheBits/turnedOnWarning": "Inst√§llningen f√∂r kontextl√§ngd ignoreras n√§r KV-cache-kvantisering anv√§nds",
	"llm.load.mlx.kvCacheGroupSize/title": "KV-cache-kvantisering: Gruppstorlek",
	"llm.load.mlx.kvCacheGroupSize/subTitle": "Gruppstorlek vid kvantiseringsoperationen f√∂r KV-cachen. H√∂gre gruppstorlek minskar minnesanv√§ndningen men kan f√∂rs√§mra kvaliteten",
	"llm.load.mlx.kvCacheGroupSize/info": "Antal bitar som KV-cachen ska kvantiseras till",
	"llm.load.mlx.kvCacheQuantizationStart/title": "KV-cache-kvantisering: B√∂rja kvantisera n√§r kontexten passerar denna l√§ngd",
	"llm.load.mlx.kvCacheQuantizationStart/subTitle": "Kontextl√§ngdstr√∂skel f√∂r att b√∂rja kvantisera KV-cachen",
	"llm.load.mlx.kvCacheQuantizationStart/info": "Kontextl√§ngdstr√∂skel f√∂r att b√∂rja kvantisera KV-cachen",
	"llm.load.mlx.kvCacheQuantization/title": "KV-cache-kvantisering",
	"llm.load.mlx.kvCacheQuantization/subTitle": "Kvantisera modellens KV-cache. Detta kan ge snabbare generering och l√§gre minnesanv√§ndning,\np√• bekostnad av modellens utdata-kvalitet.",
	"llm.load.mlx.kvCacheQuantization/bits/title": "KV-cache-kvantiseringsbitar",
	"llm.load.mlx.kvCacheQuantization/bits/tooltip": "Antal bitar att kvantisera KV-cachen till",
	"llm.load.mlx.kvCacheQuantization/bits/bits": "Bitar",
	"llm.load.mlx.kvCacheQuantization/groupSize/title": "Gruppstorleksstrategi",
	"llm.load.mlx.kvCacheQuantization/groupSize/accuracy": "Noggrannhet",
	"llm.load.mlx.kvCacheQuantization/groupSize/balanced": "Balanserad",
	"llm.load.mlx.kvCacheQuantization/groupSize/speedy": "Snabb",
	"llm.load.mlx.kvCacheQuantization/groupSize/tooltip": "Avancerat: Kvantiserad 'matmul group size'-konfiguration\n\n‚Ä¢ Noggrannhet = gruppstorlek 32\n‚Ä¢ Balanserad = gruppstorlek 64\n‚Ä¢ Snabb = gruppstorlek 128\n",
	"llm.load.mlx.kvCacheQuantization/quantizedStart/title": "B√∂rja kvantisera n√§r kontexten n√•r denna l√§ngd",
	"llm.load.mlx.kvCacheQuantization/quantizedStart/tooltip": "N√§r kontexten n√•r detta antal tokens,\nb√∂rja kvantisera KV-cachen",

	"embedding.load.contextLength/title": "Kontextl√§ngd",
	"embedding.load.contextLength/subTitle": "Maximalt antal tokens modellen kan hantera i en prompt. Se alternativen f√∂r kontext√∂verskridande under \"Inferensparametrar\" f√∂r fler s√§tt att hantera detta",
	"embedding.load.contextLength/info": "Anger det maximala antalet tokens modellen kan ta h√§nsyn till samtidigt, vilket p√•verkar hur mycket kontext den beh√•ller under bearbetning",
	"embedding.load.llama.ropeFrequencyBase/title": "RoPE-frekvensbas",
	"embedding.load.llama.ropeFrequencyBase/subTitle": "Anpassad basfrekvens f√∂r roterande positionsinb√§ddningar (RoPE). Att √∂ka detta kan ge b√§ttre prestanda vid h√∂ga kontextl√§ngder",
	"embedding.load.llama.ropeFrequencyBase/info": "[Avancerat] Justerar basfrekvensen f√∂r Rotary Positional Encoding, vilket p√•verkar hur positionsinformation b√§ddas in",
	"embedding.load.llama.evalBatchSize/title": "Utv√§rderingsbatchstorlek",
	"embedding.load.llama.evalBatchSize/subTitle": "Antal inmatningstokens att bearbeta √•t g√•ngen. Att √∂ka detta √∂kar prestandan men kr√§ver mer minne",
	"embedding.load.llama.evalBatchSize/info": "Anger antalet tokens som bearbetas tillsammans i en batch under utv√§rdering",
	"embedding.load.llama.ropeFrequencyScale/title": "RoPE-frekvensskalning",
	"embedding.load.llama.ropeFrequencyScale/subTitle": "Kontextl√§ngden skalas med denna faktor f√∂r att f√∂rl√§nga effektiv kontext med RoPE",
	"embedding.load.llama.ropeFrequencyScale/info": "[Avancerat] √Ñndrar skalningen av frekvensen f√∂r Rotary Positional Encoding f√∂r att styra granulariteten i positionsinb√§ddningen",
	"embedding.load.llama.acceleration.offloadRatio/title": "GPU-offload",
	"embedding.load.llama.acceleration.offloadRatio/subTitle": "Antal diskreta modellager att ber√§kna p√• GPU f√∂r GPU-acceleration",
	"embedding.load.llama.acceleration.offloadRatio/info": "St√§ll in antalet lager som ska avlastas till GPU:n.",
	"embedding.load.llama.keepModelInMemory/title": "Beh√•ll modell i minnet",
	"embedding.load.llama.keepModelInMemory/subTitle": "Reservera systemminne f√∂r modellen, √§ven n√§r den avlastas till GPU. F√∂rb√§ttrar prestanda men kr√§ver mer RAM",
	"embedding.load.llama.keepModelInMemory/info": "F√∂rhindrar att modellen swappas ut till disk, vilket ger snabbare √•tkomst p√• bekostnad av h√∂gre RAM-anv√§ndning",
	"embedding.load.llama.tryMmap/title": "F√∂rs√∂k med mmap()",
	"embedding.load.llama.tryMmap/subTitle": "F√∂rb√§ttrar inl√§sningstiden f√∂r modellen. Att inaktivera detta kan f√∂rb√§ttra prestandan n√§r modellen √§r st√∂rre √§n tillg√§ngligt systemminne",
	"embedding.load.llama.tryMmap/info": "L√§s in modellfiler direkt fr√•n disk till minne",
	"embedding.load.seed/title": "Seed",
	"embedding.load.seed/subTitle": "Seed f√∂r slumptalsgeneratorn som anv√§nds vid textgenerering. -1 √§r slumpm√§ssig",

	"embedding.load.seed/info": "Slumpm√§ssig Seed: St√§ller in seed f√∂r slumptalsgenerering f√∂r att s√§kerst√§lla reproducerbara resultat",

	"presetTooltip": {
		"included/title": "F√∂rinst√§llda v√§rden",
		"included/description": "F√∂ljande f√§lt kommer att till√§mpas",
		"included/empty": "Inga f√§lt i denna f√∂rinst√§llning g√§ller i detta sammanhang.",
		"included/conflict": "Du kommer att bli ombedd att v√§lja om detta v√§rde ska till√§mpas",
		"separateLoad/title": "Konfiguration vid inl√§sning",
		"separateLoad/description.1": "F√∂rinst√§llningen inneh√•ller √§ven f√∂ljande konfiguration vid inl√§sning. Konfiguration vid inl√§sning g√§ller f√∂r hela modellen och kr√§ver att modellen laddas om f√∂r att tr√§da i kraft. H√•ll ned",
		"separateLoad/description.2": "f√∂r att till√§mpa p√•",
		"separateLoad/description.3": ".",
		"excluded/title": "Kanske inte g√§ller",
		"excluded/description": "F√∂ljande f√§lt ing√•r i f√∂rinst√§llningen men g√§ller inte i det aktuella sammanhanget.",
		"legacy/title": "Legacy-f√∂rinst√§llning",
		"legacy/description": "Denna f√∂rinst√§llning √§r en √§ldre f√∂rinst√§llning. Den inneh√•ller f√∂ljande f√§lt som antingen hanteras automatiskt nu eller inte l√§ngre √§r till√§mpliga.",
		"button/publish": "Publicera till Hub",
		"button/pushUpdate": "Skicka √§ndringar till Hub",
		"button/noChangesToPush": "Inga √§ndringar att skicka",
		"button/export": "Exportera",
		"hubLabel": "F√∂rinst√§llning fr√•n Hub av {{user}}",
		"ownHubLabel": "Din f√∂rinst√§llning fr√•n Hub"
	},

  "customInputs": {
    "string": {
      "emptyParagraph": "<Tom>"
    },
		"checkboxNumeric": {
			"off": "AV"
		},
		"llamaCacheQuantizationType": {
			"off": "AV"
		},
		"mlxKvCacheBits": {
			"off": "AV"
    },
    "stringArray": {
      "empty": "<Tom>"
    },
		"llmPromptTemplate": {
			"type": "Typ",
			"types.jinja/label": "Mall (Jinja)",
			"jinja.bosToken/label": "BOS-token",
			"jinja.eosToken/label": "EOS-token",
			"jinja.template/label": "Mall",
			"jinja/error": "Misslyckades med att tolka Jinja-mall: {{error}}",
			"jinja/empty": "Ange en Jinja-mall ovan.",
			"jinja/unlikelyToWork": "Jinja-mallen du angav ovan verkar inte fungera eftersom den inte refererar till variabeln \"messages\". Kontrollera att du har angett en korrekt mall.",
			"types.manual/label": "Manuell",
			"manual.subfield.beforeSystem/label": "F√∂re System",
			"manual.subfield.beforeSystem/placeholder": "Ange systemprefix...",
			"manual.subfield.afterSystem/label": "Efter System",
			"manual.subfield.afterSystem/placeholder": "Ange systemsuffix...",
			"manual.subfield.beforeUser/label": "F√∂re Anv√§ndare",
			"manual.subfield.beforeUser/placeholder": "Ange anv√§ndarprefix...",
			"manual.subfield.afterUser/label": "Efter Anv√§ndare",
			"manual.subfield.afterUser/placeholder": "Ange anv√§ndarsuffix...",
			"manual.subfield.beforeAssistant/label": "F√∂re Assistent",
			"manual.subfield.beforeAssistant/placeholder": "Ange assistentprefix...",
			"manual.subfield.afterAssistant/label": "Efter Assistent",
			"manual.subfield.afterAssistant/placeholder": "Ange Assistent-suffix...",
			"stopStrings/label": "Ytterligare Stoppstr√§ngar",
			"stopStrings/subTitle": "Mall-specifika stoppstr√§ngar som kommer att anv√§ndas ut√∂ver anv√§ndarspecificerade stoppstr√§ngar."
    },
		"contextLength": {
			"maxValueTooltip": "Detta √§r det maximala antalet token som modellen tr√§nades f√∂r att hantera. Klicka f√∂r att s√§tta kontexten till detta v√§rde",
			"maxValueTextStart": "Modellen st√∂der upp till",
			"maxValueTextEnd": "token",
			"tooltipHint": "√Ñven om en modell kan st√∂dja upp till ett visst antal token, kan prestandan f√∂rs√§mras om din dators resurser inte r√§cker till ‚Äì var f√∂rsiktig n√§r du √∂kar detta v√§rde"
		},
		"contextOverflowPolicy": {
			"stopAtLimit": "Stoppa vid gr√§ns",
			"stopAtLimitSub": "Sluta generera n√§r modellens minne √§r fullt",
			"truncateMiddle": "Trunkera mitten",
			"truncateMiddleSub": "Tar bort meddelanden fr√•n mitten av konversationen f√∂r att ge plats √•t nya. Modellen kommer fortfarande ih√•g b√∂rjan av konversationen",
			"rollingWindow": "Rullande f√∂nster",
			"rollingWindowSub": "Modellen f√•r alltid de senaste meddelandena men kan gl√∂mma b√∂rjan av konversationen"
		},
    "llamaAccelerationOffloadRatio": {
      "max": "MAX",
      "off": "AV"
    },
		"gpuSplitStrategy": {
			"evenly": "Dela j√§mnt",
			"favorMainGpu": "Prioritera huvud-GPU"
		},
		"speculativeDecodingDraftModel": {
			"readMore": "L√§s hur det fungerar",
			"placeholder": "V√§lj en kompatibel utkastmodell",
			"noCompatible": "Inga kompatibla utkastmodeller hittades f√∂r din nuvarande modellval",
			"stillLoading": "Identifierar kompatibla utkastmodeller...",
			"notCompatible": "Den valda utkastmodellen (<draft/>) √§r inte kompatibel med det aktuella modellvalet (<current/>).",
			"off": "AV",
			"loadModelToSeeOptions": "Ladda modell <keyboard-shortcut /> f√∂r att se kompatibla alternativ",
			"compatibleWithNumberOfModels": "Rekommenderas f√∂r minst {{dynamicValue}} av dina modeller",
			"recommendedForSomeModels": "Rekommenderas f√∂r vissa modeller",
			"recommendedForLlamaModels": "Rekommenderas f√∂r Llama-modeller",
			"recommendedForQwenModels": "Rekommenderas f√∂r Qwen-modeller",
			"onboardingModal": {
			"introducing": "Introducerar",
			"speculativeDecoding": "Spekulativ avkodning",
			"firstStepBody": "Snabbare inferens f√∂r <custom-span>llama.cpp</custom-span> och <custom-span>MLX</custom-span>-modeller",
			"secondStepTitle": "Snabbare inferens med spekulativ avkodning",
			"secondStepBody": "Spekulativ avkodning √§r en teknik d√§r tv√• modeller samarbetar:\n - En st√∂rre \"huvud\"modell\n - En mindre \"utkast\"modell\n\nUnder generering f√∂resl√•r utkastmodellen snabbt tokens som den st√∂rre huvudmodellen verifierar. Att verifiera tokens √§r mycket snabbare √§n att faktiskt generera dem, vilket ger hastighetsvinster. **Generellt g√§ller att ju st√∂rre skillnad i storlek mellan huvudmodellen och utkastmodellen, desto st√∂rre hastighets√∂kning**.\n\nF√∂r att bibeh√•lla kvalitet accepterar huvudmodellen endast tokens som st√§mmer √∂verens med vad den sj√§lv skulle ha genererat, vilket m√∂jligg√∂r svarskvaliteten fr√•n den st√∂rre modellen men med snabbare inferens. B√•da modellerna m√•ste dela samma vokabul√§r.",
			"draftModelRecommendationsTitle": "Rekommendationer f√∂r utkastmodell",
			"basedOnCurrentModels": "Baserat p√• dina nuvarande modeller",
			"close": "St√§ng",
			"next": "N√§sta",
			"done": "Klar"
			},
			"speculativeDecodingLoadModelToSeeOptions": "Ladda f√∂rst en modell <model-badge /> ",
			"errorEngineNotSupported": "Spekulativ avkodning kr√§ver minst version {{minVersion}} av motorn {{engineName}}. Uppdatera motorn (<key/>) och ladda om modellen f√∂r att anv√§nda denna funktion.",
			"errorEngineNotSupported/noKey": "Spekulativ avkodning kr√§ver minst version {{minVersion}} av motorn {{engineName}}. Uppdatera motorn och ladda om modellen f√∂r att anv√§nda denna funktion."
		},
		"llmReasoningParsing": {
			"startString/label": "Startstr√§ng",
			"startString/placeholder": "Ange startstr√§ng...",
			"endString/label": "Slutstr√§ng",
			"endString/placeholder": "Ange slutstr√§ng..."
		}
  },
	"saveConflictResolution": {
		"title": "V√§lj vilka v√§rden som ska inkluderas i f√∂rinst√§llningen",
		"description": "V√§lj vilka v√§rden du vill beh√•lla",
		"instructions": "Klicka p√• ett v√§rde f√∂r att inkludera det",
		"userValues": "Tidigare v√§rde",
		"presetValues": "Nytt v√§rde",
		"confirm": "Bekr√§fta",
		"cancel": "Avbryt"
	},
	"applyConflictResolution": {
		"title": "Vilka v√§rden ska beh√•llas?",
		"description": "Du har osparade √§ndringar som √∂verlappar med den inkommande f√∂rinst√§llningen",
		"instructions": "Klicka p√• ett v√§rde f√∂r att beh√•lla det",
		"userValues": "Nuvarande v√§rde",
		"presetValues": "Inkommande f√∂rinst√§llningsv√§rde",
		"confirm": "Bekr√§fta",
		"cancel": "Avbryt"
	},
	"empty": "<Tom>",
	"noModelSelected": "Ingen modell vald",
	"apiIdentifier.label": "API-identifierare",
	"apiIdentifier.hint": "Ange valfritt en identifierare f√∂r denna modell. Den kommer att anv√§ndas i API-f√∂rfr√•gningar. L√§mna tomt f√∂r att anv√§nda standardidentifieraren.",
	"idleTTL.label": "Ladda ur automatiskt vid inaktivitet (TTL)",
	"idleTTL.hint": "Om angivet kommer modellen automatiskt att laddas ur efter att ha varit inaktiv under angiven tid.",
	"idleTTL.mins": "min",

	"presets": {
		"title": "F√∂rinst√§llning",
		"commitChanges": "Spara √§ndringar",
		"commitChanges/description": "Spara dina √§ndringar i f√∂rinst√§llningen.",
		"commitChanges.manual": "Nya f√§lt uppt√§ckta. Du kommer att kunna v√§lja vilka √§ndringar som ska inkluderas i f√∂rinst√§llningen.",
		"commitChanges.manual.hold.0": "H√•ll ned",
		"commitChanges.manual.hold.1": "f√∂r att v√§lja vilka √§ndringar som ska sparas i f√∂rinst√§llningen.",
		"commitChanges.saveAll.hold.0": "H√•ll ned",
		"commitChanges.saveAll.hold.1": "f√∂r att spara alla √§ndringar.",
		"commitChanges.saveInPreset.hold.0": "H√•ll ned",
		"commitChanges.saveInPreset.hold.1": "f√∂r att endast spara √§ndringar i f√§lt som redan ing√•r i f√∂rinst√§llningen.",
		"commitChanges/error": "Misslyckades med att spara √§ndringar i f√∂rinst√§llningen.",
		"commitChanges.manual/description": "V√§lj vilka √§ndringar som ska inkluderas i f√∂rinst√§llningen.",
		"saveAs": "Spara som ny...",
		"presetNamePlaceholder": "Ange ett namn f√∂r f√∂rinst√§llningen...",
		"cannotCommitChangesLegacy": "Detta √§r en √§ldre f√∂rinst√§llning och kan inte √§ndras. Du kan skapa en kopia genom att anv√§nda \"Spara som ny...\".",
		"cannotCommitChangesNoChanges": "Inga √§ndringar att spara.",
		"emptyNoUnsaved": "V√§lj en f√∂rinst√§llning...",
		"emptyWithUnsaved": "Osparad f√∂rinst√§llning",
		"saveEmptyWithUnsaved": "Spara f√∂rinst√§llning som...",
		"saveConfirm": "Spara",
		"saveCancel": "Avbryt",
		"saving": "Sparar...",
		"save/error": "Misslyckades med att spara f√∂rinst√§llningen.",
		"deselect": "Avmarkera f√∂rinst√§llning",
		"deselect/error": "Misslyckades med att avmarkera f√∂rinst√§llningen.",
		"select/error": "Misslyckades med att v√§lja f√∂rinst√§llning.",
		"delete/error": "Misslyckades med att radera f√∂rinst√§llning.",
		"discardChanges": "Kasta osparade",
		"discardChanges/info": "Kasta alla osparade √§ndringar och √•terst√§ll f√∂rinst√§llningen till ursprungligt tillst√•nd",
		"newEmptyPreset": "+ Ny f√∂rinst√§llning",
		"importPreset": "Importera",
		"contextMenuCopyIdentifier": "Kopiera f√∂rinst√§llnings-ID",
		"contextMenuSelect": "Anv√§nd f√∂rinst√§llning",
		"contextMenuDelete": "Ta bort...",
		"contextMenuShare": "Publicera...",
		"contextMenuOpenInHub": "Visa p√• webben",
		"contextMenuPullFromHub": "H√§mta senaste",
		"contextMenuPushChanges": "Skicka √§ndringar till Hub",
		"contextMenuPushingChanges": "Skickar...",
		"contextMenuPushedChanges": "√Ñndringar skickade",
		"contextMenuExport": "Exportera fil",
		"contextMenuRevealInExplorer": "Visa i Utforskaren",
		"contextMenuRevealInFinder": "Visa i Finder",
		"share": {
			"title": "Publicera f√∂rinst√§llning",
			"action": "Dela din f√∂rinst√§llning s√• att andra kan ladda ner, gilla och f√∂rgrena den",
			"presetOwnerLabel": "√Ñgare",
			"uploadAs": "Din f√∂rinst√§llning kommer att skapas som {{name}}",
			"presetNameLabel": "F√∂rinst√§llningsnamn",
			"descriptionLabel": "Beskrivning (valfritt)",
			"loading": "Publicerar...",
			"success": "F√∂rinst√§llning publicerad",
			"presetIsLive": "<preset-name /> √§r nu live p√• Hub!",
			"close": "St√§ng",
			"confirmViewOnWeb": "Visa p√• webben",
			"confirmCopy": "Kopiera URL",
			"confirmCopied": "Kopierad!",
			"pushedToHub": "Din f√∂rinst√§llning har skickats till Hub",
			"descriptionPlaceholder": "Ange en beskrivning...",
			"willBePublic": "Denna f√∂rinst√§llning blir offentlig. Alla p√• internet kan se den.",
			"willBePrivate": "Endast du kan se denna f√∂rinst√§llning",
			"willBeOrgVisible": "Denna f√∂rinst√§llning blir synlig f√∂r alla i organisationen.",
			"publicSubtitle": "Din f√∂rinst√§llning √§r <custom-bold>Offentlig</custom-bold>. Andra kan ladda ner och f√∂rgrena den p√• lmstudio.ai",
			"privateUsageReached": "Gr√§nsen f√∂r antal privata f√∂rinst√§llningar har uppn√•tts.",
			"continueInBrowser": "Forts√§tt i webbl√§sare",
			"confirmShareButton": "Publicera",
			"error": "Misslyckades med att publicera f√∂rinst√§llning",
			"createFreeAccount": "Skapa ett gratis konto i Hub f√∂r att publicera f√∂rinst√§llningar"
		},
		"update": {
			"title": "Skicka √§ndringar till Hub",
			"title/success": "F√∂rinst√§llning uppdaterad",
			"subtitle": "G√∂r √§ndringar i <custom-preset-name /> och skicka dem till Hub",
			"descriptionLabel": "Beskrivning",
			"descriptionPlaceholder": "Ange en beskrivning...",
			"loading": "Skickar...",
			"cancel": "Avbryt",
			"createFreeAccount": "Skapa ett gratis konto i Hub f√∂r att publicera f√∂rinst√§llningar",
			"error": "Misslyckades med att skicka uppdatering",
			"confirmUpdateButton": "Skicka"
		},
		"resolve": {
			"title": "L√∂s konflikter...",
			"tooltip": "√ñppna en dialog f√∂r att l√∂sa skillnader med Hub-versionen"
		},
		"loginToManage": {
			"title": "Logga in f√∂r att hantera..."
		},
		"downloadFromHub": {
			"title": "Ladda ner",
			"downloading": "Laddar ner...",
			"success": "Nedladdad!",
			"error": "Misslyckades med att ladda ner"
		},
		"push": {
			"title": "Skicka √§ndringar",
			"pushing": "Skickar...",
			"success": "Skickad",
			"tooltip": "Skicka dina lokala √§ndringar till den fj√§rrversion som finns p√• Hub",
			"error": "Misslyckades med att skicka"
		},
		"saveAsNewModal": {
			"title": "Hoppsan! Hittade inte f√∂rinst√§llningen p√• Hub",
			"confirmSaveAsNewDescription": "Vill du publicera denna f√∂rinst√§llning som en ny?",
			"confirmButton": "Publicera som ny"
		},
		"pull": {
			"title": "H√§mta senaste",
			"error": "Misslyckades med att h√§mta",
			"contextMenuErrorMessage": "Misslyckades med att h√§mta",
			"success": "H√§mtad",
			"pulling": "H√§mtar...",
			"upToDate": "Uppdaterad!",
			"unsavedChangesModal": {
				"title": "Du har osparade √§ndringar.",
				"bodyContent": "Att h√§mta fr√•n fj√§rrenheten kommer att skriva √∂ver dina osparade √§ndringar. Forts√§tt?",
				"confirmButton": "Skriv √∂ver osparade √§ndringar"
			}
		},
		"import": {
			"title": "Importera en f√∂rinst√§llning fr√•n fil",
			"dragPrompt": "Dra och sl√§pp f√∂rinst√§llningsfiler (.tar.gz eller preset.json) eller <custom-link>v√§lj fr√•n din dator</custom-link>",
			"remove": "Ta bort",
			"cancel": "Avbryt",
			"importPreset_zero": "Importera f√∂rinst√§llning",
			"importPreset_one": "Importera f√∂rinst√§llning",
			"importPreset_other": "Importera {{count}} f√∂rinst√§llningar",
			"selectDialog": {
				"title": "V√§lj f√∂rinst√§llningsfil (preset.json eller .tar.gz)",
				"button": "Importera"
			},
			"error": "Misslyckades med att importera f√∂rinst√§llning",
			"resultsModal": {
				"titleSuccessSection_one": "1 f√∂rinst√§llning importerad",
				"titleSuccessSection_other": "{{count}} f√∂rinst√§llningar importerade",
				"titleFailSection_zero": "",
				"titleFailSection_one": "({{count}} misslyckades)",
				"titleFailSection_other": "({{count}} misslyckades)",
				"titleAllFailed": "Misslyckades med att importera f√∂rinst√§llningar",
				"importMore": "Importera fler",
				"close": "Klar",
				"successBadge": "Lyckades",
				"alreadyExistsBadge": "F√∂rinst√§llning finns redan",
				"errorBadge": "Fel",
				"invalidFileBadge": "Ogiltig fil",
				"otherErrorBadge": "Misslyckades med att importera f√∂rinst√§llning",
				"errorViewDetailsButton": "Visa detaljer",
				"seeError": "Visa fel",
				"noName": "Inget namn",
				"useInChat": "Anv√§nd i chatt"
			},
			"importFromUrl": {
				"button": "Importera fr√•n URL...",
				"title": "Importera fr√•n URL",
				"back": "Importera fr√•n fil...",
				"action": "Klistra in LM Studio Hub-URL:en f√∂r f√∂rinst√§llningen du vill importera nedan",
				"invalidUrl": "Ogiltig URL. Kontrollera att du klistrar in en korrekt LM Studio Hub-URL.",
				"tip": "Du kan installera f√∂rinst√§llningen direkt med knappen {{buttonName}} i LM Studio Hub",
				"confirm": "Importera",
				"cancel": "Avbryt",
				"loading": "Importerar...",
				"error": "Misslyckades med att ladda ner f√∂rinst√§llning."
			}
		},
		"download": {
			"title": "H√§mta <preset-name /> fr√•n LM Studio Hub",
			"subtitle": "Spara <custom-name /> till dina f√∂rinst√§llningar. D√• kan du anv√§nda denna f√∂rinst√§llning i appen",
			"button": "H√§mta",
			"button/loading": "H√§mtar...",
			"cancel": "Avbryt",
			"error": "Misslyckades med att ladda ner f√∂rinst√§llning."
		},
		"inclusiveness": {
			"speculativeDecoding": "Inkludera i f√∂rinst√§llning"
		}
	},

	"flashAttentionWarning": "Flash Attention √§r en experimentell funktion som kan orsaka problem med vissa modeller. Om du st√∂ter p√• problem, f√∂rs√∂k att inaktivera den.",
	"llamaKvCacheQuantizationWarning": "KV-cache-kvantisering √§r en experimentell funktion som kan orsaka problem med vissa modeller. Flash Attention m√•ste vara aktiverat f√∂r V-cache-kvantisering. Om du st√∂ter p√• problem, √•terst√§ll till standardv√§rdet \"F16\".",

	"seedUncheckedHint": "Slumpm√§ssig Seed",
	"ropeFrequencyBaseUncheckedHint": "Auto",
	"ropeFrequencyScaleUncheckedHint": "Auto",

	"hardware": {
		"environmentVariables": "Milj√∂variabler",
		"environmentVariables.info": "Om du √§r os√§ker, l√§mna dessa p√• standardv√§rdena",
		"environmentVariables.reset": "√Öterst√§ll till standard",

		"gpus.information": "Konfigurera grafikkort (GPU:er) som uppt√§ckts p√• din dator",
		"gpuSettings": {
			"editMaxCapacity": "Redigera maxkapacitet",
			"hideEditMaxCapacity": "D√∂lj redigera maxkapacitet",
			"allOffWarning": "Alla GPU:er √§r avst√§ngda eller inaktiverade, se till att det finns n√•gon GPU-allokering f√∂r att kunna ladda modeller",
			"split": {
				"title": "Strategi",
				"placeholder": "V√§lj en GPU-minnesallokering",
				"options": {
					"generalDescription": "Konfigurera hur modeller ska laddas p√• dina GPU:er",
					"evenly": {
						"title": "Dela j√§mnt",
						"description": "Allokera minne j√§mnt √∂ver GPU:erna"
					},
					"priorityOrder": {
						"title": "Prioritetsordning",
						"description": "Dra f√∂r att √§ndra prioritet. Systemet f√∂rs√∂ker allokera mer p√• GPU:er som listas f√∂rst"
					},
					"custom": {
						"title": "Anpassad",
						"description": "Allokera minne",
						"maxAllocation": "Maximal allokering"
					}
				}
			},
			"deviceId.info": "Unik identifierare f√∂r denna enhet",
			"changesOnlyAffectNewlyLoadedModels": "√Ñndringar p√•verkar endast nyligen inl√§sta modeller",
			"toggleGpu": "Aktivera/Inaktivera GPU"
		}
	},

	"load.gpuSplitConfig/title": "GPU-splitkonfiguration",
	"envVars/title": "St√§ll in en milj√∂variabel",
	"envVars": {
		"select": {
			"placeholder": "V√§lj en milj√∂variabel...",
			"noOptions": "Inga fler tillg√§ngliga",
			"filter": {
				"placeholder": "Filtrera s√∂kresultat",
				"resultsFound_zero": "Inga resultat hittades",
				"resultsFound_one": "1 resultat hittades",
				"resultsFound_other": "{{count}} resultat hittades"
			}
		},
		"inputValue": {
			"placeholder": "Ange ett v√§rde"
		},
		"values": {
			"title": "Nuvarande v√§rden"
		}
  }
}
