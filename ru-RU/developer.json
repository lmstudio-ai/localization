{
  "tabs/server": "Локальный сервер",
  "tabs/extensions": "Среды выполнения LM",
  "loadSettings/title": "Загрузить настройки",
  "modelSettings/placeholder": "Выберите модель для настройки",

  "loadedModels/noModels": "Загруженные модели отсутствуют",

  "serverOptions/title": "Параметры сервера",
  "serverOptions/configurableTitle": "Настраиваемые параметры",
  "serverOptions/port/hint": "Укажите сетевой порт, который будет использовать локальный сервер. По умолчанию, LM Studio использует порт 1234. Возможно, потребуется изменить это значение, если порт уже используется.",
  "serverOptions/port/subtitle": "Порт для прослушивания",
  "serverOptions/autostart/title": "Автозапуск сервера",
  "serverOptions/autostart/hint": "Автоматически включать локальный сервер LLM в LM Studio при запуске приложения или службы.",
  "serverOptions/port/integerWarning": "Номер порта должен быть целым числом",
  "serverOptions/port/invalidPortWarning": "Порт должен быть в диапазоне от 1 до 65535",
  "serverOptions/cors/title": "Включить CORS",
  "serverOptions/cors/hint1": "Включение CORS (Cross-origin Resource Sharing) позволит веб-сайтам, которые вы посещаете, отправлять запросы на сервер LM Studio.",
  "serverOptions/cors/hint2": "CORS может потребоваться при отправке запросов с веб-сайта или из VS Code / другого расширения.",
  "serverOptions/cors/subtitle": "Разрешить междоменные запросы",
  "serverOptions/network/title": "Предоставить доступ из локальной сети",
  "serverOptions/network/subtitle": "Сделать сервер доступным для устройств в сети",
  "serverOptions/network/hint1": "Разрешить подключения с других устройств в сети.",
  "serverOptions/network/hint2": "Если опция не выбрана, сервер будет прослушивать только localhost.",
  "serverOptions/verboseLogging/title": "Подробное журналирование",
  "serverOptions/verboseLogging/subtitle": "Включить подробное журналирование для локального сервера",
  "serverOptions/contentLogging/title": "Журнал промптов и ответов",
  "serverOptions/contentLogging/subtitle": "Настройки ведения журнала локальных промптов / ответов",
  "serverOptions/contentLogging/hint": "Вести журнал промптов и/или ответов в файле журнала локального сервера.",
  "serverOptions/redactContent/title": "Маскирование содержимого",
  "serverOptions/redactContent/hint": "При включении запретить журналирование чувствительных данных, таких как содержимое запросов и ответов.",
  "serverOptions/logIncomingTokens/title": "Журналирование входящих токенов",
  "serverOptions/logIncomingTokens/hint": "Нужно ли записывать каждый токен по мере его генерации.",
  "serverOptions/fileLoggingMode/title": "Режим ведения журнала в файл",
  "serverOptions/fileLoggingMode/off/title": "ВЫКЛ",
  "serverOptions/fileLoggingMode/off/hint": "Не создавать файлы журнала",
  "serverOptions/fileLoggingMode/succinct/title": "Краткий",
  "serverOptions/fileLoggingMode/succinct/hint": "Журналировать тот же контент, что и в консоли. Длинные запросы будут обрезаны.",
  "serverOptions/fileLoggingMode/full/title": "Полный",
  "serverOptions/fileLoggingMode/full/hint": "Не обрезать длинные запросы.",
  "serverOptions/jitModelLoading/title": "Загрузка модели по требованию",
  "serverOptions/jitModelLoading/hint": "При включении, если запрос указывает на модель, которая не загружена, она будет автоматически загружена и использована. Кроме того, конечная точка \"/v1/models\" также будет включать модели, которые ещё не загружены.",
  "serverOptions/loadModel/error": "Не удалось загрузить модель",
  "serverOptions/jitModelLoadingTTL/title": "Автоматическая выгрузка неиспользуемых JIT-моделей",
  "serverOptions/jitModelLoadingTTL/hint": "Модель, загруженная по требованию (JIT) для обработки запроса API, будет автоматически выгружена из памяти по истечении заданного периода бездействия (TTL).",
  "serverOptions/jitModelLoadingTTL/ttl/label": "Макс. время простоя (TTL)",
  "serverOptions/jitModelLoadingTTL/ttl/unit": "мин.",
  "serverOptions/unloadPreviousJITModelOnLoad/title": "Оставлять только последнюю JIT-модель",
  "serverOptions/unloadPreviousJITModelOnLoad/hint": "Обеспечивает, что в памяти находится не более одной модели, загруженной по требованию (JIT), автоматически выгружая предыдущую",
  "serverOptions/allowMcp/title": "Разрешить удалённые MCP",
  "serverOptions/allowMcp/hint": "Разрешает использование MCP, не указанных в файле mcp.json. Эти MCP-соединения являются временными и существуют только на время обработки запроса. В данный момент поддерживаются только удалённые MCP.",
  "serverOptions/allowMcp/mode/off": "Выкл.",
  "serverOptions/allowMcp/mode/off/hint": "Запретить серверным запросам использовать MCP.",
  "serverOptions/allowMcp/mode/remote": "Удалённые",
  "serverOptions/allowMcp/mode/remote/hint": "Разрешить подключение к удалённым серверам MCP",

  "serverOptions/start/error": "Не удалось запустить сервер",
  "serverOptions/stop/error": "Не удалось остановить сервер",

  "serverLogs/scrollToBottom": "Перейти в конец",
  "serverLogs/clearLogs": "Очистить журналы ({{shortcut}})",
  "serverLogs/openLogsFolder": "Открыть папку журналов сервера",

  "runtimeSettings/title": "Настройки среды выполнения",
  "runtimeSettings/chooseRuntime/title": "Выбор",
  "runtimeSettings/chooseRuntime/description": "Выберите движок для каждого формата моделей",
  "runtimeSettings/chooseRuntime/showAllVersions/label": "Показывать все пакеты расширений",
  "runtimeSettings/chooseRuntime/showAllVersions/hint": "По умолчанию LM Studio показывает только последнюю версию каждого пакета расширений. Включите эту опцию, чтобы увидеть все доступные пакеты расширений.",
  "runtimeSettings/chooseRuntime/select/placeholder": "Выберите движок",

  "runtimeSettings/chooseFrameworks/title": "Фреймворки",
  "runtimeSettings/chooseFrameworks/description": "Выберите фреймворк для каждой функции",
  "runtimeSettings/chooseFramework/documentParser/builtIn/label": "Встроенный парсер",
  "runtimeSettings/chooseFramework/documentParser/select/label": "Парсер документов",
  "runtimeSettings/chooseFramework/documentParser/select/placeholder": "Выберите парсер документов",

  "runtimeOptions/uninstall": "Удалить",
  "runtimeOptions/uninstallDialog/title": "Удалить {{runtimeName}}?",
  "runtimeOptions/uninstallDialog/body": "Удаление этой среды выполнения приведёт к её удалению из системы. Это действие необратимо.",
  "runtimeOptions/uninstallDialog/body/caveats": "Некоторые файлы могут быть удалены только после перезапуска LM Studio.",
  "runtimeOptions/uninstallDialog/error": "Не удалось удалить среду выполнения",
  "runtimeOptions/uninstallDialog/confirm": "Продолжить и удалить",
  "runtimeOptions/uninstallDialog/cancel": "Отмена",
  "runtimeOptions/noCompatibleRuntimes": "Совместимые среды выполнения не найдены",
  "runtimeOptions/downloadIncompatibleRuntime": "Эта среда выполнения несовместима с вашим компьютером. Вероятнее всего, она не будет работать.",
  "runtimeOptions/noRuntimes": "Среды выполнения не найдены",

  "runtimes": {
    "manageLMRuntimes": "Управление средой выполнения LM",
    "includeOlderRuntimeVersions": "Включить старые версии",
    "dismiss": "Закрыть",
    "updateAvailableToast": {
      "title": "Доступно обновление среды выполнения LM!"
    },
    "updatedToast": {
      "title": " ✅ Среда выполнения LM обновлена: {{runtime}} → v{{version}}",
      "preferencesUpdated": "Новые загружаемые модели {{compatibilityTypes}} будут использовать обновлённую среду выполнения."
    },
    "noAvx2ErrorMessage": "Все среды выполнения LM в настоящее время требуют процессор с поддержкой AVX2",
    "downloadableRuntimes": {
      "runtimeExtensionPacks": "Пакеты расширений среды выполнения",
      "refresh": "Обновить",
      "refreshing": "Обновление...",
      "filterSegment": {
        "compatibleOnly": "Только совместимые",
        "all": "Все"
      },
      "card": {
        "releaseNotes": "Примечания к выпуску",
        "latestVersionInstalled": "Установлена последняя версия",
        "updateAvailable": "Доступно обновление"
      }
    },
    "installedRuntimes": {
      "manage": {
        "title": "Управление активными средами выполнения"
      },
      "dropdownOptions": {
        "installedVersions": "Управление версиями",
        "close": "Закрыть"
      },
      "tabs": {
        "all": "Все",
        "frameworks": "Мои фреймворки",
        "engines": "Мои движки"
      },
      "detailsModal": {
        "installedVersions": "Установленные версии для {{runtimeName}}",
        "manifestJsonTitle": "JSON-манифест (расширенный)",
        "releaseNotesTitle": "Примечания к выпуску",
        "noReleaseNotes": "Для этой версии примечания к выпуску отсутствуют",
        "back": "Назад",
        "close": "Закрыть"
      },
      "noEngines": "Нет установленных движков",
      "noFrameworks": "Нет установленных фреймворков"
    }
  },

  "inferenceParams/noParams": "Для этого типа модели отсутствуют настраиваемые параметры инференса.",

  "quickDocs": {
    "tabChipTitle": "Документация для разработчиков",
    "newToolUsePopover": "Примеры кода теперь доступны в разделе \"Документация для разработчиков\". Нажмите здесь, чтобы начать использовать инструменты!",
    "newToolUsePopoverTitle": "📚 Документация для разработчиков",
    "learnMore": "ℹ️ 👾 Для получения дополнительной информации о конечных точках локального сервера LM Studio посетите [документацию](https://lmstudio.ai/docs).",
    "helloWorld": {
      "title": "Привет, Мир!"
    },
    "chat": {
      "title": "Чат"
    },
    "structuredOutput": {
      "title": "Структурированный вывод"
    },
    "imageInput": {
      "title": "Ввод изображения"
    },
    "embeddings": {
      "title": "Эмбеддинги"
    },
    "toolUse": {
      "title": "Использование инструментов",
      "tab": {
        "saveAsPythonFile": "Сохранить как файл Python",
        "runTheScript": "Запустить скрипт:",
        "savePythonFileCopyPaste": "Сохранить как файл Python, чтобы получить команду для копирования и вставки"
      }
    },
    "newBadge": "Новый"
  },

  "endpoints/openaiCompatRest/title": "Поддерживаемые конечные точки{{extra}}",
  "endpoints/openaiCompatRest/segmentedLabel": "Совместимый с OpenAI",
  "endpoints/openaiCompatRest/getModels": "Список загруженных моделей",
  "endpoints/openaiCompatRest/postCompletions": "Режим завершения текста. Предсказание следующего токена(ов) по заданному промпту. Заметка: OpenAI считает эту конечную точку 'устаревшей'.",
  "endpoints/openaiCompatRest/postChatCompletions": "Завершение чата. Отправить историю чата модели для предсказания следующего ответа ассистента",
  "endpoints/openaiCompatRest/postEmbeddings": "Эмбеддинг текста. Генерировать текстовые эмбеддинги для заданного входного текста. Принимает строку или массив строк.",
  "endpoints/openaiCompatRest/postResponses": "Расширенный интерфейс для генерации ответов модели. Создание взаимодействий с сохранением состояния путём передачи идентификатора предыдущего ответа в качестве входных данных для следующего.",
  "endpoints/lmStudioRest/segmentedLabel": "LM Studio",
  "endpoints/lmStudioRestV1/getModels": "Список доступных моделей",
  "endpoints/lmStudioRestV1/postModelsLoad": "Загрузить модель с параметрами",
  "endpoints/lmStudioRestV1/postModelsDownload": "Загрузить модель",
  "endpoints/lmStudioRestV1/postChat": "Чат с моделью. Поддерживает многооборотные диалоги с сохранением состояния и MCP",
  "endpoints/lmStudioRestV1/getModelsDownloadStatus": "Получение статуса загрузки модели",

  "model.createVirtualModelFromInstance": "Сохранить настройки как новую виртуальную модель",
  "model.createVirtualModelFromInstance/error": "Не удалось сохранить настройки как новую виртуальную модель",

  "model": {
    "toolUseSectionTitle": "Использование инструментов",
    "toolUseDescription": "Обнаружено, что эта модель была обучена использованию инструментов\n\nОткрыть <custom-link>документацию для разработчиков</custom-link> для получения дополнительной информации"
  },

  "apiConfigOptions/title": "Конфигурация API"
}
