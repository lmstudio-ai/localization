{
  "noInstanceSelected": "Nijedna instanca modela nije odabrana",
  "resetToDefault": "Vrati na podrazumijevano",
  "showAdvancedSettings": "Prikaži napredne postavke",
  "showAll": "Sve",
  "basicSettings": "Osnovno",
  "configSubtitle": "Učitajte ili sačuvajte unaprijed postavljene postavke i eksperimentirajte s parametrima modela",
  "inferenceParameters/title": "Parametri predikcije",
  "inferenceParameters/info": "Eksperimentirajte s parametrima koji utiču na predikciju.",
  "generalParameters/title": "Opšte",
  "samplingParameters/title": "Uzorak",
  "basicTab": "Osnovno",
  "advancedTab": "Napredno",
  "advancedTab/title": "🧪 Napredna konfiguracija",
  "advancedTab/expandAll": "Proširi sve",
  "advancedTab/overridesTitle": "Prepravke konfiguracije",
  "advancedTab/noConfigsText": "Nemate nespremljene promjene - uredite vrijednosti iznad da biste vidjeli prepravke ovdje.",
  "loadInstanceFirst": "Učitajte model da biste vidjeli konfigurabilne parametre",
  "noListedConfigs": "Nema konfigurabilnih parametara",
  "generationParameters/info": "Eksperimentirajte s osnovnim parametrima koji utiču na generisanje teksta.",
  "loadParameters/title": "Parametri učitavanja",
  "loadParameters/description": "Postavke za kontrolu načina na koji se model inicijalizuje i učitava u memoriju.",
  "loadParameters/reload": "Ponovo učitaj da primijeniš promjene",
  "discardChanges": "Odbaci promjene",
  "loadModelToSeeOptions": "Učitajte model da biste vidjeli opcije",
  "llm.prediction.systemPrompt/title": "Sistemski prompt",
  "llm.prediction.systemPrompt/description": "Koristite ovo polje da pružite pozadinske instrukcije modelu, kao što su set pravila, ograničenja ili opšti zahtjevi.",
  "llm.prediction.systemPrompt/subTitle": "Smjernice za AI",
  "llm.prediction.temperature/title": "Temperatura",
  "llm.prediction.temperature/subTitle": "Koliko nasumičnosti uvesti. 0 će dati isti rezultat svaki put, dok će veće vrijednosti povećati kreativnost i varijaciju",
  "llm.prediction.temperature/info": "Iz llama.cpp dokumenata: \"Podrazumijevana vrijednost je <{{dynamicValue}}>, koja pruža balans između nasumičnosti i determinističnosti. Na ekstremu, temperatura od 0 će uvijek birati najvjerovatniji sljedeći token, što dovodi do identičnih izlaza u svakom pokretanju\"",
  "llm.prediction.llama.sampling/title": "Uzorak",
  "llm.prediction.topKSampling/title": "Top K uzorkovanje",
  "llm.prediction.topKSampling/subTitle": "Ograničava sljedeći token na jedan od top-k najvjerovatnijih tokena. Djeluje slično kao temperatura",
  "llm.prediction.topKSampling/info": "Iz llama.cpp dokumenata:\n\nTop-k uzorkovanje je metoda generisanja teksta koja bira sljedeći token samo iz top k najvjerovatnijih tokena koje model predviđa.\n\nPomaže smanjiti rizik od generisanja tokena niske vjerovatnoće ili besmislenih tokena, ali može i ograničiti raznolikost izlaza.\n\nVeća vrijednost za top-k (npr. 100) će razmatrati više tokena i dovesti do raznovrsnijeg teksta, dok će niža vrijednost (npr. 10) fokusirati na najvjerovatnije tokene i generisati konzervativniji tekst.\n\n• Podrazumijevana vrijednost je <{{dynamicValue}}>",
  "llm.prediction.llama.cpuThreads/title": "CPU niti",
  "llm.prediction.llama.cpuThreads/subTitle": "Broj CPU niti koje će se koristiti tokom inferencije",
  "llm.prediction.llama.cpuThreads/info": "Broj niti koje će se koristiti tokom računanja. Povećanje broja niti ne korelira uvijek s boljim performansama. Podrazumijevano je <{{dynamicValue}}>.",
  "llm.prediction.maxPredictedTokens/title": "Ograniči dužinu odgovora",
  "llm.prediction.maxPredictedTokens/subTitle": "Opcionalno ograničite dužinu odgovora AI-a",
  "llm.prediction.maxPredictedTokens/info": "Kontrolišite maksimalnu dužinu odgovora chatbota. Uključite da postavite ograničenje na maksimalnu dužinu odgovora, ili isključite da pustite chatbota da odluči kada da stane.",
  "llm.prediction.maxPredictedTokens/inputLabel": "Maksimalna dužina odgovora (tokeni)",
  "llm.prediction.maxPredictedTokens/wordEstimate": "Oko {{maxWords}} riječi",
  "llm.prediction.repeatPenalty/title": "Kazna za ponavljanje",
  "llm.prediction.repeatPenalty/subTitle": "Koliko obeshrabriti ponavljanje istog tokena",
  "llm.prediction.repeatPenalty/info": "Iz llama.cpp dokumenata: \"Pomaže spriječiti model da generiše repetitivni ili monoton tekst.\n\nVeća vrijednost (npr. 1.5) će jače kazniti ponavljanja, dok će niža vrijednost (npr. 0.9) biti blaža.\" • Podrazumijevana vrijednost je <{{dynamicValue}}>",
  "llm.prediction.minPSampling/title": "Min P uzorkovanje",
  "llm.prediction.minPSampling/subTitle": "Minimalna osnovna vjerovatnoća za token da bude izabran za izlaz",
  "llm.prediction.minPSampling/info": "Iz llama.cpp dokumenata:\n\nMinimalna vjerovatnoća za token da bude razmatran, relativno na vjerovatnoću najvjerovatnijeg tokena. Mora biti u [0, 1].\n\n• Podrazumijevana vrijednost je <{{dynamicValue}}>",
  "llm.prediction.topPSampling/title": "Top P uzorkovanje",
  "llm.prediction.topPSampling/subTitle": "Minimalna kumulativna vjerovatnoća za moguće sljedeće tokene. Djeluje slično kao temperatura",
  "llm.prediction.topPSampling/info": "Iz llama.cpp dokumenata:\n\nTop-p uzorkovanje, također poznato kao nucleus uzorkovanje, je druga metoda generisanja teksta koja bira sljedeći token iz podskupa tokena koji zajedno imaju kumulativnu vjerovatnoću od najmanje p.\n\nOva metoda pruža balans između raznolikosti i kvaliteta razmatrajući i vjerovatnoće tokena i broj tokena iz kojih se uzorkuje.\n\nVeća vrijednost za top-p (npr. 0.95) će dovesti do raznovrsnijeg teksta, dok će niža vrijednost (npr. 0.5) generisati fokusiraniji i konzervativniji tekst. Mora biti u (0, 1].\n\n• Podrazumijevana vrijednost je <{{dynamicValue}}>",
  "llm.prediction.stopStrings/title": "Stop stringovi",
  "llm.prediction.stopStrings/subTitle": "Stringovi koji bi trebali zaustaviti model od generisanja više tokena",
  "llm.prediction.stopStrings/info": "Specifični stringovi koji će, kada se pojave, zaustaviti model od generisanja više tokena",
  "llm.prediction.stopStrings/placeholder": "Unesite string i pritisnite ⏎",
  "llm.prediction.contextOverflowPolicy/title": "Prekoračenje konteksta",
  "llm.prediction.contextOverflowPolicy/subTitle": "Kako bi model trebao da se ponaša kada razgovor postane prevelik za njega da ga obradi",
  "llm.prediction.contextOverflowPolicy/info": "Odlučite šta da radite kada razgovor premaši veličinu radne memorije modela ('kontekst')",
  "llm.prediction.llama.frequencyPenalty/title": "Kazna za frekvenciju",
  "llm.prediction.llama.presencePenalty/title": "Kazna za prisustvo",
  "llm.prediction.llama.tailFreeSampling/title": "Tail-Free uzorkovanje",
  "llm.prediction.llama.locallyTypicalSampling/title": "Lokalno tipično uzorkovanje",
  "llm.prediction.onnx.topKSampling/title": "Top K uzorkovanje",
  "llm.prediction.onnx.topKSampling/subTitle": "Ograničava sljedeći token na jedan od top-k najvjerovatnijih tokena. Djeluje slično kao temperatura",
  "llm.prediction.onnx.topKSampling/info": "Iz ONNX dokumentacije:\n\nBroj tokena s najvišom vjerovatnoćom iz vokabulara koji će se zadržati za top-k filtriranje\n\n• Ovaj filter je isključen po defaultu",
  "llm.prediction.onnx.repeatPenalty/title": "Kazna za ponavljanje",
  "llm.prediction.onnx.repeatPenalty/subTitle": "Koliko obeshrabriti ponavljanje istog tokena",
  "llm.prediction.onnx.repeatPenalty/info": "Veća vrijednost obeshrabruje model od ponavljanja",
  "llm.prediction.onnx.topPSampling/title": "Top P uzorkovanje",
  "llm.prediction.onnx.topPSampling/subTitle": "Minimalna kumulativna vjerovatnoća za moguće sljedeće tokene. Djeluje slično kao temperatura",
  "llm.prediction.onnx.topPSampling/info": "Iz ONNX dokumentacije:\n\nSamo najvjerovatniji tokeni s vjerovatnoćama koje zbrajaju do TopP ili više se zadržavaju za generisanje\n\n• Ovaj filter je isključen po defaultu",
  "llm.prediction.seed/title": "Seed",
  "llm.prediction.structured/title": "Strukturirani izlaz",
  "llm.prediction.structured/info": "Strukturirani izlaz",
  "llm.prediction.structured/description": "Napredno: možete pružiti JSON Shemu da nametnete određeni format izlaza iz modela. Pročitajte [dokumentaciju](https://lmstudio.ai/docs/advanced/structured-output) da saznate više",
  "llm.prediction.promptTemplate/title": "Predložak prompta",
  "llm.prediction.promptTemplate/subTitle": "Format u kojem se poruke u chatu šalju modelu. Promjena ovoga može uvesti neočekivano ponašanje - budite sigurni da znate šta radite!",
  "llm.load.contextLength/title": "Dužina konteksta",
  "llm.load.contextLength/subTitle": "Maksimalan broj tokena koje model može obraditi u jednom promptu. Pogledajte opcije za prekoračenje razgovora pod \"Parametri inferencije\" za više načina upravljanja ovim",
  "llm.load.contextLength/info": "Specifikuje maksimalan broj tokena koje model može razmatrati odjednom, utičući na to koliko konteksta zadržava tokom obrade",
  "llm.load.contextLength/warning": "Postavljanje visoke vrijednosti za dužinu konteksta može značajno uticati na korištenje memorije",
  "llm.load.seed/title": "Seed",
  "llm.load.seed/subTitle": "Seed za generator slučajnih brojeva korišten u generisanju teksta. -1 je nasumičan",
  "llm.load.seed/info": "Nasumični Seed: Postavlja seed za generisanje slučajnih brojeva kako bi se osigurali reproduktivni rezultati",
  "llm.load.llama.evalBatchSize/title": "Veličina evaluacionog batch-a",
  "llm.load.llama.evalBatchSize/subTitle": "Broj ulaznih tokena koji se obrađuju odjednom. Povećanje ovoga povećava performanse na račun korištenja memorije",
  "llm.load.llama.evalBatchSize/info": "Postavlja broj primjera koji se obrađuju zajedno u jednom batch-u tokom evaluacije, utičući na brzinu i korištenje memorije",
  "llm.load.llama.ropeFrequencyBase/title": "Osnovna frekvencija RoPE",
  "llm.load.llama.ropeFrequencyBase/subTitle": "Prilagođena osnovna frekvencija za rotacione pozicijske enkodere (RoPE). Povećanje ovoga može omogućiti bolje performanse pri visokim dužinama konteksta",
  "llm.load.llama.ropeFrequencyBase/info": "[Napredno] Prilagođava osnovnu frekvenciju za rotacione pozicijske enkodere, utičući na to kako se pozicijske informacije enkodiraju",
  "llm.load.llama.ropeFrequencyScale/title": "Skala frekvencije RoPE",
  "llm.load.llama.ropeFrequencyScale/subTitle": "Dužina konteksta se skalira ovim faktorom da bi se proširio efektivni kontekst koristeći RoPE",
  "llm.load.llama.ropeFrequencyScale/info": "[Napredno] Modifikuje skaliranje frekvencije za rotacione pozicijske enkodere kako bi kontrolisao granularnost pozicijskog enkodiranja",
  "llm.load.llama.acceleration.offloadRatio/title": "GPU Offload",
  "llm.load.llama.acceleration.offloadRatio/subTitle": "Broj diskretnih slojeva modela koji će se računati na GPU za GPU akceleraciju",
  "llm.load.llama.acceleration.offloadRatio/info": "Postavite broj slojeva koji će se prebaciti na GPU.",
  "llm.load.llama.flashAttention/title": "Flash Attention",
  "llm.load.llama.flashAttention/subTitle": "Smanjuje korištenje memorije i vrijeme generisanja na nekim modelima",
  "llm.load.llama.flashAttention/info": "Ubrzava mehanizme pažnje za bržu i efikasniju obradu",
  "llm.load.numExperts/title": "Broj eksperata",
  "llm.load.numExperts/subTitle": "Broj eksperata koji će se koristiti u modelu",
  "llm.load.numExperts/info": "Broj eksperata koji će se koristiti u modelu",
  "llm.load.llama.keepModelInMemory/title": "Zadrži model u memoriji",
  "llm.load.llama.keepModelInMemory/subTitle": "Rezervišite sistemsku memoriju za model, čak i kada je prebačen na GPU. Poboljšava performanse ali zahtijeva više sistemske RAM memorije",
  "llm.load.llama.keepModelInMemory/info": "Sprječava model da se prebaci na disk, osiguravajući brži pristup na račun većeg korištenja RAM memorije",
  "llm.load.llama.useFp16ForKVCache/title": "Koristi FP16 za KV Cache",
  "llm.load.llama.useFp16ForKVCache/info": "Smanjuje korištenje memorije pohranjivanjem cache-a u polu-preciznosti (FP16)",
  "llm.load.llama.tryMmap/title": "Pokušaj mmap()",
  "llm.load.llama.tryMmap/subTitle": "Poboljšava vrijeme učitavanja modela. Onemogućavanje ovoga može poboljšati performanse kada je model veći od dostupne sistemske RAM memorije",
  "llm.load.llama.tryMmap/info": "Učitajte datoteke modela direktno s diska u memoriju",
  "embedding.load.contextLength/title": "Dužina konteksta",
  "embedding.load.contextLength/subTitle": "Maksimalan broj tokena koje model može obraditi u jednom promptu. Pogledajte opcije za prekoračenje razgovora pod \"Parametri inferencije\" za više načina upravljanja ovim",
  "embedding.load.contextLength/info": "Specifikuje maksimalan broj tokena koje model može razmatrati odjednom, utičući na to koliko konteksta zadržava tokom obrade",
  "embedding.load.llama.ropeFrequencyBase/title": "Osnovna frekvencija RoPE",
  "embedding.load.llama.ropeFrequencyBase/subTitle": "Prilagođena osnovna frekvencija za rotacione pozicijske enkodere (RoPE). Povećanje ovoga može omogućiti bolje performanse pri visokim dužinama konteksta",
  "embedding.load.llama.ropeFrequencyBase/info": "[Napredno] Prilagođava osnovnu frekvenciju za rotacione pozicijske enkodere, utičući na to kako se pozicijske informacije enkodiraju",
  "embedding.load.llama.evalBatchSize/title": "Veličina evaluacionog batch-a",
  "embedding.load.llama.evalBatchSize/subTitle": "Broj ulaznih tokena koji se obrađuju odjednom. Povećanje ovoga povećava performanse na račun korištenja memorije",
  "embedding.load.llama.evalBatchSize/info": "Postavlja broj tokena koji se obrađuju zajedno u jednom batch-u tokom evaluacije",
  "embedding.load.llama.ropeFrequencyScale/title": "Skala frekvencije RoPE",
  "embedding.load.llama.ropeFrequencyScale/subTitle": "Dužina konteksta se skalira ovim faktorom da bi se proširio efektivni kontekst koristeći RoPE",
  "embedding.load.llama.ropeFrequencyScale/info": "[Napredno] Modifikuje skaliranje frekvencije za rotacione pozicijske enkodere kako bi kontrolisao granularnost pozicijskog enkodiranja",
  "embedding.load.llama.acceleration.offloadRatio/title": "GPU Offload",
  "embedding.load.llama.acceleration.offloadRatio/subTitle": "Broj diskretnih slojeva modela koji će se računati na GPU za GPU akceleraciju",
  "embedding.load.llama.acceleration.offloadRatio/info": "Postavite broj slojeva koji će se prebaciti na GPU.",
  "embedding.load.llama.keepModelInMemory/title": "Zadrži model u memoriji",
  "embedding.load.llama.keepModelInMemory/subTitle": "Rezervišite sistemsku memoriju za model, čak i kada je prebačen na GPU. Poboljšava performanse ali zahtijeva više sistemske RAM memorije",
  "embedding.load.llama.keepModelInMemory/info": "Sprječava model da se prebaci na disk, osiguravajući brži pristup na račun većeg korištenja RAM memorije",
  "embedding.load.llama.tryMmap/title": "Pokušaj mmap()",
  "embedding.load.llama.tryMmap/subTitle": "Poboljšava vrijeme učitavanja modela. Onemogućavanje ovoga može poboljšati performanse kada je model veći od dostupne sistemske RAM memorije",
  "embedding.load.llama.tryMmap/info": "Učitajte datoteke modela direktno s diska u memoriju",
  "embedding.load.seed/title": "Seed",
  "embedding.load.seed/subTitle": "Seed za generator slučajnih brojeva korišten u generisanju teksta. -1 je nasumičan",
  "embedding.load.seed/info": "Nasumični Seed: Postavlja seed za generisanje slučajnih brojeva kako bi se osigurali reproduktivni rezultati",
  "presetTooltip": {
    "included/title": "Vrijednosti Preseta",
    "included/description": "Sljedeća polja će biti primijenjena",
    "included/empty": "Nijedno polje ovog preseta ne važi u ovom kontekstu.",
    "included/conflict": "Bit ćete upitani da li želite primijeniti ovu vrijednost",
    "separateLoad/title": "Konfiguracija pri učitavanju",
    "separateLoad/description.1": "Preset također uključuje sljedeću konfiguraciju pri učitavanju. Konfiguracija pri učitavanju je model-široka i zahtijeva ponovno učitavanje modela da bi stupila na snagu. Držite",
    "separateLoad/description.2": "da primijenite na",
    "separateLoad/description.3": ".",
    "excluded/title": "Možda ne važi",
    "excluded/description": "Sljedeća polja su uključena u preset ali ne važe u trenutnom kontekstu.",
    "legacy/title": "Legacy Preset",
    "legacy/description": "Ovaj preset je legacy preset. Uključuje sljedeća polja koja su ili automatski obrađena sada, ili više nisu primjenjiva."
  },
  "customInputs": {
    "string": {
      "emptyParagraph": "<Prazno>"
    },
    "checkboxNumeric": {
      "off": "OFF"
    },
    "stringArray": {
      "empty": "<Prazno>"
    },
    "llmPromptTemplate": {
      "type": "Tip",
      "types.jinja/label": "Predložak (Jinja)",
      "jinja.bosToken/label": "BOS Token",
      "jinja.eosToken/label": "EOS Token",
      "jinja.template/label": "Predložak",
      "jinja/error": "Neuspješno parsiranje Jinja predloška: {{error}}",
      "jinja/empty": "Molimo unesite Jinja predložak iznad.",
      "jinja/unlikelyToWork": "Jinja predložak koji ste unijeli iznad vjerovatno neće raditi jer ne referencira varijablu \"messages\". Molimo provjerite da li ste unijeli ispravan predložak.",
      "types.manual/label": "Ručno",
      "manual.subfield.beforeSystem/label": "Prije Sistema",
      "manual.subfield.beforeSystem/placeholder": "Unesite sistemski prefiks...",
      "manual.subfield.afterSystem/label": "Poslije Sistema",
      "manual.subfield.afterSystem/placeholder": "Unesite sistemski sufiks...",
      "manual.subfield.beforeUser/label": "Prije Korisnika",
      "manual.subfield.beforeUser/placeholder": "Unesite korisnički prefiks...",
      "manual.subfield.afterUser/label": "Poslije Korisnika",
      "manual.subfield.afterUser/placeholder": "Unesite korisnički sufiks...",
      "manual.subfield.beforeAssistant/label": "Prije Asistenta",
      "manual.subfield.beforeAssistant/placeholder": "Unesite prefiks asistenta...",
      "manual.subfield.afterAssistant/label": "Poslije Asistenta",
      "manual.subfield.afterAssistant/placeholder": "Unesite sufiks asistenta...",
      "stopStrings/label": "Dodatni Stop Stringovi",
      "stopStrings/subTitle": "Specifični stop stringovi za predložak koji će se koristiti uz korisnički specificirane stop stringove."
    },
    "contextLength": {
      "maxValueTooltip": "Ovo je maksimalan broj tokena koje je model treniran da obradi. Kliknite da postavite kontekst na ovu vrijednost",
      "maxValueTextStart": "Model podržava do",
      "maxValueTextEnd": "tokena",
      "tooltipHint": "Iako model može podržati do određenog broja tokena, performanse mogu opasti ako resursi vašeg računara ne mogu podnijeti opterećenje - budite oprezni pri povećanju ove vrijednosti"
    },
    "contextOverflowPolicy": {
          "stopAtLimit": "Zaustavi na granici",
          "stopAtLimitSub": "Zaustavi generisanje kada se memorija modela napuni",
          "truncateMiddle": "Skrati sredinu",
          "truncateMiddleSub": "Uklanja poruke iz sredine razgovora kako bi napravio prostor za nove. Model će i dalje pamtiti početak razgovora",
          "rollingWindow": "Klizni prozor",
          "rollingWindowSub": "Model će uvijek dobiti najnovije poruke, ali može zaboraviti početak razgovora"
    },
    "llamaAccelerationOffloadRatio": {
          "max": "MAKS",
          "off": "ISKLJ"
    }
  },
  "saveConflictResolution": {
        "title": "Odaberite koje vrijednosti uključiti u Preset",
        "description": "Odaberite koje vrijednosti zadržati",
        "instructions": "Kliknite na vrijednost da je uključite",
        "userValues": "Prethodna vrijednost",
        "presetValues": "Nova vrijednost",
        "confirm": "Potvrdi",
        "cancel": "Otkaži"
  },
  "applyConflictResolution": {
        "title": "Koje vrijednosti zadržati?",
        "description": "Imate neprimijenjene promjene koje se preklapaju s dolaznim Presetom",
        "instructions": "Kliknite na vrijednost da je zadržite",
        "userValues": "Trenutna vrijednost",
        "presetValues": "Dolazna vrijednost Preseta",
        "confirm": "Potvrdi",
        "cancel": "Otkaži"
  },
      "empty": "<Prazno>",
  "presets": {
    "title": "Preset",
        "commitChanges": "Primijeni promjene",
        "commitChanges/description": "Primijenite svoje promjene na preset.",
        "commitChanges.manual": "Otkrivena nova polja. Moći ćete odabrati koje promjene uključiti u preset.",
        "commitChanges.manual.hold.0": "Držite",
        "commitChanges.manual.hold.1": "da odaberete koje promjene primijeniti na preset.",
        "commitChanges.saveAll.hold.0": "Držite",
        "commitChanges.saveAll.hold.1": "da sačuvate sve promjene.",
        "commitChanges.saveInPreset.hold.0": "Držite",
        "commitChanges.saveInPreset.hold.1": "da sačuvate samo promjene na poljima koja su već uključena u preset.",
        "commitChanges/error": "Neuspješno primjenjivanje promjena na preset.",
        "commitChanges.manual/description": "Odaberite koje promjene uključiti u preset.",
        "saveAs": "Sačuvaj kao novo...",
        "presetNamePlaceholder": "Unesite ime za preset...",
        "cannotCommitChangesLegacy": "Ovo je legacy preset i ne može se mijenjati. Možete napraviti kopiju koristeći \"Sačuvaj kao novo...\".",
        "cannotCommitChangesNoChanges": "Nema promjena za primijeniti.",
        "emptyNoUnsaved": "Odaberite Preset...",
        "emptyWithUnsaved": "Nesačuvani Preset",
        "saveEmptyWithUnsaved": "Sačuvaj Preset kao...",
        "saveConfirm": "Sačuvaj",
        "saveCancel": "Otkaži",
        "saving": "Čuvanje...",
        "save/error": "Neuspješno čuvanje preseta.",
        "deselect": "Poništi odabir Preseta",
        "deselect/error": "Neuspješno poništavanje odabira preseta.",
        "select/error": "Neuspješno odabiranje preseta.",
        "delete/error": "Neuspješno brisanje preseta.",
        "discardChanges": "Odbaci nesačuvane",
        "discardChanges/info": "Odbacite sve neprimijenjene promjene i vratite preset na izvorno stanje",
        "newEmptyPreset": "Kreiraj novi prazan preset...",
        "contextMenuSelect": "Odaberi Preset",
        "contextMenuDelete": "Obriši"
  },
      "flashAttentionWarning": "Flash Attention je eksperimentalna funkcija koja može uzrokovati probleme s nekim modelima. Ako naiđete na probleme, pokušajte je onemogućiti.",
      "seedUncheckedHint": "Nasumični Seed",
  "ropeFrequencyBaseUncheckedHint": "Auto",
  "ropeFrequencyScaleUncheckedHint": "Auto"
