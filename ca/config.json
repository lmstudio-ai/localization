{
  "noInstanceSelected": "No s'ha seleccionat cap inst√†ncia de model",
  "resetToDefault": "Restablir",
  "showAdvancedSettings": "Mostra la configuraci√≥ avan√ßada",
  "showAll": "Tots",
  "basicSettings": "B√†sic",
  "configSubtitle": "Carrega o desa preajustaments i experimenta amb les substitucions dels par√†metres del model",
  "inferenceParameters/title": "Par√†metres de Predicci√≥",
  "inferenceParameters/info": "Experimenta amb els par√†metres que afecten la predicci√≥.",
  "generalParameters/title": "General",
  "samplingParameters/title": "Mostreig",
  "basicTab": "B√†sic",
  "advancedTab": "Avan√ßat",
  "advancedTab/title": "üß™ Configuraci√≥ Avan√ßada",
  "advancedTab/expandAll": "Expandir-ho tot",
  "advancedTab/overridesTitle": "Substitucions de Configuraci√≥",
  "advancedTab/noConfigsText": "No tens canvis no desats - edita els valors a dalt per veure les substitucions aqu√≠.",
  "loadInstanceFirst": "Carrega un model per veure els par√†metres configurables",
  "noListedConfigs": "No hi ha par√†metres configurables",
  "generationParameters/info": "Experimenta amb par√†metres b√†sics que afecten la generaci√≥ de text.",
  "loadParameters/title": "Carrega Par√†metres",
  "loadParameters/description": "Configuraci√≥ per controlar com es carrega i inicialitza el model a la mem√≤ria.",
  "loadParameters/reload": "Torna a carregar per aplicar canvis",
  "discardChanges": "Descarta els canvis",
  "loadModelToSeeOptions": "Carrega un model per veure opcions",
  "llm.prediction.systemPrompt/title": "Prompt del Sistema",
  "llm.prediction.systemPrompt/description": "Utilitza aquest camp per donar instruccions generals al model, com ara un conjunt de regles, restriccions o requisits generals.",
  "llm.prediction.systemPrompt/subTitle": "Directrius per a la IA",
  "llm.prediction.temperature/title": "Temperatura",
  "llm.prediction.temperature/subTitle": "Quanta aleatorietat introduir. 0 donar√† el mateix resultat sempre, mentre que valors m√©s alts incrementaran la creativitat i la variabilitat",
  "llm.prediction.temperature/info": "Dels documents d'ajuda de llama.cpp: \"El valor per defecte √©s <{{dynamicValue}}>, que proporciona un equilibri entre aleatorietat i determinisme. En l'extrem, una temperatura de 0 sempre triar√† el seg√ºent token m√©s probable, donant resultats id√®ntics en cada execuci√≥\"",
  "llm.prediction.llama.sampling/title": "Mostreig",
  "llm.prediction.topKSampling/title": "Mostreig Top K",
  "llm.prediction.topKSampling/subTitle": "Limita el seg√ºent token a un dels k tokens m√©s probables. Funciona de manera similar a la temperatura",
  "llm.prediction.topKSampling/info": "Dels documents d'ajuda de llama.cpp:\n\nEl mostreig Top-k √©s un m√®tode de generaci√≥ de text que selecciona el seg√ºent token nom√©s d'entre els k tokens m√©s probables predits pel model.\n\nAix√≤ ajuda a reduir el risc de generar tokens de baixa probabilitat o sense sentit, per√≤ tamb√© pot limitar la diversitat de la sortida.\n\nUn valor m√©s alt per a top-k (per exemple, 100) considerar√† m√©s tokens i conduir√† a un text m√©s divers, mentre que un valor m√©s baix (per exemple, 10) se centrar√† en els tokens m√©s probables i generar√† un text m√©s conservador.\n\n‚Ä¢ El valor per defecte √©s <{{dynamicValue}}>",
  "llm.prediction.llama.cpuThreads/title": "Fils de CPU",
  "llm.prediction.llama.cpuThreads/subTitle": "Nombre de fils de CPU a utilitzar durant la infer√®ncia",
  "llm.prediction.llama.cpuThreads/info": "El nombre de fils a utilitzar durant el c√†lcul. Augmentar el nombre de fils no sempre correlaciona amb millor rendiment. El valor per defecte √©s <{{dynamicValue}}>",
  "llm.prediction.maxPredictedTokens/title": "L√≠mita la longitud de la resposta",
  "llm.prediction.maxPredictedTokens/subTitle": "Opcionalment, limita la longitud de la resposta de la IA",
  "llm.prediction.maxPredictedTokens/info": "Controla la longitud m√†xima de la resposta del xatbot. Activa per establir un l√≠mit a la longitud m√†xima d'una resposta, o desactiva perqu√® el xatbot decideixi quan parar.",
  "llm.prediction.maxPredictedTokens/inputLabel": "Longitud m√†xima de la resposta (tokens)",
  "llm.prediction.maxPredictedTokens/wordEstimate": "Al voltant de {{maxWords}} paraules",
  "llm.prediction.repeatPenalty/title": "Penalitzaci√≥ de repetici√≥",
  "llm.prediction.repeatPenalty/subTitle": "Quant desincentivar repetir el mateix token",
  "llm.prediction.repeatPenalty/info": "Dels documents d'ajuda de llama.cpp: \"Ajuda a evitar que el model generi text repetitiu o mon√≤ton.\n\nUn valor m√©s alt (per exemple, 1.5) penalitzar√† les repeticions amb m√©s for√ßa, mentre que un valor m√©s baix (per exemple, 0.9) ser√† m√©s permissiu.\" ‚Ä¢ El valor per defecte √©s <{{dynamicValue}}>",
  "llm.prediction.minPSampling/title": "Mostreig Min P",
  "llm.prediction.minPSampling/subTitle": "Probabilitat base m√≠nima perqu√® un token sigui seleccionat per a la sortida",
  "llm.prediction.minPSampling/info": "Dels documents d'ajuda de llama.cpp:\n\nLa probabilitat m√≠nima perqu√® un token sigui considerat, en relaci√≥ amb la probabilitat del token m√©s probable. Ha de ser dins l'interval [0, 1].\n\n‚Ä¢ El valor per defecte √©s <{{dynamicValue}}>",
  "llm.prediction.topPSampling/title": "Mostreig Top P",
  "llm.prediction.topPSampling/subTitle": "Probabilitat acumulativa m√≠nima per als possibles seg√ºents tokens. Funciona de manera similar a la temperatura",
  "llm.prediction.topPSampling/info": "Dels documents d'ajuda de llama.cpp:\n\nEl mostreig Top-p, tamb√© conegut com mostreig de nucli, √©s un altre m√®tode de generaci√≥ de text que selecciona el seg√ºent token d'un subconjunt de tokens que junts tenen una probabilitat acumulativa d'almenys p.\n\nAquest m√®tode proporciona un equilibri entre diversitat i qualitat, tenint en compte tant les probabilitats dels tokens com el nombre de tokens dels quals mostrejar.\n\nUn valor m√©s alt per a top-p (per exemple, 0.95) conduir√† a un text m√©s divers, mentre que un valor m√©s baix (per exemple, 0.5) generar√† text m√©s enfocat i conservador. Ha de ser dins l'interval (0, 1].\n\n‚Ä¢ El valor per defecte √©s <{{dynamicValue}}>",
  "llm.prediction.stopStrings/title": "Cadena d'Aturada",
  "llm.prediction.stopStrings/subTitle": "Cadenes que haurien de parar el model d'emetre m√©s tokens",
  "llm.prediction.stopStrings/info": "Cadenes espec√≠fiques que, quan es troben, faran que el model pari de generar m√©s tokens",
  "llm.prediction.stopStrings/placeholder": "Introdueix una cadena i prem ‚èé",
  "llm.prediction.contextOverflowPolicy/title": "Desbordament de Context",
  "llm.prediction.contextOverflowPolicy/subTitle": "Com s'ha de comportar el model quan la conversa creix massa perqu√® pugui gestionar-la",
  "llm.prediction.contextOverflowPolicy/info": "Decideix qu√® fer quan la conversa supera la mida de la mem√≤ria de treball ('context') del model",
  "llm.prediction.llama.frequencyPenalty/title": "Penalitzaci√≥ per freq√º√®ncia",
  "llm.prediction.llama.presencePenalty/title": "Penalitzaci√≥ per pres√®ncia",
  "llm.prediction.llama.tailFreeSampling/title": "Mostreig sense cua",
  "llm.prediction.llama.locallyTypicalSampling/title": "Mostreig t√≠pic local",
  "llm.prediction.onnx.topKSampling/title": "Mostreig Top K",
  "llm.prediction.onnx.topKSampling/subTitle": "Limita el seg√ºent token a un dels k tokens m√©s probables. Funciona de manera similar a la temperatura",
  "llm.prediction.onnx.topKSampling/info": "Dels documents d'ONNX:\n\nNombre de tokens del vocabulari amb la probabilitat m√©s alta que es mantenen per al filtratge top-k\n\n‚Ä¢ Aquest filtre est√† desactivat per defecte",
  "llm.prediction.onnx.repeatPenalty/title": "Penalitzaci√≥ de repetici√≥",
  "llm.prediction.onnx.repeatPenalty/subTitle": "Quant desincentivar repetir el mateix token",
  "llm.prediction.onnx.repeatPenalty/info": "Un valor m√©s alt desincentiva que el model es repeteixi",
  "llm.prediction.onnx.topPSampling/title": "Mostreig Top P",
  "llm.prediction.onnx.topPSampling/subTitle": "Probabilitat acumulativa m√≠nima per als possibles seg√ºents tokens. Funciona de manera similar a la temperatura",
  "llm.prediction.onnx.topPSampling/info": "Dels documents d'ONNX:\n\nNom√©s es mantenen per a la generaci√≥ els tokens m√©s probables amb probabilitats que sumen TopP o m√©s.\n\n‚Ä¢ Aquest filtre est√† desactivat per defecte",
  "llm.prediction.seed/title": "Seed",
  "llm.prediction.structured/title": "Sortida estructurada",
  "llm.prediction.structured/info": "Sortida estructurada",
  "llm.prediction.promptTemplate/title": "Plantilla de prompt",
  "llm.prediction.promptTemplate/subTitle": "El format en qu√® s'envien els missatges al model. Canviar aix√≤ pot introduir comportaments inesperats: assegura't de saber qu√® est√†s fent!",

  "llm.load.contextLength/title": "Longitud de Context",
  "llm.load.contextLength/subTitle": "El nombre m√†xim de tokens que el model pot atendre en un sol prompt. Consulta les opcions de desbordament de conversa sota \"Par√†metres de infer√®ncia\" per m√©s maneres de gestionar aix√≤",
  "llm.load.contextLength/info": "Especifica el nombre m√†xim de tokens que el model pot considerar alhora, afectant quanta informaci√≥ de context ret√© durant el processament",
  "llm.load.contextLength/warning": "Establir un valor alt per a la longitud del context pot afectar significativament l'√∫s de la mem√≤ria",
  "llm.load.seed/title": "Seed",
  "llm.load.seed/subTitle": "La seed per al generador de nombres aleatoris utilitzat en la generaci√≥ de text. -1 √©s aleatori",
  "llm.load.seed/info": "Seed Aleat√≤ria: Defineix la seed per a la generaci√≥ de nombres aleatoris per garantir resultats reprodu√Øbles",
  "llm.load.llama.evalBatchSize/title": "Mida del lot d'avaluaci√≥",
  "llm.load.llama.evalBatchSize/subTitle": "Nombre de tokens d'entrada a processar alhora. Augmentar aix√≤ augmenta el rendiment a costa de l'√∫s de mem√≤ria",
  "llm.load.llama.evalBatchSize/info": "Defineix el nombre d'exemples processats conjuntament en un lot durant l'avaluaci√≥, afectant la velocitat i l'√∫s de mem√≤ria",
  "llm.load.llama.ropeFrequencyBase/title": "Base de freq√º√®ncia RoPE",
  "llm.load.llama.ropeFrequencyBase/subTitle": "Freq√º√®ncia base personalitzada per a embeddings posicionals rotatoris (RoPE). Augmentar aix√≤ pot permetre un millor rendiment a llargues longituds de context",
  "llm.load.llama.ropeFrequencyBase/info": "[Avan√ßat] Ajusta la freq√º√®ncia base per a l'Encodat Posicional Rotatori, afectant com s'incorpora la informaci√≥ posicional",
  "llm.load.llama.ropeFrequencyScale/title": "Escala de freq√º√®ncia RoPE",
  "llm.load.llama.ropeFrequencyScale/subTitle": "La longitud del context s'escala amb aquest factor per estendre el context efectiu utilitzant RoPE",
  "llm.load.llama.ropeFrequencyScale/info": "[Avan√ßat] Modifica l'escalat de la freq√º√®ncia per a l'Encodat Posicional Rotatori per controlar la granularitat de l'encodat posicional",
  "llm.load.llama.acceleration.offloadRatio/title": "Offload a GPU",
  "llm.load.llama.acceleration.offloadRatio/subTitle": "Nombre de capes discretes del model a calcular a la GPU per a l'acceleraci√≥ amb GPU",
  "llm.load.llama.acceleration.offloadRatio/info": "Estableix el nombre de capes que s'han d'assignar a la GPU.",
  "llm.load.llama.flashAttention/title": "Flash Attention",
  "llm.load.llama.flashAttention/subTitle": "Disminueix l'√∫s de mem√≤ria i el temps de generaci√≥ en alguns models",
  "llm.load.llama.flashAttention/info": "Accelera els mecanismes d'atenci√≥ per a un processament m√©s r√†pid i eficient",
  "llm.load.numExperts/title": "Nombre d'experts",
  "llm.load.numExperts/subTitle": "Nombre d'experts a utilitzar en el model",
  "llm.load.numExperts/info": "El nombre d'experts a utilitzar en el model",
  "llm.load.llama.keepModelInMemory/title": "Mantenir el model a la mem√≤ria",
  "llm.load.llama.keepModelInMemory/subTitle": "Reserva mem√≤ria del sistema per al model, fins i tot quan es descarrega a la GPU. Millora el rendiment per√≤ requereix m√©s mem√≤ria RAM del sistema",
  "llm.load.llama.keepModelInMemory/info": "Evita que el model es desi al disc, garantint un acc√©s m√©s r√†pid a canvi d'un major √∫s de RAM",
  "llm.load.llama.useFp16ForKVCache/title": "Utilitza FP16 per a la cache de KV",
  "llm.load.llama.useFp16ForKVCache/info": "Redueix l'√∫s de mem√≤ria emmagatzemant la cache en precisi√≥ mitja (FP16)",
  "llm.load.llama.tryMmap/title": "Prova mmap()",
  "llm.load.llama.tryMmap/subTitle": "Millora el temps de c√†rrega del model. Desactivar aix√≤ pot millorar el rendiment quan el model √©s m√©s gran que la RAM disponible del sistema",
  "llm.load.llama.tryMmap/info": "Carrega fitxers del model directament del disc a la mem√≤ria",

  "embedding.load.contextLength/title": "Longitud de Context",
  "embedding.load.contextLength/subTitle": "El nombre m√†xim de tokens que el model pot atendre en un sol prompt. Consulta les opcions de desbordament de conversa sota \"Par√†metres de infer√®ncia\" per m√©s maneres de gestionar aix√≤",
  "embedding.load.contextLength/info": "Especifica el nombre m√†xim de tokens que el model pot considerar alhora, afectant quanta informaci√≥ de context ret√© durant el processament",
  "embedding.load.llama.ropeFrequencyBase/title": "Base de freq√º√®ncia RoPE",
  "embedding.load.llama.ropeFrequencyBase/subTitle": "Freq√º√®ncia base personalitzada per a embeddings posicionals rotatoris (RoPE). Augmentar aix√≤ pot permetre un millor rendiment a llargues longituds de context",
  "embedding.load.llama.ropeFrequencyBase/info": "[Avan√ßat] Ajusta la freq√º√®ncia base per a l'Encodat Posicional Rotatori, afectant com s'incorpora la informaci√≥ posicional",
  "embedding.load.llama.evalBatchSize/title": "Mida del lot d'avaluaci√≥",
  "embedding.load.llama.evalBatchSize/subTitle": "Nombre de tokens d'entrada a processar alhora. Augmentar aix√≤ augmenta el rendiment a costa de l'√∫s de mem√≤ria",
  "embedding.load.llama.evalBatchSize/info": "Defineix el nombre de tokens processats conjuntament en un lot durant l'avaluaci√≥",
  "embedding.load.llama.ropeFrequencyScale/title": "Escala de freq√º√®ncia RoPE",
  "embedding.load.llama.ropeFrequencyScale/subTitle": "La longitud del context s'escala amb aquest factor per estendre el context efectiu utilitzant RoPE",
  "embedding.load.llama.ropeFrequencyScale/info": "[Avan√ßat] Modifica l'escalat de la freq√º√®ncia per a l'Encodat Posicional Rotatori per controlar la granularitat de l'encodat posicional",
  "embedding.load.llama.acceleration.offloadRatio/title": "Offload a GPU",
  "embedding.load.llama.acceleration.offloadRatio/subTitle": "Nombre de capes discretes del model a calcular a la GPU per a l'acceleraci√≥ amb GPU",
  "embedding.load.llama.acceleration.offloadRatio/info": "Estableix el nombre de capes que s'han d'assignar a la GPU.",
  "embedding.load.llama.keepModelInMemory/title": "Mantenir el model a la mem√≤ria",
  "embedding.load.llama.keepModelInMemory/subTitle": "Reserva mem√≤ria del sistema per al model, fins i tot quan es descarrega a la GPU. Millora el rendiment per√≤ requereix m√©s mem√≤ria RAM del sistema",
  "embedding.load.llama.keepModelInMemory/info": "Evita que el model es desi al disc, garantint un acc√©s m√©s r√†pid a canvi d'un major √∫s de RAM",
  "embedding.load.llama.tryMmap/title": "Prova mmap()",
  "embedding.load.llama.tryMmap/subTitle": "Millora el temps de c√†rrega del model. Desactivar aix√≤ pot millorar el rendiment quan el model √©s m√©s gran que la RAM disponible del sistema",
  "embedding.load.llama.tryMmap/info": "Carrega fitxers del model directament del disc a la mem√≤ria",
  "embedding.load.seed/title": "Seed",
  "embedding.load.seed/subTitle": "La seed per al generador de nombres aleatoris utilitzat en la generaci√≥ de text. -1 √©s aleatori",
  "embedding.load.seed/info": "Seed Aleat√≤ria: Defineix la seed per a la generaci√≥ de nombres aleatoris per garantir resultats reprodu√Øbles",

  "presetTooltip": {
    "included/title": "Valors predefinits",
    "included/description": "S'aplicaran els seg√ºents camps",
    "included/empty": "Cap dels camps d'aquest predefinit aplica en aquest context.",
    "included/conflict": "Se't demanar√† que tri√Øs si aplicar aquest valor",
    "separateLoad/title": "Configuraci√≥ del temps de c√†rrega",
    "separateLoad/description.1": "El predefinit tamb√© inclou la seg√ºent configuraci√≥ del temps de c√†rrega. La configuraci√≥ del temps de c√†rrega √©s a nivell de model i requereix tornar a carregar el model per fer efecte. Mant√©n premut",
    "separateLoad/description.2": "per aplicar a",
    "separateLoad/description.3": ".",
    "excluded/title": "Pot no aplicar",
    "excluded/description": "Els seg√ºents camps estan inclosos en el predefinit per√≤ no s'apliquen en el context actual.",
    "legacy/title": "Predefinit legacy",
    "legacy/description": "Aquest predefinit √©s un predefinit antic. Inclou els seg√ºents camps que ara es gestionen autom√†ticament o que ja no s√≥n aplicables."
  },

  "customInputs": {
    "string": {
      "emptyParagraph": "<Buit>"
    },
    "checkboxNumeric": {
      "off": "APAGAT"
    },
    "stringArray": {
      "empty": "<Buit>"
    },
    "llmPromptTemplate": {
      "type": "Tipus",
      "types.jinja/label": "Plantilla (Jinja)",
      "jinja.bosToken/label": "Token BOS",
      "jinja.eosToken/label": "Token EOS",
      "jinja.template/label": "Plantilla",
      "jinja/error": "Error en analitzar la plantilla Jinja: {{error}}",
      "types.manual/label": "Manual",
      "manual.subfield.beforeSystem/label": "Abans del Sistema",
      "manual.subfield.beforeSystem/placeholder": "Introdueix el prefix del Sistema...",
      "manual.subfield.afterSystem/label": "Despr√©s del Sistema",
      "manual.subfield.afterSystem/placeholder": "Introdueix el sufix del Sistema...",
      "manual.subfield.beforeUser/label": "Abans de l'Usuari",
      "manual.subfield.beforeUser/placeholder": "Introdueix el prefix de l'Usuari...",
      "manual.subfield.afterUser/label": "Despr√©s de l'Usuari",
      "manual.subfield.afterUser/placeholder": "Introdueix el sufix de l'Usuari...",
      "manual.subfield.beforeAssistant/label": "Abans de l'Assistent",
      "manual.subfield.beforeAssistant/placeholder": "Introdueix el prefix de l'Assistent...",
      "manual.subfield.afterAssistant/label": "Despr√©s de l'Assistent",
      "manual.subfield.afterAssistant/placeholder": "Introdueix el sufix de l'Assistent...",
      "stopStrings/label": "Cadenes d'Aturada Addicionals",
      "stopStrings/subTitle": "Cadenes d'aturada espec√≠fiques de la plantilla que s'utilitzaran a m√©s de les cadenes d'aturada especificades per l'usuari."
    },
    "contextLength": {
      "maxValueTooltip": "Aquest √©s el nombre m√†xim de tokens que el model va ser entrenat per gestionar. Clica per establir el context a aquest valor",
      "maxValueTextStart": "El model suporta fins a",
      "maxValueTextEnd": "tokens",
      "tooltipHint": "Tot i que un model pot suportar fins a un cert nombre de tokens, el rendiment pot deteriorar-se si els recursos de la teva m√†quina no poden gestionar la c√†rrega - utilitza-ho amb precauci√≥ quan augmentis aquest valor"
    },
    "contextOverflowPolicy": {
      "stopAtLimit": "Atura en el l√≠mit",
      "stopAtLimitSub": "Deixa de generar quan la mem√≤ria del model s'omple",
      "truncateMiddle": "Trunca el mig",
      "truncateMiddleSub": "Elimina missatges del mig de la conversa per fer espai per als m√©s recents. El model encara recordar√† l'inici de la conversa",
      "rollingWindow": "Finestra despla√ßable",
      "rollingWindowSub": "El model sempre rebr√† els darrers missatges per√≤ pot oblidar-se de l'inici de la conversa"
    },
    "llamaAccelerationOffloadRatio": {
      "max": "M√ÄX",
      "off": "APAGAT"
    }
  },
  "saveConflictResolution": {
    "title": "Tria quins valors incloure en el Predefinit",
    "description": "Tria quins valors mantenir",
    "instructions": "Clica sobre un valor per incloure'l",
    "userValues": "Valor Anterior",
    "presetValues": "Valor Nou",
    "confirm": "Confirmar",
    "cancel": "Cancel¬∑lar"
  },
  "applyConflictResolution": {
    "title": "Quins valors vols mantenir?",
    "description": "Tens canvis sense comprometre que se superposen amb el Predefinit entrant",
    "instructions": "Clica sobre un valor per mantenir-lo",
    "userValues": "Valor Actual",
    "presetValues": "Valor del Predefinit entrant",
    "confirm": "Confirmar",
    "cancel": "Cancel¬∑lar"
  },
  "empty": "<Buit>",
  "presets": {
    "title": "Predefinit",
    "commitChanges": "Compromet Canvis",
    "commitChanges/description": "Compromet els teus canvis al predefinit.",
    "commitChanges.manual": "Nous camps detectats. Podr√†s triar quins canvis incloure al predefinit.",
    "commitChanges.manual.hold.0": "Mant√©n premut",
    "commitChanges.manual.hold.1": "per triar quins canvis comprometre al predefinit.",
    "commitChanges.saveAll.hold.0": "Mant√©n premut",
    "commitChanges.saveAll.hold.1": "per desar tots els canvis.",
    "commitChanges.saveInPreset.hold.0": "Mant√©n premut",
    "commitChanges.saveInPreset.hold.1": "per nom√©s desar canvis als camps que ja estan inclosos en el predefinit.",
    "commitChanges/error": "No s'han pogut comprometre els canvis al predefinit.",
    "commitChanges.manual/description": "Tria quins canvis incloure en el predefinit.",
    "saveAs": "Desa com a nou...",
    "presetNamePlaceholder": "Introdueix un nom per al predefinit...",
    "cannotCommitChangesLegacy": "Aquest √©s un predefinit legacy i no es pot modificar. Pots crear-ne una c√≤pia utilitzant \"Desa com a nou...\".",
    "cannotCommitChangesNoChanges": "No hi ha canvis per comprometre.",
    "emptyNoUnsaved": "Selecciona un Predefinit...",
    "emptyWithUnsaved": "Predefinit no desat",
    "saveEmptyWithUnsaved": "Desa Predefinit Com...",
    "saveConfirm": "Desa",
    "saveCancel": "Cancel¬∑lar",
    "saving": "Desant...",
    "save/error": "No s'ha pogut desar el predefinit.",
    "deselect": "Desselecciona Predefinit",
    "deselect/error": "No s'ha pogut desseleccionar el predefinit.",
    "select/error": "No s'ha pogut seleccionar el predefinit.",
    "delete/error": "No s'ha pogut eliminar el predefinit.",
    "discardChanges": "Descarta els Canvis no Desats",
    "discardChanges/info": "Descarta tots els canvis no compromesos i restaura el predefinit al seu estat original",
    "newEmptyPreset": "Crea un nou predefinit buit...",
    "contextMenuSelect": "Selecciona Predefinit",
    "contextMenuDelete": "Elimina"
  },

  "flashAttentionWarning": "Flash Attention √©s una funcionalitat experimental que pot causar problemes amb alguns models. Si trobes problemes, prova de desactivar-la.",

  "seedUncheckedHint": "Seed Aleat√≤ria",
  "ropeFrequencyBaseUncheckedHint": "Auto",
  "ropeFrequencyScaleUncheckedHint": "Auto"
}