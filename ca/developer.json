{
  "tabs/server": "Servidor Local",
  "tabs/extensions": "Entorns d'Execució LM",
  "loadSettings/title": "Carrega la Configuració",
  "modelSettings/placeholder": "Selecciona un model per configurar-lo",

  "loadedModels/noModels": "Cap model carregat",

  "serverOptions/title": "Opcions del Servidor",
  "serverOptions/configurableTitle": "Opcions Configurables",
  "serverOptions/port/hint": "Estableix el port de xarxa que el servidor local utilitzarà. Per defecte, LM Studio utilitza el port 1234. És possible que s'hagi de canviar si el port ja té un altre ús.",
  "serverOptions/port/subtitle": "The port to listen on",
  "serverOptions/autostart/title": "Auto-iniciar el Servidor",
  "serverOptions/autostart/hint": "Inicia automàticament el servidor local en carregar un model",
  "serverOptions/port/integerWarning": "El port ha de ser un nombre sencer",
  "serverOptions/port/invalidPortWarning": "El port ha d'estar entre 1 i 65535",
  "serverOptions/cors/title": "Activa CORS",
  "serverOptions/cors/hint1": "Activar CORS (Cross-origin Resource Sharing) permetria que els webs que visites enviessin sol·licituts al servidor de LM Studio.",
  "serverOptions/cors/hint2": "Pot ser necessari activar CORS quan VS Code (les seves extensions) o un web enviï una sol·licitud.",
  "serverOptions/cors/subtitle": "Permet cross-origin requests",
  "serverOptions/network/title": "Permet Dispositius en la Xarxa Local",
  "serverOptions/network/subtitle": "Mostra el servidor als dispositius de la xarxa",
  "serverOptions/network/hint1": "Decideix si altres dispositius en la teva xarxa es poden connectar al servidor.",
  "serverOptions/network/hint2": "Si no es marca, el servidor només escoltarà al host local.",
  "serverOptions/verboseLogging/title": "Inici de Sessió Detallat",
  "serverOptions/verboseLogging/subtitle": "Activa l'inici de sessió detallat per al servidor local",
  "serverOptions/contentLogging/title": "Log Prompts and Responses",
  "serverOptions/contentLogging/subtitle": "Local request / response logging settings",
  "serverOptions/contentLogging/hint": "Whether to log prompts and/or the response in the local server log file.",
  "serverOptions/jitModelLoading/title": "Just-in-Time Model Loading",
  "serverOptions/jitModelLoading/hint": "When enabled, if a request specified a model that is not loaded, it will be automatically loaded and used. In addition, the \"/v1/models\" endpoint will also include models that are not yet loaded.",
  "serverOptions/loadModel/error": "Error en carregar el model",

  "serverLogs/scrollToBottom": "Ves al final",
  "serverLogs/clearLogs": "Neteja els logs ({{shortcut}})",
  "serverLogs/openLogsFolder": "Obre la carpeta dels logs del servidor",

  "runtimeSettings/title": "Configuració dels Entorns d'Execució",
  "runtimeSettings/chooseRuntime/title": "Configura Entorns d'Execució",
  "runtimeSettings/chooseRuntime/description": "Selecciona un entorn d'execució per a cada format de model",
  "runtimeSettings/chooseRuntime/showAllVersions/label": "Mostra tots els entorns d'execució",
  "runtimeSettings/chooseRuntime/showAllVersions/hint": "Per defecte, LM Studio només mostra l'última versió de cada entorn d'execució compatible. Activa aquesta opció per veure tots els entorns d'execució disponibles.",
  "runtimeSettings/chooseRuntime/select/placeholder": "Selecciona un entorn d'execució",

  "runtimeOptions/uninstall": "Desinstal·la",
  "runtimeOptions/uninstallDialog/title": "Desinstal·la {{runtimeName}}?",
  "runtimeOptions/uninstallDialog/body": "Desinstal·lar l'entorn d'execució l'el·liminarà del sistema. L'acció és irreversible.",
  "runtimeOptions/uninstallDialog/body/caveats": "Alguns arxius no s'el·liminaran fins que no es reiniciï LM Studio.",
  "runtimeOptions/uninstallDialog/error": "Error en desinstal·lar l'entorn d'execució",
  "runtimeOptions/uninstallDialog/confirm": "Continua i Desinstal·la",
  "runtimeOptions/uninstallDialog/cancel": "Cancel·la",
  "runtimeOptions/noCompatibleRuntimes": "Cap entorn d'execució compatible trobat",
  "runtimeOptions/downloadIncompatibleRuntime": "Aquest entorn d'execució no és compatible amb el teu maquinari. Probablement no funcionarà.",
  "runtimeOptions/noRuntimes": "Cap enorn d'execució trobat",

  "inferenceParams/noParams": "No configurable inference parameters available for this model type",

  "endpoints/openaiCompatRest/title": "Supported endpoints (OpenAI-like)",
  "endpoints/openaiCompatRest/getModels": "Llistat dels models carregats",
  "endpoints/openaiCompatRest/postCompletions": "Text Completions mode. Predict the next token(s) given a prompt. Note: OpenAI considers this endpoint 'deprecated'.",
  "endpoints/openaiCompatRest/postChatCompletions": "Chat completions. Send a chat history to the model to predict the next assistant response",
  "endpoints/openaiCompatRest/postEmbeddings": "Text Embedding. Generate text embeddings for a given text input. Takes a string or array of strings.",

  "model.createVirtualModelFromInstance": "Guarda la configuració com un nou model virtual",
  "model.createVirtualModelFromInstance/error": "Error en guardar la configuració com un nou model virtual",

  "apiConfigOptions/title": "Configurar l'API"
}
