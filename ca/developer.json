{
  "tabs/server": "Servidor Local",
  "tabs/extensions": "Runtimes del LM",
  "loadSettings/title": "Carrega la configuraci√≥",
  "modelSettings/placeholder": "Selecciona un model per a configurar-lo",

  "loadedModels/noModels": "Cap model carregat",

  "serverOptions/title": "Opcions del Servidor",
  "serverOptions/configurableTitle": "Opcions Configurables",
  "serverOptions/port/hint": "Estableix quin port de la xarxa utilitzar√† el servidor local. Per defecte, el LM Studio utilitza el port 1234. √âs possible que hagis de canviar-lo si aquest port ja s'est√† usant.",
  "serverOptions/port/subtitle": "El port a escoltar",
  "serverOptions/autostart/title": "Autoiniciar el servidor",
  "serverOptions/autostart/hint": "Enc√©n autom√†ticament el servidor de LLMs locals del LM Studio en encendre l'ordinador o obrir l'app",
  "serverOptions/port/integerWarning": "El port ha de ser un nombre natural",
  "serverOptions/port/invalidPortWarning": "El nombre del port ha d'estar entre 1 i 65535",
  "serverOptions/cors/title": "Activa CORS",
  "serverOptions/cors/hint1": "Activar CORS (Cross-origin Resource Sharing) permetria que els webs que visitis facin peticions al servidor del LM Studio.",
  "serverOptions/cors/hint2": "√âs possible que sigui necessari activar CORS quan es facin peticions des d'un web o VS Code / altres extensions.",
  "serverOptions/cors/subtitle": "Permet les peticions cross-origin",
  "serverOptions/network/title": "Serveix a la Xarxa Local",
  "serverOptions/network/subtitle": "Exposa el servidor a altres dispositius de la xarxa",
  "serverOptions/network/hint1": "Decideix si permetre connexions d'altres dispositius de la xarxa.",
  "serverOptions/network/hint2": "Si no es marca, el servidor nom√©s escoltar√† a localhost.",
  "serverOptions/verboseLogging/title": "Registre Detallat (Verbose Logging)",
  "serverOptions/verboseLogging/subtitle": "Activa el registre detallat pel servidor local",
  "serverOptions/contentLogging/title": "Registra Prompts i Respostes",
  "serverOptions/contentLogging/subtitle": "Configuraci√≥ de registre de peticions locals / respostes",
  "serverOptions/contentLogging/hint": "Decideix si registrar els prompts i/o les respoestes del servidor local a un fitxer log.",
  "serverOptions/redactContent/title": "Censurar Contingut",
  "serverOptions/redactContent/hint": "Quan s'activi, impedeix que informaci√≥ sensible, com el contingut de les peticions i les respostes, quedi enregistrada.",
  "serverOptions/logIncomingTokens/title": "Registra els Tokens Entrants",
  "serverOptions/logIncomingTokens/hint": "Decideix si registrar cadasc√∫n dels tokens a mesura que es generen.",
  "serverOptions/fileLoggingMode/title": "Tipus de Fitxer de Registre",
  "serverOptions/fileLoggingMode/off/title": "APAGAT",
  "serverOptions/fileLoggingMode/off/hint": "No crea cap fitxer de registre",
  "serverOptions/fileLoggingMode/succinct/title": "Breu",
  "serverOptions/fileLoggingMode/succinct/hint": "Registra el contingut com est√† a la consola. Les peticions llargues es truncaran.",
  "serverOptions/fileLoggingMode/full/title": "Complet",
  "serverOptions/fileLoggingMode/full/hint": "No truncar√† les peticions llargues.",
  "serverOptions/jitModelLoading/title": "C√†rrega del Model a Temps (Just-in-Time)",
  "serverOptions/jitModelLoading/hint": "Quan s'activi, si una petici√≥ es fa a un model que no est√† carregat, es carregar√† i utilitzar√† autom√†ticament. A m√©s, l'endpoint de \"/v1/models\" tamb√© inclour√† models que no estiguin carregats encara.",
  "serverOptions/loadModel/error": "No s'ha pogut carregar el model",
  "serverOptions/jitModelLoadingTTL/title": "Descarrega el model carregat amb JIT autom√†ticament quan es deixi d'utilitzar",
  "serverOptions/jitModelLoadingTTL/hint": "Un model carregat amb Just-in-time (JIT) per respondre a la petici√≥ d'una API ser√† descarregat autom√†ticament despr√©s de romandre sense utilitzar una estona (TTL).",
  "serverOptions/jitModelLoadingTTL/ttl/label": "Temps d'Espera M√†xim TTL",
  "serverOptions/jitModelLoadingTTL/ttl/unit": "minuts",
  "serverOptions/unloadPreviousJITModelOnLoad/title": "Nom√©s mant√©n l'√∫ltim model carregat JIT",
  "serverOptions/unloadPreviousJITModelOnLoad/hint": "Assegura't que, com a m√†xim, hi hagi un model carregat via JIT en qualsevol moment (descarregar√† models previs)",
  "serverOptions/allowMcp/title": "Permet MCPs Remots",
  "serverOptions/allowMcp/hint": "Permet utilitzar MCPs que no es trobin al teu mcp.json. Aquestes connexions MCP s√≥n ef√≠meres i nom√©s existeixen durant la duraci√≥ de la petici√≥. Pel moment, nom√©s se suporten MCPs remots.",
  "serverOptions/allowMcp/mode/off": "Apagat",
  "serverOptions/allowMcp/mode/off/hint": "No permetis que les peticions utilitzin MCP",
  "serverOptions/allowMcp/mode/remote": "Remot",
  "serverOptions/allowMcp/mode/remote/hint": "Permet connexions amb servidors MCP remots",
 
  "serverLogs/scrollToBottom": "Ves al final",
  "serverLogs/clearLogs": "Esborra els registres ({{shortcut}})",
  "serverLogs/openLogsFolder": "Obre la carpeta dels registres",

  "runtimeSettings/title": "Configuraci√≥ de Runtimes",
  "runtimeSettings/chooseRuntime/title": "Seleccions",
  "runtimeSettings/chooseRuntime/description": "Selecciona un motor per utilitzar a cada format de model",
  "runtimeSettings/chooseRuntime/showAllVersions/label": "Mostra tots els paquets d'extensi√≥",
  "runtimeSettings/chooseRuntime/showAllVersions/hint": "Per defecte, el LM Studio nom√©s mostra l'√∫ltima versi√≥ de cada paquet d'extensi√≥. Activa aquesta opci√≥ per veure tots els paquets d'extensi√≥ disponibles.",
  "runtimeSettings/chooseRuntime/select/placeholder": "Selecciona un motor",

  "runtimeSettings/chooseFrameworks/title": "Frameworks",
  "runtimeSettings/chooseFrameworks/description": "Selecciona un framework per utilitzar a cadascuna de les funcionalitats",
  "runtimeSettings/chooseFramework/documentParser/builtIn/label": "Parser integrat",
  "runtimeSettings/chooseFramework/documentParser/select/label": "Parser pe a Documents",
  "runtimeSettings/chooseFramework/documentParser/select/placeholder": "Selecciona un parser de documents",

  "runtimeOptions/uninstall": "Desinstal¬∑la",
  "runtimeOptions/uninstallDialog/title": "Desinstal¬∑la {{runtimeName}}?",
  "runtimeOptions/uninstallDialog/body": "Desinstal¬∑lar el runtime l'eliminar√† del sistema. Aquesta acci√≥ √©s irreversible.",
  "runtimeOptions/uninstallDialog/body/caveats": "√âs possible que alguns fitxers nom√©s s'eliminin despr√©s de reiniciar el LM Studio.",
  "runtimeOptions/uninstallDialog/error": "No s'ha pogut desinstal¬∑lar el runtime",
  "runtimeOptions/uninstallDialog/confirm": "Continua i Desinstal¬∑la",
  "runtimeOptions/uninstallDialog/cancel": "Cancel¬∑la",
  "runtimeOptions/noCompatibleRuntimes": "Cap runtime compatible trobat",
  "runtimeOptions/downloadIncompatibleRuntime": "S'ha determinat que aquest runtime no √©s compatible amb el teu maquinari. Probablement no funcioni.",
  "runtimeOptions/noRuntimes": "Cap runtime trobat",

  "runtimes": {
    "manageLMRuntimes": "Gestiona els Runtimes del LM",
    "includeOlderRuntimeVersions": "Inclou-hi versions antigues",
    "dismiss": "Ignora",
    "updateAvailableToast": {
      "title": "Actualitzaci√≥ del Runtime LM Disponible!"
    },
    "updatedToast": {
      "title": " ‚úÖ Runtime LM Actualitzat: {{runtime}} ‚Üí v{{version}}",
      "preferencesUpdated": "Els models {{compatibilityTypes}} carregats a partir d'ara utilitzaran el runtime actualitzat."
    },
    "noAvx2ErrorMessage": "Tots els runtimes LM requereixen una CPU que suporti AVX2",
    "downloadableRuntimes": {
      "runtimeExtensionPacks": "Paquets d'Extensi√≥ de Runtimes",
      "refresh": "Refresca",
      "refreshing": "Refrescant...",
      "filterSegment": {
        "compatibleOnly": "Nom√©s Compatibles",
        "all": "Tots"
      },
      "card": {
        "releaseNotes": "Notes de la Versi√≥",
        "latestVersionInstalled": "√öltima Versi√≥ Instal¬∑lada",
        "updateAvailable": "Actualitzaci√≥ Disponible"
      }
    },
    "installedRuntimes": {
      "manage": {
        "title": "Gestiona els Runtimes Actius"
      },
      "dropdownOptions": {
        "installedVersions": "Gestiona Versions",
        "close": "Tanca"
      },
      "tabs": {
        "all": "Tots",
        "frameworks": "Els Meus Frameworks",
        "engines": "Els Meus Motors"
      },
      "detailsModal": {
        "installedVersions": "Versions instal¬∑lades per a {{runtimeName}}",
        "manifestJsonTitle": "Manifest JSON (avan√ßat)",
        "releaseNotesTitle": "Notes de la Versi√≥",
        "noReleaseNotes": "Aquesta versi√≥ no t√© notes de la versi√≥",
        "back": "Enrere",
        "close": "Tanca"
      },
      "noEngines": "Cap motor instal¬∑lat",
      "noFrameworks": "Cap frameworks instal¬∑lat"
    }
  },

  "inferenceParams/noParams": "No hi ha par√†metres d'infer√®ncia configurables disponibles per a aquest tipus de model",

  "quickDocs": {
    "tabChipTitle": "Guia R√†pida",
    "newToolUsePopover": "Els fragments de codi ara estan disponibles a la \"Guia R√†pida\". Fes clic aqu√≠ per iniciar-te amb l'√∫s d'eines!",
    "newToolUsePopoverTitle": "üìö Guia R√†pida",
    "learnMore": "‚ÑπÔ∏è üëæ Per aprendre'n m√©s sobre els endpoints del servidor local del LM Studio, fes una ullada a la [documentaci√≥](https://lmstudio.ai/docs).",
    "helloWorld": {
      "title": "Hello, World!"
    },
    "chat": {
      "title": "Xat"
    },
    "structuredOutput": {
      "title": "Resposta Estructurada"
    },
    "imageInput": {
      "title": "Inserci√≥ d'Imatges"
    },
    "embeddings": {
      "title": "Embeddings"
    },
    "toolUse": {
      "title": "√ös d'Eines",
      "tab": {
        "saveAsPythonFile": "Desa com un fitxer de Python",
        "runTheScript": "Executa el codi:",
        "savePythonFileCopyPaste": "Desa com a fitxer python per tenir una instrucci√≥ copiar-enganxar"
      }
    },
    "newBadge": "Nou"
  },

  "endpoints/openaiCompatRest/title": "Endpoints suportats{{extra}}",
  "endpoints/openaiCompatRest/segmentedLabel": "Com el d'OpenAI",
  "endpoints/openaiCompatRest/getModels": "Llista els models actualment carregats",
  "endpoints/openaiCompatRest/postCompletions": "Mode de Emplenament de Text. Prediu el pr√≤xim token(s) donat un prompt. Nota: OpenAI considera aquest endpoint 'obsolet'.",
  "endpoints/openaiCompatRest/postChatCompletions": "Emplenament dels Xats. Envia l'historial del xat al model per poder predir la pr√≤xima resposta de l'assistent",
  "endpoints/openaiCompatRest/postEmbeddings": "Embedding de text. Genera embeddings de text donada una entrada de text. Accepta una cadena o un conjunt de cadenes",
  "endpoints/openaiCompatRest/postResponses": "Interfa√ß avan√ßada per generar respostes del model. Crea interaccions m√©s espec√≠fiques donant l'id d'una resposta pr√®via com a input per la seg√ºent.",
  "endpoints/lmStudioRest/segmentedLabel": "LM Studio",
  "endpoints/lmStudioRestV1/getModels": "Llista els models disponibles",
  "endpoints/lmStudioRestV1/postModelsLoad": "Carrega un model amb opcions",
  "endpoints/lmStudioRestV1/postModelsDownload": "Descarrega un model",
  "endpoints/lmStudioRestV1/postChat": "Xateja amb un model. Suporta converses a torns 'stateful multi-turn conversations' i MCP",
  "endpoints/lmStudioRestV1/getModelsDownloadStatus": "Comprova l'estat de la desc√†rrega del model",

  "model.createVirtualModelFromInstance": "Desa la Configuraci√≥ com un Nou Model Virtual",
  "model.createVirtualModelFromInstance/error": "No s'ha pogut desar la configuraci√≥ com un nou model virtual",

  "model": {
    "toolUseSectionTitle": "√ös d'Eines",
    "toolUseDescription": "S'ha detectat que aquest model pot utilitzar eines\n\nObre la <custom-link>guia r√†pida</custom-link> per a obtenir m√©s informaci√≥"
  },

  "apiConfigOptions/title": "Configuraci√≥ de l'API"
}
