{
  "tabs/server": "로컬 서버",
  "tabs/extensions": "확장 프로그램",
  "loadSettings/title": "설정 로드",
  "modelSettings/placeholder": "구성할 모델 선택",

  "loadedModels/noModels": "로드된 모델 없음",

  "serverOptions/title": "서버 옵션",
  "serverOptions/configurableTitle": "구성 가능한 옵션",
  "serverOptions/port/hint": "로컬 서버가 사용할 네트워킹 포트를 설정합니다. 기본적으로 LM Studio는 포트 1234를 사용합니다. 포트가 이미 사용 중인 경우 변경해야 할 수 있습니다.",
  "serverOptions/port/subtitle": "청취할 포트",
  "serverOptions/autostart/title": "서버 자동 시작",
  "serverOptions/autostart/hint": "모델이 로드될 때 로컬 서버를 자동으로 시작합니다",
  "serverOptions/port/integerWarning": "포트 번호는 정수여야 합니다",
  "serverOptions/port/invalidPortWarning": "포트는 1과 65535 사이여야 합니다",
  "serverOptions/cors/title": "CORS 활성화",
  "serverOptions/cors/hint1": "CORS(교차 출처 자원 공유)를 활성화하면 방문하는 웹사이트가 LM Studio 서버에 요청을 보낼 수 있습니다.",
  "serverOptions/cors/hint2": "웹 페이지나 VS Code / 기타 확장에서 요청을 보낼 때 CORS가 필요할 수 있습니다.",
  "serverOptions/cors/subtitle": "교차 출처 요청 허용",
  "serverOptions/network/title": "로컬 네트워크에서 제공",
  "serverOptions/network/subtitle": "네트워크의 장치에 서버 노출",
  "serverOptions/network/hint1": "네트워크의 다른 장치에서 연결을 허용할지 여부입니다.",
  "serverOptions/network/hint2": "체크하지 않으면 서버는 localhost에서만 수신합니다.",
  "serverOptions/verboseLogging/title": "상세 로깅",
  "serverOptions/verboseLogging/subtitle": "로컬 서버에 대한 상세 로깅 활성화",
  "serverOptions/contentLogging/title": "프롬프트 및 응답 로깅",
  "serverOptions/contentLogging/subtitle": "로컬 요청 / 응답 로깅 설정",
  "serverOptions/contentLogging/hint": "로컬 서버 로그 파일에 프롬프트 및/또는 응답을 기록할지 여부입니다.",
  "serverOptions/loadModel/error": "모델 로드 실패",

  "serverLogs/scrollToBottom": "맨 아래로 이동",
  "serverLogs/clearLogs": "로그 지우기 ({{shortcut}})",
  "serverLogs/openLogsFolder": "서버 로그 폴더 열기",

  "runtimeSettings/title": "런타임 설정",
  "runtimeSettings/chooseRuntime/title": "런타임 구성",
  "runtimeSettings/chooseRuntime/description": "각 모델 형식에 대한 런타임 선택",
  "runtimeSettings/chooseRuntime/showAllVersions/label": "모든 버전 표시",
  "runtimeSettings/chooseRuntime/showAllVersions/hint": "기본적으로 LM Studio는 각 런타임의 최신 버전만 표시합니다. 이 옵션을 활성화하면 사용 가능한 모든 버전을 볼 수 있습니다.",
  "runtimeSettings/chooseRuntime/select/placeholder": "런타임 선택",

  "runtimeOptions/uninstall": "제거",
  "runtimeOptions/uninstallDialog/title": "{{runtimeName}}을 제거하시겠습니까?",
  "runtimeOptions/uninstallDialog/body": "이 런타임을 제거하면 시스템에서 삭제됩니다. 이 작업은 되돌릴 수 없습니다.",
  "runtimeOptions/uninstallDialog/body/caveats": "일부 파일은 LM Studio를 다시 시작한 후에만 제거될 수 있습니다.",
  "runtimeOptions/uninstallDialog/error": "런타임 제거 실패",
  "runtimeOptions/uninstallDialog/confirm": "계속하고 제거",
  "runtimeOptions/uninstallDialog/cancel": "취소",
  "runtimeOptions/noCompatibleRuntimes": "호환되는 런타임을 찾을 수 없습니다",
  "runtimeOptions/downloadIncompatibleRuntime": "이 런타임은 귀하의 기기와 호환되지 않는 것으로 판단되었습니다. 작동하지 않을 가능성이 높습니다.",
  "runtimeOptions/noRuntimes": "런타임을 찾을 수 없습니다",

  "inferenceParams/noParams": "이 모델 유형에는 구성 가능한 추론 매개변수가 없습니다",

  "endpoints/openaiCompatRest/title": "지원되는 엔드포인트 (OpenAI like)",
  "endpoints/openaiCompatRest/getModels": "현재 로드된 모델 목록",
  "endpoints/openaiCompatRest/postCompletions": "텍스트 완성 모드. 프롬프트를 제공하여 다음 토큰을 예측합니다. 참고: OpenAI는 이 엔드포인트를 '사용 중단'으로 간주합니다.",
  "endpoints/openaiCompatRest/postChatCompletions": "채팅 완성. 모델에 채팅 기록을 보내어 다음 어시스턴트 응답을 예측합니다",
  "endpoints/openaiCompatRest/postEmbeddings": "텍스트 임베딩. 주어진 텍스트 입력에 대한 텍스트 임베딩을 생성합니다. 문자열 또는 문자열 배열을 입력으로 받습니다.",

  "model.createVirtualModelFromInstance": "설정을 새 가상 모델로 저장",
  "model.createVirtualModelFromInstance/error": "설정을 새 가상 모델로 저장하지 못했습니다",

  "apiConfigOptions/title": "API 구성"
}
