{
  "noInstanceSelected": "هیچ نمونه مدلی انتخاب نشده است",
  "resetToDefault": "بازنشانی",
  "showAdvancedSettings": "نمایش تنظیمات پیشرفته",
  "showAll": "همه",
  "basicSettings": "پایه",
  "configSubtitle": "بارگیری یا ذخیره پیش‌تنظیمات و آزمایش بازنویسی پارامترهای مدل",
  "inferenceParameters/title": "پارامترهای پیش‌بینی",
  "inferenceParameters/info": "آزمایش پارامترهایی که بر پیش‌بینی تأثیر می‌گذارند",
  "generalParameters/title": "عمومی",
  "samplingParameters/title": "نمونه‌برداری",
  "basicTab": "پایه",
  "advancedTab": "پیشرفته",
  "advancedTab/title": "🧪 پیکربندی پیشرفته",
  "advancedTab/expandAll": "گسترش همه",
  "advancedTab/overridesTitle": "بازنویسی تنظیمات",
  "advancedTab/noConfigsText": "تغییرات ذخیره نشده‌ای ندارید - مقادیر بالا را ویرایش کنید تا بازنویسی‌ها اینجا نمایش داده شوند",
  "loadInstanceFirst": "ابتدا یک مدل بارگذاری کنید تا پارامترهای قابل تنظیم نمایش داده شوند",
  "noListedConfigs": "هیچ پارامتر قابل تنظیمی وجود ندارد",
  "generationParameters/info": "آزمایش پارامترهای پایه که بر تولید متن تأثیر می‌گذارند",
  "loadParameters/title": "پارامترهای بارگذاری",
  "loadParameters/description": "تنظیمات مربوط به روش مقداردهی اولیه و بارگذاری مدل در حافظه",
  "loadParameters/reload": "بارگذاری مجدد برای اعمال تغییرات",
  "discardChanges": "لغو تغییرات",
  "loadModelToSeeOptions": "یک مدل بارگذاری کنید تا گزینه‌ها نمایش داده شوند",
  "llm.prediction.systemPrompt/title": "اعلان سیستم",
  "llm.prediction.systemPrompt/description": "از این فیلد برای ارائه دستورالعمل‌های پس‌زمینه به مدل استفاده کنید، مانند مجموعه‌ای از قوانین، محدودیت‌ها یا نیازمندی‌های کلی",
  "llm.prediction.systemPrompt/subTitle": "راهنماهای هوش مصنوعی",
  "llm.prediction.temperature/title": "دما",
  "llm.prediction.temperature/subTitle": "میزان تصادفی بودن. مقدار 0 هر بار نتیجه یکسانی تولید می‌کند، در حالی که مقادیر بالاتر خلاقیت و تنوع را افزایش می‌دهند",
  "llm.prediction.temperature/info": "از اسناد راهنمای llama.cpp: «مقدار پیش‌فرض <{{dynamicValue}}> است که تعادلی بین تصادفی بودن و قطعیت ایجاد می‌کند. در دمای 0 مدل همیشه محتمل‌ترین توکن بعدی را انتخاب می‌کند»",
  "llm.prediction.llama.sampling/title": "نمونه‌برداری",
  "llm.prediction.topKSampling/title": "نمونه‌برداری Top K",
  "llm.prediction.topKSampling/subTitle": "توکن بعدی را به K توکن با بیشترین احتمال محدود می‌کند. عملکردی مشابه دمای نمونه‌برداری دارد",
  "llm.prediction.topKSampling/info": "از اسناد راهنمای llama.cpp:\n\nنمونه‌برداری Top-K فقط توکن‌های با بالاترین احتمال را برای تولید متن انتخاب می‌کند\n\nمقدار بالاتر (مثلاً 100) متن متنوع‌تر و مقدار پایین‌تر (مثلاً 10) متن محافظه‌کارانه‌تری تولید می‌کند\n\n• مقدار پیش‌فرض: <{{dynamicValue}}>",
  "llm.prediction.llama.cpuThreads/title": "رشته‌های پردازنده",
  "llm.prediction.llama.cpuThreads/subTitle": "تعداد رشته‌های پردازنده مورد استفاده در فرآیند پیش‌بینی",
  "llm.prediction.llama.cpuThreads/info": "تعداد رشته‌های مورد استفاده در پردازش. افزایش همیشه به بهبود عملکرد منجر نمی‌شود. پیش‌فرض: <{{dynamicValue}}>",
  "llm.prediction.maxPredictedTokens/title": "محدودیت طول پاسخ",
  "llm.prediction.maxPredictedTokens/subTitle": "تعیین حداکثر طول مجاز برای پاسخ هوش مصنوعی",
  "llm.prediction.maxPredictedTokens/info": "کنترل حداکثر طول پاسخ چتبات. فعال کنید تا محدودیت اعمال شود یا غیرفعال کنید تا مدل خودش تصمیم بگیرد",
  "llm.prediction.maxPredictedTokens/inputLabel": "حداکثر طول پاسخ (توکن)",
  "llm.prediction.maxPredictedTokens/wordEstimate": "حدود {{maxWords}} کلمه",
  "llm.prediction.repeatPenalty/title": "جریمه تکرار",
  "llm.prediction.repeatPenalty/subTitle": "میزان جلوگیری از تکرار توکن‌های مشابه",
  "llm.prediction.repeatPenalty/info": "از اسناد llama.cpp: «مقدار بالاتر (مثلاً 1.5) تکرار را بیشتر جریمه می‌کند. مقدار پیش‌فرض: <{{dynamicValue}}>»",
  "llm.prediction.minPSampling/title": "نمونه‌برداری Min P",
  "llm.prediction.minPSampling/subTitle": "حداقل احتمال پایه برای انتخاب یک توکن",
  "llm.prediction.minPSampling/info": "از اسناد llama.cpp:\n\nحداقل احتمال نسبی نسبت به محتمل‌ترین توکن. باید بین [0, 1] باشد\n\n• پیش‌فرض: <{{dynamicValue}}>",
  "llm.prediction.topPSampling/title": "نمونه‌برداری Top P",
  "llm.prediction.topPSampling/subTitle": "حداقل احتمال تجمعی برای توکن‌های ممکن بعدی. عملکردی مشابه دما دارد",
  "llm.prediction.topPSampling/info": "از اسناد llama.cpp:\n\nنمونه‌برداری هسته‌ای. مقدار بالاتر (مثلاً 0.95) متن متنوع‌تر تولید می‌کند\n\n• پیش‌فرض: <{{dynamicValue}}>",
  "llm.prediction.stopStrings/title": "رشته‌های توقف",
  "llm.prediction.stopStrings/subTitle": "رشته‌هایی که تولید توکن را متوقف می‌کنند",
  "llm.prediction.stopStrings/info": "مواجهه با این رشته‌ها باعث توقف تولید توکن می‌شود",
  "llm.prediction.stopStrings/placeholder": "رشته را وارد کرده و ⏎ را بزنید",
  "llm.prediction.contextOverflowPolicy/title": "سرریز متن زمینه",
  "llm.prediction.contextOverflowPolicy/subTitle": "رفتار مدل هنگام بزرگ‌تر شدن متن زمینه از ظرفیت",
  "llm.prediction.contextOverflowPolicy/info": "تعیین اقدام مورد نیاز هنگام فراتر رفتن حجم گفتگو از حافظه فعال مدل («متن زمینه»)",
  "llm.prediction.llama.frequencyPenalty/title": "جریمه فرکانس",
  "llm.prediction.llama.presencePenalty/title": "جریمه حضور",
  "llm.prediction.llama.tailFreeSampling/title": "نمونه‌برداری بدون دنباله",
  "llm.prediction.llama.locallyTypicalSampling/title": "نمونه‌برداری معمولی محلی",
  "llm.prediction.onnx.topKSampling/title": "نمونه‌برداری Top K",
  "llm.prediction.onnx.topKSampling/subTitle": "محدود کردن توکن بعدی به K توکن با بیشترین احتمال. عملکردی مشابه دما دارد",
  "llm.prediction.onnx.topKSampling/info": "از اسناد ONNX:\n\nتعداد توکن‌های با بالاترین احتمال برای فیلتر Top-K\n\n• این فیلتر به طور پیش‌فرض غیرفعال است",
  "llm.prediction.onnx.repeatPenalty/title": "جریمه تکرار",
  "llm.prediction.onnx.repeatPenalty/subTitle": "میزان جلوگیری از تکرار توکن‌های مشابه",
  "llm.prediction.onnx.repeatPenalty/info": "مقدار بالاتر از تکرار توکن‌ها جلوگیری می‌کند",
  "llm.prediction.onnx.topPSampling/title": "نمونه‌برداری Top P",
  "llm.prediction.onnx.topPSampling/subTitle": "حداقل احتمال تجمعی برای توکن‌های ممکن بعدی. عملکردی مشابه دما دارد",
  "llm.prediction.onnx.topPSampling/info": "از اسناد ONNX:\n\nفقط توکن‌هایی با مجموع احتمال بالاتر از Top P انتخاب می‌شوند\n\n• این فیلتر به طور پیش‌فرض غیرفعال است",
  "llm.prediction.seed/title": "سید",
  "llm.prediction.structured/title": "خروجی ساختاریافته",
  "llm.prediction.structured/info": "خروجی ساختاریافته",
  "llm.prediction.structured/description": "پیشرفته: می‌توانید یک JSON Schema برای اعمال قالب خاصی به خروجی مدل ارائه دهید. [مستندات](https://lmstudio.ai/docs/advanced/structured-output) را مطالعه کنید",
  "llm.prediction.promptTemplate/title": "قالب اعلان",
  "llm.prediction.promptTemplate/subTitle": "قالب ارسال پیام‌های گفتگو به مدل. تغییر این ممکن است منجر به رفتار غیرمنتظره شود - فقط در صورت آگاهی کامل تغییر دهید!",

  "llm.load.contextLength/title": "طول متن زمینه",
  "llm.load.contextLength/subTitle": "حداکثر تعداد توکن‌هایی که مدل می‌تواند در یک اعلان پردازش کند. برای مدیریت پیشرفته‌تر به بخش «پارامترهای استنتاج» مراجعه کنید",
  "llm.load.contextLength/info": "تعیین کننده حداکثر تعداد توکن‌های قابل پردازش همزمان که بر میزان حفظ متن زمینه تأثیر می‌گذارد",
  "llm.load.contextLength/warning": "تنظیم مقدار بالا برای طول متن زمینه می‌تواند مصرف حافظه را به شدت افزایش دهد",
  "llm.load.seed/title": "سید",
  "llm.load.seed/subTitle": "مقدار سید برای مولد اعداد تصادفی در تولید متن. مقدار -1 تصادفی است",
  "llm.load.seed/info": "سید تصادفی: تنظیم سید برای تولید اعداد تصادفی جهت اطمینان از نتایج تکرارپذیر",

  "llm.load.llama.evalBatchSize/title": "اندازه دسته ارزیابی",
  "llm.load.llama.evalBatchSize/subTitle": "تعداد توکن‌های ورودی برای پردازش همزمان. افزایش این مقدار عملکرد را به قیمت مصرف بیشتر حافظه بهبود می‌بخشد",
  "llm.load.llama.evalBatchSize/info": "تعیین تعداد نمونه‌های پردازش شده در یک دسته طی ارزیابی که بر سرعت و مصرف حافظه تأثیر می‌گذارد",
  "llm.load.llama.ropeFrequencyBase/title": "پایه فرکانسی RoPE",
  "llm.load.llama.ropeFrequencyBase/subTitle": "فرکانس پایه سفارشی برای جاسازی موقعیتی چرخشی (RoPE). افزایش این مقدار ممکن است عملکرد را در متن‌های زمینه طولانی بهبود بخشد",
  "llm.load.llama.ropeFrequencyBase/info": "[پیشرفته] تنظیم فرکانس پایه برای کدگذاری موقعیتی چرخشی که بر نحوه جاسازی اطلاعات موقعیتی تأثیر می‌گذارد",
  "llm.load.llama.ropeFrequencyScale/title": "مقیاس فرکانسی RoPE",
  "llm.load.llama.ropeFrequencyScale/subTitle": "طول متن زمینه با این ضریب مقیاس می‌شود تا زمینه موثر با استفاده از RoPE گسترش یابد",
  "llm.load.llama.ropeFrequencyScale/info": "[پیشرفته] تنظیم مقیاس فرکانس برای کدگذاری موقعیتی چرخشی جهت کنترل دقت کدگذاری موقعیتی",
  "llm.load.llama.acceleration.offloadRatio/title": "خارج‌سازی به GPU",
  "llm.load.llama.acceleration.offloadRatio/subTitle": "تعداد لایه‌های مدل برای پردازش روی GPU جهت شتاب‌دهی",
  "llm.load.llama.acceleration.offloadRatio/info": "تعیین تعداد لایه‌هایی که به GPU منتقل می‌شوند",
  "llm.load.llama.flashAttention/title": "توجه سریع",
  "llm.load.llama.flashAttention/subTitle": "مصرف حافظه و زمان تولید را در برخی مدل‌ها کاهش می‌دهد",
  "llm.load.llama.flashAttention/info": "مکانیزم‌های توجه را برای پردازش سریع‌تر و کارآمدتر تسریع می‌کند",
  "llm.load.numExperts/title": "تعداد متخصصین",
  "llm.load.numExperts/subTitle": "تعداد متخصصین مورد استفاده در مدل",
  "llm.load.numExperts/info": "تعداد متخصصین استفاده شده در مدل",
  "llm.load.llama.keepModelInMemory/title": "نگهداری مدل در حافظه",
  "llm.load.llama.keepModelInMemory/subTitle": "حتی با وجود انتقال به GPU، حافظه سیستم را برای مدل رزرو می‌کند. عملکرد را بهبود می‌بخشد اما به RAM بیشتری نیاز دارد",
  "llm.load.llama.keepModelInMemory/info": "از جابجایی مدل به دیسک جلوگیری کرده و دسترسی سریع‌تر را با مصرف RAM بیشتر تضمین می‌کند",
  "llm.load.llama.useFp16ForKVCache/title": "استفاده از FP16 برای حافظه نهان کلید-مقدار",
  "llm.load.llama.useFp16ForKVCache/info": "مصرف حافظه را با ذخیره‌سازی حافظه نهان در دقت نیمه (FP16) کاهش می‌دهد",
  "llm.load.llama.tryMmap/title": "امتحان کردن mmap()",
  "llm.load.llama.tryMmap/subTitle": "زمان بارگذاری مدل را بهبود می‌بخشد. غیرفعال کردن این گزینه ممکن است عملکرد را هنگام بزرگ‌تر بودن مدل از حافظه موجود بهبود بخشد",
  "llm.load.llama.tryMmap/info": "بارگذاری مستقیم فایل‌های مدل از دیسک به حافظه",

  "embedding.load.contextLength/title": "طول متن زمینه",
  "embedding.load.contextLength/subTitle": "حداکثر تعداد توکن‌هایی که مدل می‌تواند در یک اعلان پردازش کند. برای مدیریت پیشرفته‌تر به بخش «پارامترهای استنتاج» مراجعه کنید",
  "embedding.load.contextLength/info": "تعیین کننده حداکثر تعداد توکن‌های قابل پردازش همزمان که بر میزان حفظ متن زمینه تأثیر می‌گذارد",
  "embedding.load.llama.ropeFrequencyBase/title": "پایه فرکانسی RoPE",
  "embedding.load.llama.ropeFrequencyBase/subTitle": "فرکانس پایه سفارشی برای جاسازی موقعیتی چرخشی (RoPE). افزایش این مقدار ممکن است عملکرد را در متن‌های زمینه طولانی بهبود بخشد",
  "embedding.load.llama.ropeFrequencyBase/info": "[پیشرفته] تنظیم فرکانس پایه برای کدگذاری موقعیتی چرخشی که بر نحوه جاسازی اطلاعات موقعیتی تأثیر می‌گذارد",
  "embedding.load.llama.evalBatchSize/title": "اندازه دسته ارزیابی",
  "embedding.load.llama.evalBatchSize/subTitle": "تعداد توکن‌های ورودی برای پردازش همزمان. افزایش این مقدار عملکرد را به قیمت مصرف بیشتر حافظه بهبود می‌بخشد",
  "embedding.load.llama.evalBatchSize/info": "تعیین تعداد توکن‌های پردازش شده در یک دسته طی ارزیابی",
  "embedding.load.llama.ropeFrequencyScale/title": "مقیاس فرکانسی RoPE",
  "embedding.load.llama.ropeFrequencyScale/subTitle": "طول متن زمینه با این ضریب مقیاس می‌شود تا زمینه موثر با استفاده از RoPE گسترش یابد",
  "embedding.load.llama.ropeFrequencyScale/info": "[پیشرفته] تنظیم مقیاس فرکانس برای کدگذاری موقعیتی چرخشی جهت کنترل دقت کدگذاری موقعیتی",
  "embedding.load.llama.acceleration.offloadRatio/title": "خارج‌سازی به GPU",
  "embedding.load.llama.acceleration.offloadRatio/subTitle": "تعداد لایه‌های مدل برای پردازش روی GPU جهت شتاب‌دهی",
  "embedding.load.llama.acceleration.offloadRatio/info": "تعیین تعداد لایه‌هایی که به GPU منتقل می‌شوند",
  "embedding.load.llama.keepModelInMemory/title": "نگهداری مدل در حافظه",
  "embedding.load.llama.keepModelInMemory/subTitle": "حتی با وجود انتقال به GPU، حافظه سیستم را برای مدل رزرو می‌کند. عملکرد را بهبود می‌بخشد اما به RAM بیشتری نیاز دارد",
  "embedding.load.llama.keepModelInMemory/info": "از جابجایی مدل به دیسک جلوگیری کرده و دسترسی سریع‌تر را با مصرف RAM بیشتر تضمین می‌کند",
  "embedding.load.llama.tryMmap/title": "امتحان کردن mmap()",
  "embedding.load.llama.tryMmap/subTitle": "زمان بارگذاری مدل را بهبود می‌بخشد. غیرفعال کردن این گزینه ممکن است عملکرد را هنگام بزرگ‌تر بودن مدل از حافظه موجود بهبود بخشد",
  "embedding.load.llama.tryMmap/info": "بارگذاری مستقیم فایل‌های مدل از دیسک به حافظه",
  "embedding.load.seed/title": "سید",
  "embedding.load.seed/subTitle": "مقدار سید برای مولد اعداد تصادفی در تولید متن. مقدار -1 سید تصادفی است",

  "embedding.load.seed/info": "سید تصادفی: تنظیم سید برای تولید اعداد تصادفی جهت اطمینان از نتایج تکرارپذیر",

  "presetTooltip": {
    "included/title": "مقادیر پیش‌تنظیم",
    "included/description": "فیلدهای زیر اعمال خواهند شد",
    "included/empty": "هیچ فیلدی از این پیش‌تنظیم در این متناسب نیست.",
    "included/conflict": "از شما خواسته می‌شود انتخاب کنید که آیا این مقدار اعمال شود یا خیر",
    "separateLoad/title": "پیکربندی زمان بارگذاری",
    "separateLoad/description.1": "این پیش‌تنظیم شامل تنظیمات زمان بارگذاری زیر نیز می‌شود. این تنظیمات در سطح مدل بوده و نیازمند بارگذاری مجدد مدل هستند. دکمه",
    "separateLoad/description.2": "را نگه دارید تا اعمال شود برای",
    "separateLoad/description.3": ".",
    "excluded/title": "ممکن است اعمال نشود",
    "excluded/description": "فیلدهای زیر در پیش‌تنظیم موجودند اما در این متناسب نیستند",
    "legacy/title": "پیش‌تنظیم قدیمی",
    "legacy/description": "این یک پیش‌تنظیم قدیمی است. شامل فیلدهای زیر می‌شود که یا اکنون به صورت خودکار مدیریت می‌شوند یا دیگر کاربردی ندارند."
  },

  "customInputs": {
    "string": {
      "emptyParagraph": "<خالی>"
    },
    "checkboxNumeric": {
      "off": "خاموش"
    },
    "stringArray": {
      "empty": "<خالی>"
    },
    "llmPromptTemplate": {
      "type": "نوع",
      "types.jinja/label": "قالب (Jinja)",
      "jinja.bosToken/label": "توکن BOS",
      "jinja.eosToken/label": "توکن EOS",
      "jinja.template/label": "قالب",
      "jinja/error": "خطا در تجزیه قالب Jinja: {{error}}",
      "jinja/empty": "لطفاً یک قالب Jinja وارد کنید",
      "jinja/unlikelyToWork": "قالب Jinja وارد شده احتمالاً کار نمی‌کند زیرا به متغیر «messages» ارجاع نشده است. لطفاً بررسی کنید",
      "types.manual/label": "دستی",
      "manual.subfield.beforeSystem/label": "قبل از سیستم",
      "manual.subfield.beforeSystem/placeholder": "پیشوند سیستم را وارد کنید...",
      "manual.subfield.afterSystem/label": "پس از سیستم",
      "manual.subfield.afterSystem/placeholder": "پسوند سیستم را وارد کنید...",
      "manual.subfield.beforeUser/label": "قبل از کاربر",
      "manual.subfield.beforeUser/placeholder": "پیشوند کاربر را وارد کنید...",
      "manual.subfield.afterUser/label": "پس از کاربر",
      "manual.subfield.afterUser/placeholder": "پسوند کاربر را وارد کنید...",
      "manual.subfield.beforeAssistant/label": "قبل از دستیار",
      "manual.subfield.beforeAssistant/placeholder": "پیشوند دستیار را وارد کنید...",
      "manual.subfield.afterAssistant/label": "پس از دستیار",
      "manual.subfield.afterAssistant/placeholder": "پسوند دستیار را وارد کنید...",
      "stopStrings/label": "رشته‌های توقف اضافی",
      "stopStrings/subTitle": "رشته‌های توقف خاص قالب که علاوه بر رشته‌های تعیین شده توسط کاربر استفاده می‌شوند"
    },
    "contextLength": {
      "maxValueTooltip": "این حداکثر تعداد توکنی است که مدل برای پردازش آموزش دیده است. کلیک کنید تا متن زمینه روی این مقدار تنظیم شود",
      "maxValueTextStart": "مدل تا سقف",
      "maxValueTextEnd": "توکن را پشتیبانی می‌کند",
      "tooltipHint": "با وجود پشتیبانی مدل از تعداد توکن بیشتر، عملکرد ممکن است با محدودیت منابع سخت‌افزاری کاهش یابد - در افزایش این مقدار احتیاط کنید"
    },
    "contextOverflowPolicy": {
      "stopAtLimit": "توقف در حد مجاز",
      "stopAtLimitSub": "تولید را متوقف کند وقتی حافظه مدل پر شود",
      "truncateMiddle": "حذف از میانه",
      "truncateMiddleSub": "پیام‌های میانی گفتگو را حذف می‌کند تا فضای کافی ایجاد شود. مدل ابتدای گفتگو را به خاطر می‌سپارد",
      "rollingWindow": "پنجره گردان",
      "rollingWindowSub": "مدل همیشه جدیدترین پیام‌ها را دریافت می‌کند اما ممکن است ابتدای گفتگو را فراموش کند"
    },
    "llamaAccelerationOffloadRatio": {
      "max": "حداکثر",
      "off": "خاموش"
    }
  },
  "saveConflictResolution": {
    "title": "انتخاب مقادیر برای گنجاندن در پیش‌تنظیم",
    "description": "مقادیر مورد نظر برای حفظ را انتخاب کنید",
    "instructions": "برای گنجاندن مقدار، روی آن کلیک کنید",
    "userValues": "مقدار قبلی",
    "presetValues": "مقدار جدید",
    "confirm": "تأیید",
    "cancel": "لغو"
  },
  "applyConflictResolution": {
    "title": "کدام مقادیر حفظ شوند؟",
    "description": "تغییرات ذخیره نشده‌ای دارید که با پیش‌تنظیم ورودی تداخل دارند",
    "instructions": "برای حفظ مقدار، روی آن کلیک کنید",
    "userValues": "مقدار فعلی",
    "presetValues": "مقدار پیش‌تنظیم ورودی",
    "confirm": "تأیید",
    "cancel": "لغو"
  },
  "empty": "<خالی>",
  "presets": {
    "title": "پیش‌تنظیم",
    "commitChanges": "ذخیره تغییرات",
    "commitChanges/description": "تغییرات را در پیش‌تنظیم ذخیره کنید",
    "commitChanges.manual": "فیلدهای جدید شناسایی شدند. می‌توانید انتخاب کنید کدام تغییرات در پیش‌تنظیم گنجانده شوند",
    "commitChanges.manual.hold.0": "دکمه",
    "commitChanges.manual.hold.1": "را نگه دارید تا تغییرات مورد نظر برای ذخیره انتخاب شوند",
    "commitChanges.saveAll.hold.0": "دکمه",
    "commitChanges.saveAll.hold.1": "را نگه دارید تا همه تغییرات ذخیره شوند",
    "commitChanges.saveInPreset.hold.0": "دکمه",
    "commitChanges.saveInPreset.hold.1": "را نگه دارید تا فقط تغییرات فیلدهای موجود ذخیره شوند",
    "commitChanges/error": "ذخیره تغییرات در پیش‌تنظیم ناموفق بود",
    "commitChanges.manual/description": "انتخاب تغییرات برای گنجاندن در پیش‌تنظیم",
    "saveAs": "ذخیره به عنوان جدید...",
    "presetNamePlaceholder": "نامی برای پیش‌تنظیم وارد کنید...",
    "cannotCommitChangesLegacy": "این یک پیش‌تنظیم قدیمی است و قابل ویرایش نیست. می‌توانید با استفاده از «ذخیره به عنوان جدید» یک کپی ایجاد کنید",
    "cannotCommitChangesNoChanges": "هیچ تغییری برای ذخیره وجود ندارد",
    "emptyNoUnsaved": "یک پیش‌تنظیم انتخاب کنید...",
    "emptyWithUnsaved": "پیش‌تنظیم ذخیره نشده",
    "saveEmptyWithUnsaved": "ذخیره پیش‌تنظیم به عنوان...",
    "saveConfirm": "ذخیره",
    "saveCancel": "لغو",
    "saving": "در حال ذخیره...",
    "save/error": "ذخیره پیش‌تنظیم ناموفق بود",
    "deselect": "لغو انتخاب پیش‌تنظیم",
    "deselect/error": "لغو انتخاب پیش‌تنظیم ناموفق بود",
    "select/error": "انتخاب پیش‌تنظیم ناموفق بود",
    "delete/error": "حذف پیش‌تنظیم ناموفق بود",
    "discardChanges": "نادیده گرفتن تغییرات",
    "discardChanges/info": "تمام تغییرات ذخیره نشده را نادیده گرفته و پیش‌تنظیم را به حالت اولیه بازگردان",
    "newEmptyPreset": "ایجاد پیش‌تنظیم خالی جدید...",
    "contextMenuSelect": "انتخاب پیش‌تنظیم",
    "contextMenuDelete": "حذف"
  },

  "flashAttentionWarning": "توجه سریع یک قابلیت آزمایشی است که ممکن است با برخی مدل‌ها مشکلاتی ایجاد کند. در صورت بروز مشکل، آن را غیرفعال کنید",

  "seedUncheckedHint": "سید تصادفی",
  "ropeFrequencyBaseUncheckedHint": "خودکار",
  "ropeFrequencyScaleUncheckedHint": "خودکار"
}
