{
  "noInstanceSelected": "هیچ مدل انتخاب نشده است",
  "resetToDefault": "بازنشانی",
  "showAdvancedSettings": "نمایش تنظیمات پیشرفته",
  "showAll": "همه",
  "basicSettings": "پایه",
  "configSubtitle": "پیش‌تنظیم‌ها را بارگذاری یا ذخیره کرده و پارامترهای مدل را تنظیم کنید",
  "inferenceParameters/title": "پارامترهای پیش‌بینی",
  "inferenceParameters/info": "با پارامترهایی که بر پیش‌بینی تأثیر می‌گذارند، آزمایش کنید.",
  "generalParameters/title": "عمومی",
  "samplingParameters/title": "نمونه‌گیری",
  "basicTab": "پایه",
  "advancedTab": "پیشرفته",
  "advancedTab/title": "🧪 پیکربندی پیشرفته",
  "advancedTab/expandAll": "باز کردن همه",
  "advancedTab/overridesTitle": "بازنویسی تنظیمات",
  "advancedTab/noConfigsText": "هیچ تغییری ذخیره نشده است – برای مشاهده بازنویسی‌ها، مقادیر بالا را ویرایش کنید.",
  "loadInstanceFirst": "ابتدا یک مدل را بارگذاری کنید تا پارامترهای قابل تنظیم را ببینید",
  "noListedConfigs": "هیچ پارامتر قابل تنظیمی موجود نیست",
  "generationParameters/info": "با پارامترهای پایه که بر تولید متن تأثیر دارند، آزمایش کنید.",
  "loadParameters/title": "پارامترهای بارگذاری",
  "loadParameters/description": "تنظیماتی برای نحوه‌ی بارگذاری و راه‌اندازی مدل در حافظه",
  "loadParameters/reload": "بارگذاری مجدد برای اعمال تغییرات",
  "loadParameters/reload/error": "خطا در بارگذاری مجدد مدل",
  "discardChanges": "لغو تغییرات",
  "loadModelToSeeOptions": "برای مشاهده گزینه‌ها، یک مدل را بارگذاری کنید",
  "schematicsError.title": "شمای پیکربندی در فیلدهای زیر دارای خطا است:",
  "manifestSections": {
    "structuredOutput/title": "خروجی ساختارمند",
    "speculativeDecoding/title": "رمزگشایی احتمالی",
    "sampling/title": "نمونه‌گیری",
    "settings/title": "تنظیمات",
    "toolUse/title": "استفاده از ابزار",
    "promptTemplate/title": "الگوی پرامپت"
  },

  "llm.prediction.systemPrompt/title": "پرامپت سیستمی",
  "llm.prediction.systemPrompt/description": "از این فیلد برای ارائه‌ی دستورالعمل‌های پس‌زمینه به مدل استفاده کنید، مانند مجموعه‌ای از قوانین، محدودیت‌ها یا الزامات کلی.",
  "llm.prediction.systemPrompt/subTitle": "راهنمایی برای هوش مصنوعی",
  "llm.prediction.temperature/title": "دمای تولید (Temperature)",
  "llm.prediction.temperature/subTitle": "میزان تصادفی‌ بودن خروجی. مقدار ۰ همیشه خروجی یکسانی می‌دهد و مقادیر بالاتر باعث خلاقیت و تنوع بیشتر می‌شود.",
  "llm.prediction.temperature/info": "از مستندات llama.cpp: «مقدار پیش‌فرض <{{dynamicValue}}> است که تعادل بین تصادفی بودن و تعیین‌پذیری را حفظ می‌کند. مقدار ۰ همیشه محتمل‌ترین توکن را انتخاب می‌کند و خروجی تکراری خواهد بود.»",
  "llm.prediction.llama.sampling/title": "نمونه‌گیری",
  "llm.prediction.topKSampling/title": "نمونه‌گیری Top K",
  "llm.prediction.topKSampling/subTitle": "توکن بعدی را فقط از بین k توکن با بیشترین احتمال انتخاب می‌کند. مشابه دما عمل می‌کند.",
  "llm.prediction.topKSampling/info": "از مستندات llama.cpp:\n\nروش نمونه‌گیری Top-K فقط توکن‌هایی را در نظر می‌گیرد که جزو k توکن برتر از نظر احتمال هستند. این روش احتمال تولید توکن‌های بی‌معنی را کاهش می‌دهد اما ممکن است تنوع متن را هم محدود کند. مقدار بیشتر (مثلاً ۱۰۰) تنوع بیشتری ایجاد می‌کند و مقدار کمتر (مثلاً ۱۰) متن متمرکزتری تولید می‌کند.\n\n• مقدار پیش‌فرض <{{dynamicValue}}> است.",
  "llm.prediction.llama.cpuThreads/title": "تعداد تردهای CPU",
  "llm.prediction.llama.cpuThreads/subTitle": "تعداد تردهایی که هنگام پیش‌بینی استفاده می‌شوند",
  "llm.prediction.llama.cpuThreads/info": "تعداد تردهایی که هنگام پردازش استفاده می‌شوند. افزایش تعداد تردها همیشه به معنای عملکرد بهتر نیست. مقدار پیش‌فرض <{{dynamicValue}}> است.",
  "llm.prediction.maxPredictedTokens/title": "محدودیت طول پاسخ",
  "llm.prediction.maxPredictedTokens/subTitle": "محدود کردن طول پاسخ مدل به‌صورت اختیاری",
  "llm.prediction.maxPredictedTokens/info": "طول پاسخ مدل را کنترل کنید. فعال‌سازی این گزینه اجازه می‌دهد حداکثر طول پاسخ را مشخص کنید. در غیر این‌ صورت، مدل خودش تصمیم می‌گیرد کی متوقف شود.",
  "llm.prediction.maxPredictedTokens/inputLabel": "حداکثر طول پاسخ (تعداد توکن‌ها)",
  "llm.prediction.maxPredictedTokens/wordEstimate": "حدود {{maxWords}} واژه",
  "llm.prediction.repeatPenalty/title": "جریمه‌ی تکرار",
  "llm.prediction.repeatPenalty/subTitle": "میزان جلوگیری از تکرار توکن‌ها",
  "llm.prediction.repeatPenalty/info": "از مستندات llama.cpp: «به جلوگیری از تولید متن‌های تکراری و یکنواخت کمک می‌کند. مقدار بیشتر (مثلاً ۱.۵) تکرار را شدیدتر جریمه می‌کند، در حالی که مقدار کمتر (مثلاً ۰.۹) ملایم‌تر است.» • مقدار پیش‌فرض <{{dynamicValue}}> است.",
  "llm.prediction.minPSampling/title": "نمونه‌گیری حداقلی (Min P)",
  "llm.prediction.minPSampling/subTitle": "حداقل احتمال پایه برای انتخاب یک توکن",
  "llm.prediction.minPSampling/info": "از مستندات llama.cpp:\n\nحداقل احتمالی که یک توکن باید داشته باشد تا برای خروجی انتخاب شود، نسبت به محتمل‌ترین توکن. باید بین ۰ و ۱ باشد.\n\n• مقدار پیش‌فرض <{{dynamicValue}}> است.",
  "llm.prediction.topPSampling/title": "نمونه‌گیری Top P",
  "llm.prediction.topPSampling/subTitle": "احتمال تجمعی حداقلی برای انتخاب توکن‌های بعدی. مشابه دما عمل می‌کند.",
  "llm.prediction.topPSampling/info": "از مستندات llama.cpp:\n\nTop-P یا نمونه‌گیری هسته‌ای، توکن بعدی را از بین مجموعه‌ای انتخاب می‌کند که مجموع احتمال آن‌ها حداقل برابر p باشد.\n\nاین روش تعادل بین تنوع و کیفیت را فراهم می‌کند. مقدار بالاتر (مثلاً ۰.۹۵) تنوع بیشتر و مقدار کمتر (مثلاً ۰.۵) متن محافظه‌کارانه‌تری تولید می‌کند. باید در بازه (۰، ۱] باشد.\n\n• مقدار پیش‌فرض <{{dynamicValue}}> است.",
  "llm.prediction.stopStrings/title": "رشته‌های توقف",
  "llm.prediction.stopStrings/subTitle": "رشته‌هایی که باعث توقف تولید توکن می‌شوند",
  "llm.prediction.stopStrings/info": "رشته‌هایی خاص که اگر ظاهر شوند، تولید متن متوقف می‌شود.",
  "llm.prediction.stopStrings/placeholder": "یک رشته وارد کرده و ⏎ را فشار دهید",
  "llm.prediction.contextOverflowPolicy/title": "افزایش بیش‌ازحد حافظه متنی",
  "llm.prediction.contextOverflowPolicy/subTitle": "رفتار مدل در صورت بزرگ شدن بیش از حد گفتگو",
  "llm.prediction.contextOverflowPolicy/info": "تعیین کنید که مدل هنگام عبور از حداکثر حافظه متنی چطور عمل کند.",
  "llm.prediction.llama.frequencyPenalty/title": "جریمه تکرار فرکانسی",
  "llm.prediction.llama.presencePenalty/title": "جریمه حضور",
  "llm.prediction.llama.tailFreeSampling/title": "نمونه‌گیری بدون دُم",
  "llm.prediction.llama.locallyTypicalSampling/title": "نمونه‌گیری معمول محلی",
  "llm.prediction.llama.xtcProbability/title": "احتمال نمونه‌گیری XTC",
  "llm.prediction.llama.xtcProbability/subTitle": "نمونه‌گیری XTC فقط با این احتمال در هر توکن فعال می‌شود. این روش باعث افزایش خلاقیت و کاهش کلیشه می‌شود.",
  "llm.prediction.llama.xtcProbability/info": "نمونه‌گیری XTC فقط با این احتمال در هر توکن فعال می‌شود. معمولاً خلاقیت را افزایش داده و کلیشه‌ها را کاهش می‌دهد.",
  "llm.prediction.llama.xtcThreshold/title": "آستانه نمونه‌گیری XTC",
  "llm.prediction.llama.xtcThreshold/subTitle": "آستانه‌ای برای حذف توکن‌های پرتکرار. با احتمال `xtc-probability`، توکن‌هایی با احتمال بین `xtc-threshold` و ۰.۵ حذف می‌شوند، به‌جز کم‌احتمال‌ترین توکن",
  "llm.prediction.llama.xtcThreshold/info": "آستانه‌ای برای نمونه‌گیری XTC. توکن‌هایی بین `xtc-threshold` و ۰.۵ بررسی می‌شوند و همه به‌جز کم‌احتمال‌ترین حذف می‌شوند.",
  "llm.prediction.mlx.topKSampling/title": "نمونه‌گیری Top K",
  "llm.prediction.mlx.topKSampling/subTitle": "توکن بعدی را فقط از بین k توکن برتر انتخاب می‌کند",
  "llm.prediction.mlx.topKSampling/info": "توکن بعدی فقط از بین محتمل‌ترین k توکن انتخاب می‌شود. مشابه دما عمل می‌کند.",
  "llm.prediction.onnx.topKSampling/title": "نمونه‌گیری Top K",
  "llm.prediction.onnx.topKSampling/subTitle": "محدود کردن توکن بعدی به بین k توکن با بیشترین احتمال",
  "llm.prediction.onnx.topKSampling/info": "از مستندات ONNX:\n\nفقط k توکن با بیشترین احتمال برای تولید در نظر گرفته می‌شوند.\n\n• این فیلتر به‌صورت پیش‌فرض غیرفعال است.",
  "llm.prediction.onnx.repeatPenalty/title": "جریمه تکرار",
  "llm.prediction.onnx.repeatPenalty/subTitle": "میزان جلوگیری از تکرار توکن",
  "llm.prediction.onnx.repeatPenalty/info": "مقدار بیشتر باعث جلوگیری بیشتر از تکرار متن می‌شود.",
  "llm.prediction.onnx.topPSampling/title": "نمونه‌گیری Top P",
  "llm.prediction.onnx.topPSampling/subTitle": "احتمال تجمعی حداقلی برای انتخاب توکن‌های بعدی",
  "llm.prediction.onnx.topPSampling/info": "از مستندات ONNX:\n\nفقط محتمل‌ترین توکن‌ها که مجموع احتمال‌شان برابر یا بیشتر از TopP باشد انتخاب می‌شوند.\n\n• این فیلتر به‌صورت پیش‌فرض غیرفعال است.",
  "llm.prediction.seed/title": "بذر تصادفی",
  "llm.prediction.structured/title": "خروجی ساختارمند",
  "llm.prediction.structured/info": "خروجی ساختارمند",
  "llm.prediction.structured/description": "پیشرفته: می‌توانید یک [JSON Schema](https://json-schema.org/learn/miscellaneous-examples) برای اجبار مدل به تولید خروجی با فرمت خاص ارائه دهید. مستندات را در [این لینک](https://lmstudio.ai/docs/advanced/structured-output) ببینید.",
  "llm.prediction.tools/title": "استفاده از ابزار",
  "llm.prediction.tools/description": "پیشرفته: می‌توانید لیستی از ابزارهای سازگار با JSON برای فراخوانی توسط مدل فراهم کنید. مستندات را در [این لینک](https://lmstudio.ai/docs/advanced/tool-use) بخوانید.",
  "llm.prediction.tools/serverPageDescriptionAddon": "در درخواست‌های API از طریق فیلد `tools` ارسال شود.",
  "llm.prediction.promptTemplate/title": "الگوی پرامپت",
  "llm.prediction.promptTemplate/subTitle": "قالبی که پیام‌ها در چت برای مدل ارسال می‌شوند. تغییر آن ممکن است رفتارهای غیرمنتظره ایجاد کند - فقط در صورتی تغییر دهید که بدانید چه می‌کنید!",
  "llm.prediction.speculativeDecoding.numDraftTokensExact/title": "تعداد توکن‌های پیشنویس",
  "llm.prediction.speculativeDecoding.numDraftTokensExact/subTitle": "تعداد توکن‌هایی که مدل پیشنویس به ازای هر توکن مدل اصلی تولید می‌کند. تعادلی میان سرعت و کیفیت بیابید.",
  "llm.prediction.speculativeDecoding.minContinueDraftingProbability/title": "آستانه ادامه پیشنویس",
  "llm.prediction.speculativeDecoding.minContinueDraftingProbability/subTitle": "تولید پیشنویس تا زمانی ادامه یابد که احتمال توکن کمتر از این مقدار شود. مقادیر بالاتر = ریسک کمتر، پاداش کمتر",
  "llm.prediction.speculativeDecoding.minDraftLengthToConsider/title": "حداقل طول پیشنویس",
  "llm.prediction.speculativeDecoding.minDraftLengthToConsider/subTitle": "پیشنویس‌هایی که طول‌شان کمتر از این مقدار باشد نادیده گرفته می‌شوند",
  "llm.prediction.speculativeDecoding.maxTokensToDraft/title": "حداکثر اندازه پیشنویس",
  "llm.prediction.speculativeDecoding.maxTokensToDraft/subTitle": "حداکثر تعداد توکن مجاز در یک پیشنویس. اگر احتمال همه توکن‌ها بالاتر از آستانه باشد، این مقدار سقف است.",
  "llm.prediction.speculativeDecoding.draftModel/title": "مدل پیشنویس",
  "llm.prediction.reasoning.parsing/title": "تجزیه بخش استدلال",
  "llm.prediction.reasoning.parsing/subTitle": "نحوه تجزیه بخش‌های استدلال در خروجی مدل",

  "llm.load.contextLength/title": "طول زمینه (Context)",
  "llm.load.contextLength/subTitle": "حداکثر تعداد توکن‌هایی که مدل می‌تواند در یک پرامپت بررسی کند. برای مدیریت بیشتر، گزینه‌های سرریز گفتگو را در بخش \"پارامترهای پیش‌بینی\" ببینید",
  "llm.load.contextLength/info": "تعداد حداکثری توکن‌هایی که مدل به طور هم‌زمان می‌تواند بررسی کند را مشخص می‌کند و بر میزان زمینه‌ی قابل نگهداری در پردازش تأثیر می‌گذارد",
  "llm.load.contextLength/warning": "تنظیم مقدار بالا برای طول زمینه می‌تواند مصرف حافظه را به‌طور قابل توجهی افزایش دهد",
  "llm.load.seed/title": "بذر (Seed)",
  "llm.load.seed/subTitle": "بذر تولیدکننده اعداد تصادفی برای تولید متن. مقدار -1 به معنی تصادفی بودن است",
  "llm.load.seed/info": "بذر تصادفی: مقدار بذر را برای تولید نتایج قابل تکرار تنظیم می‌کند",

  "llm.load.llama.evalBatchSize/title": "اندازه دسته ارزیابی",
  "llm.load.llama.evalBatchSize/subTitle": "تعداد توکن‌هایی که به‌صورت هم‌زمان پردازش می‌شوند. افزایش این مقدار عملکرد را افزایش ولی مصرف حافظه را نیز بالا می‌برد",
  "llm.load.llama.evalBatchSize/info": "تعداد مثال‌هایی که در یک دسته هنگام ارزیابی پردازش می‌شوند را تنظیم می‌کند، که بر سرعت و مصرف حافظه تأثیر می‌گذارد",
  "llm.load.llama.ropeFrequencyBase/title": "پایه فرکانس RoPE",
  "llm.load.llama.ropeFrequencyBase/subTitle": "پایه سفارشی برای جاسازی موقعیتی چرخشی (RoPE). افزایش آن ممکن است عملکرد را در زمینه‌های طولانی بهبود دهد",
  "llm.load.llama.ropeFrequencyBase/info": "[پیشرفته] پایه فرکانس را برای رمزگذاری موقعیتی چرخشی تنظیم می‌کند که بر نحوه جاسازی اطلاعات موقعیتی تأثیر دارد",
  "llm.load.llama.ropeFrequencyScale/title": "مقیاس فرکانس RoPE",
  "llm.load.llama.ropeFrequencyScale/subTitle": "طول زمینه با این ضریب مقیاس‌بندی می‌شود تا زمینه‌ی مؤثر را با استفاده از RoPE افزایش دهد",
  "llm.load.llama.ropeFrequencyScale/info": "[پیشرفته] مقیاس فرکانس در RoPE را برای کنترل دقت موقعیتی تنظیم می‌کند",
  "llm.load.llama.acceleration.offloadRatio/title": "استفاده از GPU",
  "llm.load.llama.acceleration.offloadRatio/subTitle": "تعداد لایه‌های مدل که برای شتاب GPU محاسبه می‌شوند",
  "llm.load.llama.acceleration.offloadRatio/info": "تعداد لایه‌هایی را که به GPU منتقل می‌شوند تنظیم می‌کند",
  "llm.load.llama.flashAttention/title": "توجه سریع (Flash Attention)",
  "llm.load.llama.flashAttention/subTitle": "مصرف حافظه و زمان تولید را در برخی مدل‌ها کاهش می‌دهد",
  "llm.load.llama.flashAttention/info": "مکانیسم‌های توجه را برای پردازش سریع‌تر و کارآمدتر تسریع می‌کند",
  "llm.load.numExperts/title": "تعداد متخصص‌ها",
  "llm.load.numExperts/subTitle": "تعداد متخصص‌هایی که در مدل استفاده می‌شود",
  "llm.load.numExperts/info": "تعداد متخصص‌هایی که در مدل استفاده می‌شود",
  "llm.load.llama.keepModelInMemory/title": "نگهداری مدل در حافظه",
  "llm.load.llama.keepModelInMemory/subTitle": "حافظه سیستم را برای مدل رزرو می‌کند حتی اگر به GPU منتقل شده باشد. عملکرد را بهبود می‌دهد اما RAM بیشتری نیاز دارد",
  "llm.load.llama.keepModelInMemory/info": "از انتقال مدل به دیسک جلوگیری می‌کند و دسترسی سریع‌تر را فراهم می‌کند اما مصرف RAM را افزایش می‌دهد",
  "llm.load.llama.useFp16ForKVCache/title": "استفاده از FP16 برای کش KV",
  "llm.load.llama.useFp16ForKVCache/info": "با ذخیره کش در دقت نیمه (FP16) مصرف حافظه را کاهش می‌دهد",
  "llm.load.llama.tryMmap/title": "استفاده از mmap()",
  "llm.load.llama.tryMmap/subTitle": "زمان بارگذاری مدل را بهبود می‌بخشد. غیرفعال کردن آن ممکن است هنگام بزرگ بودن مدل نسبت به RAM عملکرد بهتری بدهد",
  "llm.load.llama.tryMmap/info": "فایل‌های مدل را مستقیماً از دیسک به حافظه بارگذاری می‌کند",
  "llm.load.llama.cpuThreadPoolSize/title": "اندازه مخزن ترد CPU",
  "llm.load.llama.cpuThreadPoolSize/subTitle": "تعداد تردهای CPU اختصاص‌ یافته برای محاسبه مدل",
  "llm.load.llama.cpuThreadPoolSize/info": "تعداد تردهای CPU برای محاسبه مدل را مشخص می‌کند. افزایش آن همیشه به معنای عملکرد بهتر نیست. مقدار پیش‌فرض <{{dynamicValue}}> است.",
  "llm.load.llama.kCacheQuantizationType/title": "نوع کوانتیزه‌سازی کش K",
  "llm.load.llama.kCacheQuantizationType/subTitle": "مقدارهای پایین‌تر مصرف حافظه را کاهش می‌دهند ولی ممکن است کیفیت را نیز کاهش دهند. تأثیر آن بسته به مدل متفاوت است.",
  "llm.load.llama.vCacheQuantizationType/title": "نوع کوانتیزه‌سازی کش V",
  "llm.load.llama.vCacheQuantizationType/subTitle": "مقدارهای پایین‌تر مصرف حافظه را کاهش می‌دهند ولی ممکن است کیفیت را نیز کاهش دهند. تأثیر آن بسته به مدل متفاوت است.",
  "llm.load.llama.vCacheQuantizationType/turnedOnWarning": "⚠️ اگر Flash Attention فعال نیست، باید این مقدار را غیرفعال کنید",
  "llm.load.llama.vCacheQuantizationType/disabledMessage": "تنها در صورتی می‌توان این گزینه را فعال کرد که Flash Attention نیز فعال باشد",
  "llm.load.llama.vCacheQuantizationType/invalidF32MetalState": "⚠️ هنگام استفاده از F32 باید Flash Attention غیرفعال باشد",
  "llm.load.mlx.kvCacheBits/title": "کوانتیزه‌سازی کش KV",
  "llm.load.mlx.kvCacheBits/subTitle": "تعداد بیت‌هایی که کش KV باید کوانتیزه شود",
  "llm.load.mlx.kvCacheBits/info": "تعداد بیت‌هایی که کش KV باید کوانتیزه شود",
  "llm.load.mlx.kvCacheBits/turnedOnWarning": "هنگام استفاده از کوانتیزه‌سازی کش KV، تنظیمات طول زمینه نادیده گرفته می‌شود",
  "llm.load.mlx.kvCacheGroupSize/title": "کوانتیزه‌سازی کش KV: اندازه گروه",
  "llm.load.mlx.kvCacheGroupSize/subTitle": "اندازه گروه هنگام عملیات کوانتیزه‌سازی کش KV. مقدار بیشتر حافظه را کمتر مصرف می‌کند ولی ممکن است کیفیت را کاهش دهد",
  "llm.load.mlx.kvCacheGroupSize/info": "تعداد بیت‌هایی که کش KV باید کوانتیزه شود",
  "llm.load.mlx.kvCacheQuantizationStart/title": "شروع کوانتیزه‌سازی کش KV",
  "llm.load.mlx.kvCacheQuantizationStart/subTitle": "آستانه طول زمینه برای شروع کوانتیزه‌سازی کش KV",
  "llm.load.mlx.kvCacheQuantizationStart/info": "آستانه طول زمینه برای شروع کوانتیزه‌سازی کش KV",
  "llm.load.mlx.kvCacheQuantization/title": "کوانتیزه‌سازی کش KV",
  "llm.load.mlx.kvCacheQuantization/subTitle": "کش KV مدل را کوانتیزه می‌کند. این کار ممکن است سرعت تولید را افزایش داده و مصرف حافظه را کاهش دهد، ولی ممکن است به قیمت کیفیت خروجی مدل باشد.",
  "llm.load.mlx.kvCacheQuantization/bits/title": "بیت‌های کوانتیزه‌سازی کش KV",
  "llm.load.mlx.kvCacheQuantization/bits/tooltip": "تعداد بیت‌هایی که کش KV باید با آن کوانتیزه شود",
  "llm.load.mlx.kvCacheQuantization/bits/bits": "بیت",
  "llm.load.mlx.kvCacheQuantization/groupSize/title": "استراتژی اندازه گروه",
  "llm.load.mlx.kvCacheQuantization/groupSize/accuracy": "دقت",
  "llm.load.mlx.kvCacheQuantization/groupSize/balanced": "متعادل",
  "llm.load.mlx.kvCacheQuantization/groupSize/speedy": "سریع",
  "llm.load.mlx.kvCacheQuantization/groupSize/tooltip": "پیشرفته: پیکربندی 'matmul group size' برای کوانتیزه‌سازی\n\n• دقت = گروه ۳۲\n• متعادل = گروه ۶۴\n• سریع = گروه ۱۲۸\n",
  "llm.load.mlx.kvCacheQuantization/quantizedStart/title": "شروع کوانتیزه‌سازی زمانی که زمینه به این مقدار برسد",
  "llm.load.mlx.kvCacheQuantization/quantizedStart/tooltip": "هنگامی که طول زمینه به این مقدار توکن برسد، کوانتیزه‌سازی کش KV را آغاز کن",

  "embedding.load.contextLength/title": "طول زمینه (Context)",
  "embedding.load.contextLength/subTitle": "حداکثر تعداد توکن‌هایی که مدل می‌تواند در یک پرامپت بررسی کند. برای گزینه‌های بیشتر به بخش \"پارامترهای پیش‌بینی\" مراجعه کنید",
  "embedding.load.contextLength/info": "حداکثر تعداد توکن‌هایی که مدل می‌تواند به‌طور هم‌زمان در نظر بگیرد را مشخص می‌کند و بر میزان زمینه‌ای که مدل می‌تواند نگه دارد تأثیر می‌گذارد",
  "embedding.load.llama.ropeFrequencyBase/title": "پایه فرکانس RoPE",
  "embedding.load.llama.ropeFrequencyBase/subTitle": "پایه سفارشی برای جاسازی موقعیتی چرخشی (RoPE). افزایش این مقدار ممکن است عملکرد بهتری در زمینه‌های طولانی فراهم کند",
  "embedding.load.llama.ropeFrequencyBase/info": "[پیشرفته] پایه فرکانس را برای رمزگذاری موقعیتی چرخشی تنظیم می‌کند که بر نحوه جاسازی اطلاعات موقعیتی تأثیر دارد",
  "embedding.load.llama.evalBatchSize/title": "اندازه دسته ارزیابی",
  "embedding.load.llama.evalBatchSize/subTitle": "تعداد توکن‌هایی که به‌صورت هم‌زمان پردازش می‌شوند. افزایش آن عملکرد را بالا می‌برد ولی مصرف حافظه را نیز افزایش می‌دهد",
  "embedding.load.llama.evalBatchSize/info": "تعداد توکن‌هایی که در یک دسته هنگام ارزیابی پردازش می‌شوند را تنظیم می‌کند",
  "embedding.load.llama.ropeFrequencyScale/title": "مقیاس فرکانس RoPE",
  "embedding.load.llama.ropeFrequencyScale/subTitle": "طول زمینه با این ضریب مقیاس‌بندی می‌شود تا زمینه مؤثر با استفاده از RoPE افزایش یابد",
  "embedding.load.llama.ropeFrequencyScale/info": "[پیشرفته] مقیاس فرکانس در رمزگذاری موقعیتی چرخشی را برای کنترل دقت رمزگذاری موقعیتی تنظیم می‌کند",
  "embedding.load.llama.acceleration.offloadRatio/title": "استفاده از GPU",
  "embedding.load.llama.acceleration.offloadRatio/subTitle": "تعداد لایه‌های مجزای مدل که برای شتاب GPU پردازش می‌شوند",
  "embedding.load.llama.acceleration.offloadRatio/info": "تعداد لایه‌هایی که به GPU منتقل می‌شوند را تنظیم می‌کند",
  "embedding.load.llama.keepModelInMemory/title": "نگه‌داشتن مدل در حافظه",
  "embedding.load.llama.keepModelInMemory/subTitle": "حافظه سیستم را برای مدل رزرو می‌کند حتی اگر به GPU منتقل شود. عملکرد را افزایش می‌دهد ولی RAM بیشتری مصرف می‌کند",
  "embedding.load.llama.keepModelInMemory/info": "جلوگیری می‌کند از این‌که مدل به دیسک منتقل شود، دسترسی سریع‌تر را فراهم می‌کند اما مصرف حافظه را بالا می‌برد",
  "embedding.load.llama.tryMmap/title": "استفاده از mmap()",
  "embedding.load.llama.tryMmap/subTitle": "زمان بارگذاری مدل را بهبود می‌دهد. غیرفعال کردن آن در صورت بزرگ بودن مدل نسبت به RAM می‌تواند عملکرد بهتری بدهد",
  "embedding.load.llama.tryMmap/info": "فایل‌های مدل را مستقیماً از دیسک به حافظه بارگذاری می‌کند",
  "embedding.load.seed/title": "بذر (Seed)",
  "embedding.load.seed/subTitle": "بذر تولیدکننده اعداد تصادفی برای تولید متن. -1 به معنای بذر تصادفی است",
  "embedding.load.seed/info": "بذر تصادفی: مقدار بذر را برای تولید نتایج قابل تکرار تنظیم می‌کند",

  "presetTooltip": {
    "included/title": "مقادیر پیش‌فرض",
    "included/description": "فیلدهای زیر اعمال خواهند شد",
    "included/empty": "هیچ‌کدام از فیلدهای این پیش‌تنظیم در این زمینه اعمال نمی‌شوند.",
    "included/conflict": "از شما خواسته خواهد شد که انتخاب کنید آیا این مقدار اعمال شود یا نه",
    "separateLoad/title": "تنظیمات زمان بارگذاری",
    "separateLoad/description.1": "این پیش‌تنظیم همچنین شامل تنظیمات بارگذاری زیر می‌باشد. این تنظیمات مربوط به کل مدل هستند و برای اعمال نیاز به بارگذاری مجدد مدل دارند. نگه‌دارید",
    "separateLoad/description.2": "برای اعمال به",
    "separateLoad/description.3": ".",
    "excluded/title": "ممکن است اعمال نشود",
    "excluded/description": "فیلدهای زیر در پیش‌تنظیم وجود دارند اما در زمینه‌ی فعلی قابل استفاده نیستند.",
    "legacy/title": "پیش‌تنظیم قدیمی",
    "legacy/description": "این پیش‌تنظیم یک نسخه قدیمی است. شامل فیلدهایی است که اکنون به صورت خودکار مدیریت می‌شوند یا دیگر کاربردی ندارند.",
    "button/publish": "انتشار در هاب",
    "button/pushUpdate": "ارسال تغییرات به هاب",
    "button/export": "خروجی گرفتن"
  },

  "customInputs": {
    "string": {
      "emptyParagraph": "<خالی>"
    },
    "checkboxNumeric": {
      "off": "خاموش"
    },
    "llamaCacheQuantizationType": {
      "off": "خاموش"
    },
    "mlxKvCacheBits": {
      "off": "خاموش"
    },
    "stringArray": {
      "empty": "<خالی>"
    },
    "llmPromptTemplate": {
      "type": "نوع",
      "types.jinja/label": "الگو (Jinja)",
      "jinja.bosToken/label": "توکن شروع (BOS)",
      "jinja.eosToken/label": "توکن پایان (EOS)",
      "jinja.template/label": "الگو",
      "jinja/error": "خطا در پردازش الگوی Jinja: {{error}}",
      "jinja/empty": "لطفاً در بالا یک الگوی Jinja وارد کنید.",
      "jinja/unlikelyToWork": "الگوی Jinja وارد شده به نظر نمی‌رسد که کار کند، زیرا متغیر \"messages\" را شامل نمی‌شود. لطفاً بررسی کنید که الگو را به‌درستی وارد کرده‌اید.",
      "types.manual/label": "دستی",
      "manual.subfield.beforeSystem/label": "قبل از سیستم",
      "manual.subfield.beforeSystem/placeholder": "پیشوند سیستم را وارد کنید...",
      "manual.subfield.afterSystem/label": "بعد از سیستم",
      "manual.subfield.afterSystem/placeholder": "پسوند سیستم را وارد کنید...",
      "manual.subfield.beforeUser/label": "قبل از کاربر",
      "manual.subfield.beforeUser/placeholder": "پیشوند کاربر را وارد کنید...",
      "manual.subfield.afterUser/label": "بعد از کاربر",
      "manual.subfield.afterUser/placeholder": "پسوند کاربر را وارد کنید...",
      "manual.subfield.beforeAssistant/label": "قبل از دستیار",
      "manual.subfield.beforeAssistant/placeholder": "پیشوند دستیار را وارد کنید...",
      "manual.subfield.afterAssistant/label": "بعد از دستیار",
      "manual.subfield.afterAssistant/placeholder": "پسوند دستیار را وارد کنید...",
      "stopStrings/label": "رشته‌های توقف اضافی",
      "stopStrings/subTitle": "رشته‌های توقف خاص این الگو که علاوه بر موارد مشخص‌شده توسط کاربر استفاده خواهند شد."
    },
    "contextLength": {
      "maxValueTooltip": "این حداکثر تعداد توکن‌هایی است که مدل برای پردازش آموزش دیده است. کلیک کنید تا طول زمینه روی این مقدار تنظیم شود",
      "maxValueTextStart": "مدل پشتیبانی می‌کند تا",
      "maxValueTextEnd": "توکن",
      "tooltipHint": "اگرچه ممکن است مدل از تعداد زیادی توکن پشتیبانی کند، اما در صورت محدود بودن منابع سیستم، عملکرد ممکن است افت کند — در افزایش این مقدار احتیاط کنید"
    },
    "contextOverflowPolicy": {
      "stopAtLimit": "توقف در حد",
      "stopAtLimitSub": "تولید را متوقف کن زمانی که حافظه مدل پر شد",
      "truncateMiddle": "حذف میانی",
      "truncateMiddleSub": "پیام‌هایی از وسط گفتگو حذف می‌شوند تا جا برای پیام‌های جدیدتر باز شود. مدل همچنان شروع گفتگو را به یاد دارد",
      "rollingWindow": "پنجره چرخشی",
      "rollingWindowSub": "مدل همیشه آخرین چند پیام را دریافت می‌کند ولی ممکن است ابتدای گفتگو را فراموش کند"
    },
    "llamaAccelerationOffloadRatio": {
      "max": "حداکثر",
      "off": "خاموش"
    },
    "llamaAccelerationSplitStrategy": {
      "evenly": "تقسیم یکنواخت",
      "favorMainGpu": "اولویت با GPU اصلی"
    },
    "speculativeDecodingDraftModel": {
      "readMore": "اطلاعات بیشتر درباره نحوه عملکرد",
      "placeholder": "یک مدل پیشنویس سازگار انتخاب کنید",
      "noCompatible": "هیچ مدل پیشنویس سازگاری برای مدل فعلی شما یافت نشد",
      "stillLoading": "در حال شناسایی مدل‌های پیشنویس سازگار...",
      "notCompatible": "مدل پیشنویس انتخاب شده (<draft/>) با مدل فعلی (<current/>) ناسازگار است.",
      "off": "خاموش",
      "loadModelToSeeOptions": "برای مشاهده گزینه‌های سازگار، ابتدا مدل را بارگذاری کنید <keyboard-shortcut />",
      "compatibleWithNumberOfModels": "پیشنهادشده برای حداقل {{dynamicValue}} مدل شما",
      "recommendedForSomeModels": "پیشنهادشده برای برخی مدل‌ها",
      "recommendedForLlamaModels": "پیشنهادشده برای مدل‌های Llama",
      "recommendedForQwenModels": "پیشنهادشده برای مدل‌های Qwen",
      "onboardingModal": {
        "introducing": "معرفی",
        "speculativeDecoding": "رمزگشایی احتمالی (Speculative Decoding)",
        "firstStepBody": "افزایش سرعت پیش‌بینی برای مدل‌های <custom-span>llama.cpp</custom-span> و <custom-span>MLX</custom-span>",
        "secondStepTitle": "افزایش سرعت با استفاده از Speculative Decoding",
        "secondStepBody": "Speculative Decoding تکنیکی است که شامل همکاری دو مدل است:\n - یک مدل اصلی بزرگ‌تر\n - یک مدل پیشنویس کوچک‌تر\n\nدر طول تولید، مدل پیشنویس به‌سرعت توکن‌هایی را پیشنهاد می‌دهد که مدل اصلی آن‌ها را تأیید می‌کند. تأیید توکن‌ها سریع‌تر از تولید آن‌ها است و همین منبع افزایش سرعت می‌باشد. **به طور کلی، هرچه اختلاف اندازه بین مدل اصلی و پیشنویس بیشتر باشد، سرعت نیز بیشتر خواهد بود**.\n\nبرای حفظ کیفیت، مدل اصلی فقط توکن‌هایی را می‌پذیرد که با خروجی خودش مطابقت داشته باشند، بنابراین کیفیت پاسخ مدل اصلی حفظ شده و سرعت نیز افزایش می‌یابد. هر دو مدل باید واژگان یکسانی داشته باشند.",
        "draftModelRecommendationsTitle": "مدل‌های پیشنهادی پیشنویس",
        "basedOnCurrentModels": "بر اساس مدل‌های فعلی شما",
        "close": "بستن",
        "next": "بعدی",
        "done": "پایان"
      },
      "speculativeDecodingLoadModelToSeeOptions": "لطفاً ابتدا یک مدل بارگذاری کنید <model-badge />",
      "errorEngineNotSupported": "برای استفاده از Speculative Decoding به نسخه حداقل {{minVersion}} از موتور {{engineName}} نیاز است. لطفاً موتور را به‌روزرسانی کرده (<key/>) و مدل را مجدداً بارگذاری کنید.",
      "errorEngineNotSupported/noKey": "برای استفاده از Speculative Decoding به نسخه حداقل {{minVersion}} از موتور {{engineName}} نیاز است. لطفاً موتور را به‌روزرسانی کرده و مدل را مجدداً بارگذاری کنید."
    },
    "llmReasoningParsing": {
      "startString/label": "رشته شروع",
      "startString/placeholder": "رشته شروع را وارد کنید...",
      "endString/label": "رشته پایان",
      "endString/placeholder": "رشته پایان را وارد کنید..."
    }
  },
  "saveConflictResolution": {
    "title": "انتخاب کنید کدام مقادیر در پیش‌تنظیم ذخیره شوند",
    "description": "مقادیر موردنظر برای نگه‌داشتن را انتخاب کنید",
    "instructions": "برای انتخاب، روی مقدار کلیک کنید",
    "userValues": "مقدار قبلی",
    "presetValues": "مقدار جدید",
    "confirm": "تأیید",
    "cancel": "لغو"
  },
  "applyConflictResolution": {
    "title": "کدام مقادیر حفظ شوند؟",
    "description": "شما تغییرات ذخیره‌نشده‌ای دارید که با پیش‌تنظیم دریافتی تداخل دارند",
    "instructions": "برای حفظ مقدار، روی آن کلیک کنید",
    "userValues": "مقدار فعلی",
    "presetValues": "مقدار پیش‌تنظیم دریافتی",
    "confirm": "تأیید",
    "cancel": "لغو"
  },
  "empty": "<خالی>",
  "noModelSelected": "هیچ مدلی انتخاب نشده است",
  "apiIdentifier.label": "شناسه API",
  "apiIdentifier.hint": "در صورت تمایل، یک شناسه برای این مدل وارد کنید. این شناسه در درخواست‌های API استفاده می‌شود. در صورت خالی گذاشتن، شناسه پیش‌فرض استفاده خواهد شد.",
  "idleTTL.label": "خروج خودکار در صورت بی‌کاری (TTL)",
  "idleTTL.hint": "اگر تنظیم شود، مدل پس از مدت‌زمان مشخص‌شده‌ی بی‌کاری، به‌صورت خودکار از حافظه خارج خواهد شد.",
  "idleTTL.mins": "دقیقه",

  "presets": {
    "title": "پیش‌تنظیم",
    "commitChanges": "ثبت تغییرات",
    "commitChanges/description": "تغییرات خود را در پیش‌تنظیم ثبت کنید.",
    "commitChanges.manual": "فیلدهای جدید شناسایی شدند. می‌توانید انتخاب کنید کدام تغییرات در پیش‌تنظیم قرار گیرند.",
    "commitChanges.manual.hold.0": "نگه‌دارید",
    "commitChanges.manual.hold.1": "برای انتخاب تغییراتی که باید در پیش‌تنظیم ثبت شوند.",
    "commitChanges.saveAll.hold.0": "نگه‌دارید",
    "commitChanges.saveAll.hold.1": "برای ذخیره تمام تغییرات.",
    "commitChanges.saveInPreset.hold.0": "نگه‌دارید",
    "commitChanges.saveInPreset.hold.1": "برای ذخیره فقط تغییرات مربوط به فیلدهای موجود در پیش‌تنظیم.",
    "commitChanges/error": "ثبت تغییرات در پیش‌تنظیم با خطا مواجه شد.",
    "commitChanges.manual/description": "تغییراتی را که باید در پیش‌تنظیم قرار گیرند انتخاب کنید.",
    "saveAs": "ذخیره به عنوان پیش‌تنظیم جدید...",
    "presetNamePlaceholder": "یک نام برای پیش‌تنظیم وارد کنید...",
    "cannotCommitChangesLegacy": "این یک پیش‌تنظیم قدیمی است و نمی‌توان آن را تغییر داد. می‌توانید با استفاده از \"ذخیره به عنوان جدید...\" یک نسخه جدید ایجاد کنید.",
    "cannotCommitChangesNoChanges": "تغییری برای ثبت وجود ندارد.",
    "emptyNoUnsaved": "یک پیش‌تنظیم انتخاب کنید...",
    "emptyWithUnsaved": "پیش‌تنظیم ذخیره‌نشده",
    "saveEmptyWithUnsaved": "ذخیره پیش‌تنظیم با نام...",
    "saveConfirm": "ذخیره",
    "saveCancel": "لغو",
    "saving": "در حال ذخیره...",
    "save/error": "ذخیره پیش‌تنظیم با خطا مواجه شد.",
    "deselect": "لغو انتخاب پیش‌تنظیم",
    "deselect/error": "لغو انتخاب پیش‌تنظیم با خطا مواجه شد.",
    "select/error": "انتخاب پیش‌تنظیم با خطا مواجه شد.",
    "delete/error": "حذف پیش‌تنظیم با خطا مواجه شد.",
    "discardChanges": "لغو تغییرات ذخیره‌نشده",
    "discardChanges/info": "همه تغییرات ذخیره‌نشده را لغو کرده و پیش‌تنظیم را به حالت اولیه بازگردانید",
    "newEmptyPreset": "+ پیش‌تنظیم جدید",
    "importPreset": "وارد کردن",
    "contextMenuSelect": "اعمال پیش‌تنظیم",
    "contextMenuDelete": "حذف...",
    "contextMenuShare": "انتشار...",
    "contextMenuOpenInHub": "مشاهده در هاب",
    "contextMenuPushChanges": "ارسال تغییرات به هاب",
    "contextMenuPushingChanges": "در حال ارسال...",
    "contextMenuPushedChanges": "تغییرات ارسال شدند",
    "contextMenuExport": "خروجی گرفتن",
    "contextMenuRevealInExplorer": "نمایش در فایل اکسپلورر",
    "contextMenuRevealInFinder": "نمایش در Finder",
    "share": {
      "title": "انتشار پیش‌تنظیم",
      "action": "پیش‌تنظیم خود را برای دانلود، پسندیدن و انشعاب توسط دیگران منتشر کنید",
      "presetOwnerLabel": "مالک",
      "uploadAs": "پیش‌تنظیم شما با نام {{name}} منتشر خواهد شد",
      "presetNameLabel": "نام پیش‌تنظیم",
      "descriptionLabel": "توضیح (اختیاری)",
      "loading": "در حال انتشار...",
      "success": "پیش‌تنظیم با موفقیت منتشر شد",
      "presetIsLive": "<preset-name /> اکنون در هاب فعال است!",
      "close": "بستن",
      "confirmViewOnWeb": "مشاهده در وب",
      "confirmCopy": "کپی لینک",
      "confirmCopied": "کپی شد!",
      "pushedToHub": "پیش‌تنظیم شما در هاب منتشر شد",
      "descriptionPlaceholder": "توضیحی وارد کنید...",
      "willBePublic": "انتشار پیش‌تنظیم باعث عمومی شدن آن خواهد شد",
      "publicSubtitle": "پیش‌تنظیم شما <custom-bold>عمومی</custom-bold> است. دیگران می‌توانند آن را در lmstudio.ai دانلود و انشعاب دهند.",
      "confirmShareButton": "انتشار",
      "error": "انتشار پیش‌تنظیم با خطا مواجه شد",
      "createFreeAccount": "برای انتشار پیش‌تنظیم، یک حساب رایگان در هاب ایجاد کنید"
    },
    "update": {
      "title": "ارسال تغییرات به هاب",
      "title/success": "پیش‌تنظیم با موفقیت به‌روزرسانی شد",
      "subtitle": "تغییراتی در <custom-preset-name /> ایجاد کنید و آن را به هاب ارسال نمایید",
      "descriptionLabel": "توضیح",
      "descriptionPlaceholder": "توضیحی وارد کنید...",
      "loading": "در حال ارسال...",
      "cancel": "لغو",
      "createFreeAccount": "برای انتشار پیش‌تنظیم، یک حساب رایگان در هاب ایجاد کنید",
      "error": "ارسال تغییرات با خطا مواجه شد",
      "confirmUpdateButton": "ارسال"
    },
    "import": {
      "title": "وارد کردن پیش‌تنظیم از فایل",
      "dragPrompt": "فایل‌های JSON پیش‌تنظیم را بکشید یا <custom-link>از رایانه انتخاب کنید</custom-link>",
      "remove": "حذف",
      "cancel": "لغو",
      "importPreset_zero": "وارد کردن پیش‌تنظیم",
      "importPreset_one": "وارد کردن پیش‌تنظیم",
      "importPreset_other": "وارد کردن {{count}} پیش‌تنظیم",
      "selectDialog": {
        "title": "انتخاب فایل پیش‌تنظیم (.json)",
        "button": "وارد کردن"
      },
      "error": "وارد کردن پیش‌تنظیم با خطا مواجه شد",
      "resultsModal": {
        "titleSuccessSection_one": "۱ پیش‌تنظیم با موفقیت وارد شد",
        "titleSuccessSection_other": "{{count}} پیش‌تنظیم با موفقیت وارد شد",
        "titleFailSection_zero": "",
        "titleFailSection_one": "({{count}} شکست خورده)",
        "titleFailSection_other": "({{count}} شکست خورده)",
        "titleAllFailed": "وارد کردن پیش‌تنظیم‌ها با شکست مواجه شد",
        "importMore": "وارد کردن بیشتر",
        "close": "تمام",
        "successBadge": "موفق",
        "alreadyExistsBadge": "پیش‌تنظیم از قبل وجود دارد",
        "errorBadge": "خطا",
        "invalidFileBadge": "فایل نامعتبر",
        "otherErrorBadge": "وارد کردن پیش‌تنظیم با شکست مواجه شد",
        "errorViewDetailsButton": "مشاهده جزئیات",
        "seeError": "مشاهده خطا",
        "noName": "بدون نام پیش‌تنظیم",
        "useInChat": "استفاده در چت"
      },
      "importFromUrl": {
        "button": "وارد کردن از لینک...",
        "title": "وارد کردن از URL",
        "back": "وارد کردن از فایل...",
        "action": "آدرس LM Studio Hub مربوط به پیش‌تنظیم موردنظر را در زیر وارد کنید",
        "invalidUrl": "آدرس نامعتبر. لطفاً مطمئن شوید که آدرس معتبر LM Studio Hub را وارد کرده‌اید.",
        "tip": "می‌توانید با دکمه {{buttonName}} در LM Studio Hub، پیش‌تنظیم را مستقیماً نصب کنید",
        "confirm": "وارد کردن",
        "cancel": "لغو",
        "loading": "در حال وارد کردن...",
        "error": "دانلود پیش‌تنظیم با خطا مواجه شد."
      }
    },
    "download": {
      "title": "دریافت <preset-name /> از LM Studio Hub",
      "subtitle": "<custom-name /> را به پیش‌تنظیم‌های خود اضافه کنید. با این کار می‌توانید از این پیش‌تنظیم در برنامه استفاده کنید",
      "button": "دریافت",
      "button/loading": "در حال دریافت...",
      "cancel": "لغو",
      "error": "دریافت پیش‌تنظیم با خطا مواجه شد."
    },
    "inclusiveness": {
      "speculativeDecoding": "در پیش‌تنظیم قرار بگیرد"
    }
  },

  "flashAttentionWarning": "ویژگی Flash Attention یک قابلیت آزمایشی است که ممکن است در برخی مدل‌ها مشکلاتی ایجاد کند. اگر با مشکلی مواجه شدید، آن را غیرفعال کنید.",
  "llamaKvCacheQuantizationWarning": "کوانتیزه‌سازی کش KV یک ویژگی آزمایشی است که ممکن است در برخی مدل‌ها مشکل‌ساز شود. برای کوانتیزه‌سازی کش V، Flash Attention باید فعال باشد. اگر مشکلی پیش آمد، به مقدار پیش‌فرض \"F16\" بازگردید.",

  "seedUncheckedHint": "بذر تصادفی",
  "ropeFrequencyBaseUncheckedHint": "خودکار",
  "ropeFrequencyScaleUncheckedHint": "خودکار",

  "hardware": {
    "advancedGpuSettings": "تنظیمات پیشرفته GPU",
    "advancedGpuSettings.info": "اگر مطمئن نیستید، این مقادیر را در حالت پیش‌فرض رها کنید",
    "advancedGpuSettings.reset": "بازنشانی به پیش‌فرض",
    "environmentVariables": {
      "title": "متغیرهای محیطی",
      "description": "متغیرهای محیطی فعال در طول اجرای مدل.",
      "key.placeholder": "انتخاب متغیر...",
      "value.placeholder": "مقدار"
    },
    "mainGpu": {
      "title": "GPU اصلی",
      "description": "GPU‌ای که برای پردازش مدل اولویت دارد.",
      "placeholder": "GPU اصلی را انتخاب کنید..."
    },
    "splitStrategy": {
      "title": "استراتژی تقسیم",
      "description": "نحوه تقسیم پردازش مدل بین GPUها.",
      "placeholder": "استراتژی تقسیم را انتخاب کنید..."
    }
  }
}
