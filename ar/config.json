{
  "noInstanceSelected": "لم يتم تحديد نموذج",
  "resetToDefault": "إعادة تعيين",
  "showAdvancedSettings": "عرض الإعدادات المتقدمة",
  "showAll": "الكل",
  "basicSettings": "أساسي",
  "configSubtitle": "تحميل أو حفظ الإعدادات المسبقة وتجربة تجاوزات معلمات النموذج",
  "inferenceParameters/title": "معلمات التنبؤ",
  "inferenceParameters/info": "تجربة المعلمات التي تؤثر على التنبؤ.",
  "generalParameters/title": "عام",
  "samplingParameters/title": "أخذ العينات",
  "basicTab": "أساسي",
  "advancedTab": "متقدم",
  "advancedTab/title": "🧪 التكوين المتقدم",
  "advancedTab/expandAll": "توسيع الكل",
  "advancedTab/overridesTitle": "تجاوزات التكوين",
  "advancedTab/noConfigsText": "ليس لديك تغييرات غير محفوظة - قم بتعديل القيم أعلاه لرؤية التجاوزات هنا.",
  "loadInstanceFirst": "قم بتحميل نموذج لعرض المعلمات القابلة للتكوين",
  "noListedConfigs": "لا توجد معلمات قابلة للتكوين",
  "generationParameters/info": "تجربة المعلمات الأساسية التي تؤثر على توليد النص.",
  "loadParameters/title": "معلمات التحميل",
  "loadParameters/description": "إعدادات للتحكم في طريقة تهيئة النموذج وتحميله في الذاكرة.",
  "loadParameters/reload": "إعادة التحميل لتطبيق التغييرات",
  "loadParameters/reload/error": "فشل في إعادة تحميل النموذج",
  "discardChanges": "تجاهل التغييرات",
  "loadModelToSeeOptions": "قم بتحميل نموذج لرؤية الخيارات",
  "schematicsError.title": "يحتوي مخطط التكوين على أخطاء في الحقول التالية:",
  "manifestSections": {
    "structuredOutput/title": "مخرجات منظمة",
    "speculativeDecoding/title": "فك الترميز التخميني",
    "sampling/title": "أخذ العينات",
    "settings/title": "الإعدادات",
    "toolUse/title": "استخدام الأدوات",
    "promptTemplate/title": "قالب الموجه"
  },

  "llm.prediction.systemPrompt/title": "موجه النظام",
  "llm.prediction.systemPrompt/description": "استخدم هذا الحقل لتوفير تعليمات خلفية للنموذج، مثل مجموعة من القواعد أو القيود أو المتطلبات العامة.",
  "llm.prediction.systemPrompt/subTitle": "إرشادات للذكاء الاصطناعي",
  "llm.prediction.temperature/title": "درجة الحرارة",
  "llm.prediction.temperature/subTitle": "مقدار العشوائية المراد إدخالها. 0 سيعطي نفس النتيجة في كل مرة، بينما القيم الأعلى ستزيد من الإبداع والتباين",
  "llm.prediction.temperature/info": "من وثائق مساعدة llama.cpp: \"القيمة الافتراضية هي <{{dynamicValue}}>، والتي توفر توازناً بين العشوائية والحتمية. في الحالة القصوى، درجة حرارة 0 ستختار دائماً الرمز التالي الأكثر احتمالاً، مما يؤدي إلى مخرجات متطابقة في كل تشغيل\"",
  "llm.prediction.llama.sampling/title": "أخذ العينات",
  "llm.prediction.topKSampling/title": "أخذ عينات Top K",
  "llm.prediction.topKSampling/subTitle": "يقيد الرمز التالي إلى واحد من أعلى k رموز احتمالاً. يعمل بشكل مشابه لدرجة الحرارة",
  "llm.prediction.topKSampling/info": "من وثائق مساعدة llama.cpp:\n\nأخذ عينات Top-k هو طريقة لتوليد النص تختار الرمز التالي فقط من أعلى k رموز محتملة يتنبأ بها النموذج.\n\nيساعد في تقليل مخاطر توليد رموز منخفضة الاحتمال أو غير منطقية، ولكنه قد يحد أيضاً من تنوع المخرجات.\n\nقيمة أعلى لـ top-k (مثل 100) ستأخذ في الاعتبار المزيد من الرموز وتؤدي إلى نص أكثر تنوعاً، بينما قيمة أقل (مثل 10) ستركز على الرموز الأكثر احتمالاً وتولد نصاً أكثر تحفظاً.\n\n• القيمة الافتراضية هي <{{dynamicValue}}>",
  "llm.prediction.llama.cpuThreads/title": "مسارات المعالج",
  "llm.prediction.llama.cpuThreads/subTitle": "عدد مسارات المعالج المراد استخدامها أثناء الاستدلال",
  "llm.prediction.llama.cpuThreads/info": "عدد المسارات المراد استخدامها أثناء الحساب. زيادة عدد المسارات لا تتناسب دائماً مع تحسين الأداء. القيمة الافتراضية هي <{{dynamicValue}}>.",
  "llm.prediction.maxPredictedTokens/title": "تحديد طول الرد",
  "llm.prediction.maxPredictedTokens/subTitle": "تحديد طول رد الذكاء الاصطناعي اختيارياً",
  "llm.prediction.maxPredictedTokens/info": "التحكم في الحد الأقصى لطول رد روبوت المحادثة. قم بالتشغيل لتعيين حد لأقصى طول للرد، أو قم بالإيقاف للسماح لروبوت المحادثة بتحديد متى يتوقف.",
  "llm.prediction.maxPredictedTokens/inputLabel": "الحد الأقصى لطول الرد (الرموز)",
  "llm.prediction.maxPredictedTokens/wordEstimate": "حوالي {{maxWords}} كلمة",
  "llm.prediction.repeatPenalty/title": "عقوبة التكرار",
  "llm.prediction.repeatPenalty/subTitle": "مقدار تثبيط تكرار نفس الرمز",
  "llm.prediction.repeatPenalty/info": "من وثائق مساعدة llama.cpp: \"يساعد في منع النموذج من توليد نص متكرر أو رتيب.\n\nقيمة أعلى (مثل 1.5) ستعاقب التكرارات بشكل أقوى، بينما قيمة أقل (مثل 0.9) ستكون أكثر تساهلاً.\" • القيمة الافتراضية هي <{{dynamicValue}}>",
  "llm.prediction.minPSampling/title": "أخذ عينات Min P",
  "llm.prediction.minPSampling/subTitle": "الحد الأدنى للاحتمال الأساسي لاختيار رمز للمخرجات",
  "llm.prediction.minPSampling/info": "من وثائق مساعدة llama.cpp:\n\nالحد الأدنى لاحتمال اختيار رمز، بالنسبة لاحتمال الرمز الأكثر احتمالاً. يجب أن يكون في [0, 1].\n\n• القيمة الافتراضية هي <{{dynamicValue}}>",
  "llm.prediction.topPSampling/title": "أخذ عينات Top P",
  "llm.prediction.topPSampling/subTitle": "الحد الأدنى للاحتمال التراكمي للرموز التالية المحتملة. يعمل بشكل مشابه لدرجة الحرارة",
  "llm.prediction.topPSampling/info": "من وثائق مساعدة llama.cpp:\n\nأخذ عينات Top-p، المعروف أيضاً باسم أخذ عينات النواة، هو طريقة أخرى لتوليد النص تختار الرمز التالي من مجموعة فرعية من الرموز التي لديها معاً احتمال تراكمي لا يقل عن p.\n\nتوفر هذه الطريقة توازناً بين التنوع والجودة من خلال النظر في كل من احتمالات الرموز وعدد الرموز المراد أخذ عينات منها.\n\nقيمة أعلى لـ top-p (مثل 0.95) ستؤدي إلى نص أكثر تنوعاً، بينما قيمة أقل (مثل 0.5) ستولد نصاً أكثر تركيزاً وتحفظاً. يجب أن تكون في (0, 1].\n\n• القيمة الافتراضية هي <{{dynamicValue}}>",
  "llm.prediction.stopStrings/title": "سلاسل التوقف",
  "llm.prediction.stopStrings/subTitle": "السلاسل التي يجب أن توقف النموذج عن توليد المزيد من الرموز",
  "llm.prediction.stopStrings/info": "سلاسل محددة عند مواجهتها ستوقف النموذج عن توليد المزيد من الرموز",
  "llm.prediction.stopStrings/placeholder": "أدخل سلسلة واضغط ⏎",
  "llm.prediction.contextOverflowPolicy/title": "تجاوز السياق",
  "llm.prediction.contextOverflowPolicy/subTitle": "كيف يجب أن يتصرف النموذج عندما تصبح المحادثة كبيرة جداً بحيث لا يمكن معالجتها",
  "llm.prediction.contextOverflowPolicy/info": "قرر ما يجب فعله عندما تتجاوز المحادثة حجم ذاكرة عمل النموذج ('السياق')",
  "llm.prediction.llama.frequencyPenalty/title": "عقوبة التكرار",
  "llm.prediction.llama.presencePenalty/title": "عقوبة الوجود",
  "llm.prediction.llama.tailFreeSampling/title": "أخذ عينات خالٍ من الذيل",
  "llm.prediction.llama.locallyTypicalSampling/title": "أخذ عينات نموذجي محلياً",
  "llm.prediction.llama.xtcProbability/title": "احتمال أخذ عينات XTC",
  "llm.prediction.llama.xtcProbability/subTitle": "سيتم تنشيط أخذ عينات XTC (استبعاد الخيارات الأعلى) بهذا الاحتمال لكل رمز تم توليده. يمكن أن يعزز أخذ عينات XTC الإبداع ويقلل من الكليشيهات",
  "llm.prediction.llama.xtcProbability/info": "سيتم تنشيط أخذ عينات XTC (استبعاد الخيارات الأعلى) بهذا الاحتمال، لكل رمز تم توليده. عادةً ما يعزز أخذ عينات XTC الإبداع ويقلل من الكليشيهات",
  "llm.prediction.llama.xtcThreshold/title": "عتبة أخذ عينات XTC",
  "llm.prediction.llama.xtcThreshold/subTitle": "عتبة XTC (استبعاد الخيارات الأعلى). باحتمال `xtc-probability`، ابحث عن الرموز ذات الاحتمالات بين `xtc-threshold` و 0.5، وقم بإزالة جميع هذه الرموز باستثناء الأقل احتمالاً",
  "llm.prediction.llama.xtcThreshold/info": "عتبة XTC (استبعاد الخيارات الأعلى). باحتمال `xtc-probability`، ابحث عن الرموز ذات الاحتمالات بين `xtc-threshold` و 0.5، وقم بإزالة جميع هذه الرموز باستثناء الأقل احتمالاً",
  "llm.prediction.mlx.topKSampling/title": "Top K Sampling",
  "llm.prediction.mlx.topKSampling/subTitle": "Limits the next token to one of the top-k most probable tokens. Acts similarly to temperature",
  "llm.prediction.mlx.topKSampling/info": "Limits the next token to one of the top-k most probable tokens. Acts similarly to temperature",
  "llm.prediction.onnx.topKSampling/title": "Top K Sampling",
  "llm.prediction.onnx.topKSampling/subTitle": "Limits the next token to one of the top-k most probable tokens. Acts similarly to temperature",
  "llm.prediction.onnx.topKSampling/info": "From ONNX documentation:\n\nNumber of highest probability vocabulary tokens to keep for top-k-filtering\n\n• This filter is turned off by default",
  "llm.prediction.onnx.repeatPenalty/title": "Repeat Penalty",
  "llm.prediction.onnx.repeatPenalty/subTitle": "How much to discourage repeating the same token",
  "llm.prediction.onnx.repeatPenalty/info": "A higher value discourages the model from repeating itself",
  "llm.prediction.onnx.topPSampling/title": "Top P Sampling",
  "llm.prediction.onnx.topPSampling/subTitle": "Minimum cumulative probability for the possible next tokens. Acts similarly to temperature",
  "llm.prediction.onnx.topPSampling/info": "From ONNX documentation:\n\nOnly the most probable tokens with probabilities that add up to TopP or higher are kept for generation\n\n• This filter is turned off by default",
  "llm.prediction.seed/title": "Seed",
  "llm.prediction.structured/title": "Structured Output",
  "llm.prediction.structured/info": "Structured Output",
  "llm.prediction.structured/description": "Advanced: you can provide a [JSON Schema](https://json-schema.org/learn/miscellaneous-examples) to enforce a particular output format from the model. Read the [documentation](https://lmstudio.ai/docs/advanced/structured-output) to learn more",
  "llm.prediction.tools/title": "Tool Use",
  "llm.prediction.tools/description": "Advanced: you can provide a JSON-compliant list of tools for the model to request calls to. Read the [documentation](https://lmstudio.ai/docs/advanced/tool-use) to learn more",
  "llm.prediction.tools/serverPageDescriptionAddon": "Pass this through the request body as `tools` when using the server API",
  "llm.prediction.promptTemplate/title": "Prompt Template",
  "llm.prediction.promptTemplate/subTitle": "التنسيق الذي يتم إرسال الرسائل في المحادثة به إلى النموذج. قد يؤدي تغيير هذا إلى سلوك غير متوقع - تأكد من أنك تعرف ما تفعله!",
  "llm.prediction.speculativeDecoding.numDraftTokensExact/title": "عدد الرموز المسودة المراد توليدها",
  "llm.prediction.speculativeDecoding.numDraftTokensExact/subTitle": "عدد الرموز المراد توليدها باستخدام نموذج المسودة لكل رمز من النموذج الرئيسي. ابحث عن النقطة المثالية بين الحساب والمكافأة",
  "llm.prediction.speculativeDecoding.minContinueDraftingProbability/title": "عتبة احتمال المسودة",
  "llm.prediction.speculativeDecoding.minContinueDraftingProbability/subTitle": "استمر في المسودة حتى يقل احتمال الرمز عن هذه العتبة. القيم الأعلى تعني عادةً مخاطر أقل ومكافأة أقل",
  "llm.prediction.speculativeDecoding.minDraftLengthToConsider/title": "الحد الأدنى لحجم المسودة",
  "llm.prediction.speculativeDecoding.minDraftLengthToConsider/subTitle": "سيتم تجاهل المسودات الأصغر من هذا من قبل النموذج الرئيسي. القيم الأعلى تعني عادةً مخاطر أقل ومكافأة أقل",
  "llm.prediction.speculativeDecoding.maxTokensToDraft/title": "الحد الأقصى لحجم المسودة",
  "llm.prediction.speculativeDecoding.maxTokensToDraft/subTitle": "الحد الأقصى لعدد الرموز المسموح بها في المسودة. السقف إذا كانت جميع احتمالات الرموز > العتبة. القيم الأقل تعني عادةً مخاطر أقل ومكافأة أقل",
  "llm.prediction.speculativeDecoding.draftModel/title": "نموذج المسودة",
  "llm.prediction.reasoning.parsing/title": "تحليل قسم المنطق",
  "llm.prediction.reasoning.parsing/subTitle": "كيفية تحليل أقسام المنطق في مخرجات النموذج",

  "llm.load.contextLength/title": "طول السياق",
  "llm.load.contextLength/subTitle": "الحد الأقصى لعدد الرموز التي يمكن للنموذج الانتباه إليها في موجه واحد. راجع خيارات تجاوز المحادثة تحت \"معلمات الاستدلال\" لمزيد من الطرق لإدارة هذا",
  "llm.load.contextLength/info": "يحدد الحد الأقصى لعدد الرموز التي يمكن للنموذج أخذها في الاعتبار في وقت واحد، مما يؤثر على مقدار السياق الذي يحتفظ به أثناء المعالجة",
  "llm.load.contextLength/warning": "تعيين قيمة عالية لطول السياق يمكن أن يؤثر بشكل كبير على استخدام الذاكرة",
  "llm.load.seed/title": "البذرة",
  "llm.load.seed/subTitle": "بذرة مولد الأرقام العشوائية المستخدم في توليد النص. -1 عشوائي",
  "llm.load.seed/info": "بذرة عشوائية: تعيين بذرة لتوليد الأرقام العشوائية لضمان نتائج قابلة للتكرار",

  "llm.load.llama.evalBatchSize/title": "حجم دفعة التقييم",
  "llm.load.llama.evalBatchSize/subTitle": "عدد رموز الإدخال المراد معالجتها في وقت واحد. زيادة هذا يزيد الأداء على حساب استخدام الذاكرة",
  "llm.load.llama.evalBatchSize/info": "تعيين عدد الأمثلة التي تتم معالجتها معاً في دفعة واحدة أثناء التقييم، مما يؤثر على السرعة واستخدام الذاكرة",
  "llm.load.llama.ropeFrequencyBase/title": "قاعدة تردد RoPE",
  "llm.load.llama.ropeFrequencyBase/subTitle": "تردد أساسي مخصص للتضمينات الموضعية الدوارة (RoPE). قد تمكن زيادة هذا من أداء أفضل في أطوال السياق العالية",
  "llm.load.llama.ropeFrequencyBase/info": "[متقدم] يضبط التردد الأساسي للتشفير الموضعي الدوار، مما يؤثر على كيفية تضمين المعلومات الموضعية",
  "llm.load.llama.ropeFrequencyScale/title": "مقياس تردد RoPE",
  "llm.load.llama.ropeFrequencyScale/subTitle": "يتم قياس طول السياق بهذا العامل لتمديد السياق الفعال باستخدام RoPE",
  "llm.load.llama.ropeFrequencyScale/info": "[متقدم] يعدل قياس التردد للتشفير الموضعي الدوار للتحكم في دقة التشفير الموضعي",
  "llm.load.llama.acceleration.offloadRatio/title": "نقل إلى GPU",
  "llm.load.llama.acceleration.offloadRatio/subTitle": "عدد طبقات النموذج المنفصلة المراد حسابها على GPU لتسريع GPU",
  "llm.load.llama.acceleration.offloadRatio/info": "تعيين عدد الطبقات المراد نقلها إلى GPU.",
  "llm.load.llama.flashAttention/title": "انتباه فلاش",
  "llm.load.llama.flashAttention/subTitle": "يقلل استخدام الذاكرة ووقت التوليد في بعض النماذج",
  "llm.load.llama.flashAttention/info": "يسرع آليات الانتباه لمعالجة أسرع وأكثر كفاءة",
  "llm.load.numExperts/title": "عدد الخبراء",
  "llm.load.numExperts/subTitle": "عدد الخبراء المراد استخدامهم في النموذج",
  "llm.load.numExperts/info": "عدد الخبراء المراد استخدامهم في النموذج",
  "llm.load.llama.keepModelInMemory/title": "إبقاء النموذج في الذاكرة",
  "llm.load.llama.keepModelInMemory/subTitle": "حجز ذاكرة النظام للنموذج، حتى عند نقله إلى GPU. يحسن الأداء ولكنه يتطلب المزيد من ذاكرة الوصول العشوائي للنظام",
  "llm.load.llama.keepModelInMemory/info": "يمنع النموذج من التبديل إلى القرص، مما يضمن وصولاً أسرع على حساب استخدام ذاكرة وصول عشوائي أعلى",
  "llm.load.llama.useFp16ForKVCache/title": "استخدام FP16 لـ KV Cache",
  "llm.load.llama.useFp16ForKVCache/info": "يقلل استخدام الذاكرة عن طريق تخزين ذاكرة التخزين المؤقت بنصف دقة (FP16)",
  "llm.load.llama.tryMmap/title": "تجربة mmap()",
  "llm.load.llama.tryMmap/subTitle": "يحسن وقت تحميل النموذج. قد يؤدي تعطيل هذا إلى تحسين الأداء عندما يكون النموذج أكبر من ذاكرة الوصول العشوائي المتاحة للنظام",
  "llm.load.llama.tryMmap/info": "تحميل ملفات النموذج مباشرة من القرص إلى الذاكرة",
  "llm.load.llama.cpuThreadPoolSize/title": "حجم مجموعة مسارات المعالج",
  "llm.load.llama.cpuThreadPoolSize/subTitle": "عدد مسارات المعالج المراد تخصيصها لمجموعة المسارات المستخدمة لحساب النموذج",
  "llm.load.llama.cpuThreadPoolSize/info": "عدد مسارات المعالج المراد تخصيصها لمجموعة المسارات المستخدمة لحساب النموذج. زيادة عدد المسارات لا تتناسب دائماً مع تحسين الأداء. القيمة الافتراضية هي <{{dynamicValue}}>.",
  "llm.load.llama.kCacheQuantizationType/title": "نوع تكميم K Cache",
  "llm.load.llama.kCacheQuantizationType/subTitle": "القيم الأقل تقلل استخدام الذاكرة ولكن قد تقلل الجودة. يختلف التأثير بشكل كبير بين النماذج.",
  "llm.load.llama.vCacheQuantizationType/title": "نوع تكميم V Cache",
  "llm.load.llama.vCacheQuantizationType/subTitle": "القيم الأقل تقلل استخدام الذاكرة ولكن قد تقلل الجودة. يختلف التأثير بشكل كبير بين النماذج.",
  "llm.load.llama.vCacheQuantizationType/turnedOnWarning": "⚠️ يجب عليك تعطيل هذه القيمة إذا لم يتم تمكين Flash Attention",
  "llm.load.llama.vCacheQuantizationType/disabledMessage": "يمكن تشغيله فقط عندما يكون Flash Attention ممكناً",
  "llm.load.llama.vCacheQuantizationType/invalidF32MetalState": "⚠️ يجب عليك تعطيل flash attention عند استخدام F32",
  "llm.load.mlx.kvCacheBits/title": "تكميم KV Cache",
  "llm.load.mlx.kvCacheBits/subTitle": "عدد البتات التي يجب تكميم KV cache إليها",
  "llm.load.mlx.kvCacheBits/info": "عدد البتات التي يجب تكميم KV cache إليها",
  "llm.load.mlx.kvCacheBits/turnedOnWarning": "يتم تجاهل إعداد طول السياق عند استخدام تكميم KV Cache",
  "llm.load.mlx.kvCacheGroupSize/title": "تكميم KV Cache: حجم المجموعة",
  "llm.load.mlx.kvCacheGroupSize/subTitle": "حجم المجموعة أثناء عملية التكميم لـ KV cache. حجم المجموعة الأعلى يقلل استخدام الذاكرة ولكن قد يقلل الجودة",
  "llm.load.mlx.kvCacheGroupSize/info": "عدد البتات التي يجب تكميم KV cache إليها",
  "llm.load.mlx.kvCacheQuantizationStart/title": "تكميم KV Cache: بدء التكميم عندما يتجاوز السياق هذا الطول",
  "llm.load.mlx.kvCacheQuantizationStart/subTitle": "عتبة طول السياق لبدء تكميم KV cache",
  "llm.load.mlx.kvCacheQuantizationStart/info": "عتبة طول السياق لبدء تكميم KV cache",
  "llm.load.mlx.kvCacheQuantization/title": "تكميم KV Cache",
  "llm.load.mlx.kvCacheQuantization/subTitle": "تكميم KV cache للنموذج. قد يؤدي هذا إلى توليد أسرع وبصمة ذاكرة أقل،\nعلى حساب جودة مخرجات النموذج.",
  "llm.load.mlx.kvCacheQuantization/bits/title": "بتات تكميم KV cache",
  "llm.load.mlx.kvCacheQuantization/bits/tooltip": "عدد البتات المراد تكميم KV cache إليها",
  "llm.load.mlx.kvCacheQuantization/bits/bits": "بتات",
  "llm.load.mlx.kvCacheQuantization/groupSize/title": "استراتيجية حجم المجموعة",
  "llm.load.mlx.kvCacheQuantization/groupSize/accuracy": "دقة",
  "llm.load.mlx.kvCacheQuantization/groupSize/balanced": "متوازن",
  "llm.load.mlx.kvCacheQuantization/groupSize/speedy": "سريع",
  "llm.load.mlx.kvCacheQuantization/groupSize/tooltip": "متقدم: تكوين 'حجم مجموعة matmul' المكمم\n\n• دقة = حجم مجموعة 32\n• متوازن = حجم مجموعة 64\n• سريع = حجم مجموعة 128\n",
  "llm.load.mlx.kvCacheQuantization/quantizedStart/title": "بدء التكميم عندما يصل السياق إلى هذا الطول",
  "llm.load.mlx.kvCacheQuantization/quantizedStart/tooltip": "عندما يصل السياق إلى هذا العدد من الرموز،\nابدأ في تكميم KV cache",

  "embedding.load.contextLength/title": "طول السياق",
  "embedding.load.contextLength/subTitle": "الحد الأقصى لعدد الرموز التي يمكن للنموذج الانتباه إليها في موجه واحد. راجع خيارات تجاوز المحادثة تحت \"معلمات الاستدلال\" لمزيد من الطرق لإدارة هذا",
  "embedding.load.contextLength/info": "يحدد الحد الأقصى لعدد الرموز التي يمكن للنموذج أخذها في الاعتبار في وقت واحد، مما يؤثر على مقدار السياق الذي يحتفظ به أثناء المعالجة",
  "embedding.load.llama.ropeFrequencyBase/title": "قاعدة تردد RoPE",
  "embedding.load.llama.ropeFrequencyBase/subTitle": "تردد أساسي مخصص للتضمينات الموضعية الدوارة (RoPE). قد تمكن زيادة هذا من أداء أفضل في أطوال السياق العالية",
  "embedding.load.llama.ropeFrequencyBase/info": "[متقدم] يضبط التردد الأساسي للتشفير الموضعي الدوار، مما يؤثر على كيفية تضمين المعلومات الموضعية",
  "embedding.load.llama.evalBatchSize/title": "حجم دفعة التقييم",
  "embedding.load.llama.evalBatchSize/subTitle": "عدد رموز الإدخال المراد معالجتها في وقت واحد. زيادة هذا يزيد الأداء على حساب استخدام الذاكرة",
  "embedding.load.llama.evalBatchSize/info": "تعيين عدد الرموز التي تتم معالجتها معاً في دفعة واحدة أثناء التقييم",
  "embedding.load.llama.ropeFrequencyScale/title": "مقياس تردد RoPE",
  "embedding.load.llama.ropeFrequencyScale/subTitle": "يتم قياس طول السياق بهذا العامل لتمديد السياق الفعال باستخدام RoPE",
  "embedding.load.llama.ropeFrequencyScale/info": "[متقدم] يعدل قياس التردد للتشفير الموضعي الدوار للتحكم في دقة التشفير الموضعي",
  "embedding.load.llama.acceleration.offloadRatio/title": "نقل إلى GPU",
  "embedding.load.llama.acceleration.offloadRatio/subTitle": "عدد طبقات النموذج المنفصلة المراد حسابها على GPU لتسريع GPU",
  "embedding.load.llama.acceleration.offloadRatio/info": "تعيين عدد الطبقات المراد نقلها إلى GPU.",
  "embedding.load.llama.keepModelInMemory/title": "إبقاء النموذج في الذاكرة",
  "embedding.load.llama.keepModelInMemory/subTitle": "حجز ذاكرة النظام للنموذج، حتى عند نقله إلى GPU. يحسن الأداء ولكنه يتطلب المزيد من ذاكرة الوصول العشوائي للنظام",
  "embedding.load.llama.keepModelInMemory/info": "يمنع النموذج من التبديل إلى القرص، مما يضمن وصولاً أسرع على حساب استخدام ذاكرة وصول عشوائي أعلى",
  "embedding.load.llama.tryMmap/title": "تجربة mmap()",
  "embedding.load.llama.tryMmap/subTitle": "يحسن وقت تحميل النموذج. قد يؤدي تعطيل هذا إلى تحسين الأداء عندما يكون النموذج أكبر من ذاكرة الوصول العشوائي المتاحة للنظام",
  "embedding.load.llama.tryMmap/info": "تحميل ملفات النموذج مباشرة من القرص إلى الذاكرة",
  "embedding.load.seed/title": "البذرة",
  "embedding.load.seed/subTitle": "بذرة مولد الأرقام العشوائية المستخدم في توليد النص. -1 عشوائي",
  "embedding.load.seed/info": "بذرة عشوائية: تعيين بذرة لتوليد الأرقام العشوائية لضمان نتائج قابلة للتكرار",

  "presetTooltip": {
    "included/title": "قيم الإعداد المسبق",
    "included/description": "سيتم تطبيق الحقول التالية",
    "included/empty": "لا توجد حقول من هذا الإعداد المسبق تنطبق في هذا السياق.",
    "included/conflict": "سيتم سؤالك عما إذا كنت تريد تطبيق هذه القيمة",
    "separateLoad/title": "تكوين وقت التحميل",
    "separateLoad/description.1": "يتضمن الإعداد المسبق أيضاً تكوين وقت التحميل التالي. تكوين وقت التحميل خاص بالنموذج بالكامل ويتطلب إعادة تحميل النموذج ليكون فعالاً. اضغط",
    "separateLoad/description.2": "لتطبيق على",
    "separateLoad/description.3": ".",
    "excluded/title": "قد لا ينطبق",
    "excluded/description": "الحقول التالية مدرجة في الإعداد المسبق ولكنها لا تنطبق في السياق الحالي.",
    "legacy/title": "إعداد مسبق قديم",
    "legacy/description": "هذا إعداد مسبق قديم. يتضمن الحقول التالية التي يتم التعامل معها تلقائياً الآن، أو لم تعد قابلة للتطبيق.",
    "button/publish": "نشر في Hub",
    "button/pushUpdate": "دفع التغييرات إلى Hub",
    "button/export": "تصدير"
  },

  "customInputs": {
    "string": {
      "emptyParagraph": "<فارغ>"
    },
    "checkboxNumeric": {
      "off": "إيقاف"
    },
    "llamaCacheQuantizationType": {
      "off": "إيقاف"
    },
    "mlxKvCacheBits": {
      "off": "إيقاف"
    },
    "stringArray": {
      "empty": "<فارغ>"
    },
    "llmPromptTemplate": {
      "type": "النوع",
      "types.jinja/label": "قالب (Jinja)",
      "jinja.bosToken/label": "رمز BOS",
      "jinja.eosToken/label": "رمز EOS",
      "jinja.template/label": "قالب",
      "jinja/error": "فشل في تحليل قالب Jinja: {{error}}",
      "jinja/empty": "الرجاء إدخال قالب Jinja أعلاه.",
      "jinja/unlikelyToWork": "من غير المحتمل أن يعمل قالب Jinja الذي قدمته أعلاه لأنه لا يشير إلى المتغير \"messages\". يرجى التحقق مرة أخرى مما إذا كنت قد أدخلت قالباً صحيحاً.",
      "types.manual/label": "يدوي",
      "manual.subfield.beforeSystem/label": "قبل النظام",
      "manual.subfield.beforeSystem/placeholder": "أدخل بادئة النظام...",
      "manual.subfield.afterSystem/label": "بعد النظام",
      "manual.subfield.afterSystem/placeholder": "أدخل لاحقة النظام...",
      "manual.subfield.beforeUser/label": "قبل المستخدم",
      "manual.subfield.beforeUser/placeholder": "أدخل بادئة المستخدم...",
      "manual.subfield.afterUser/label": "بعد المستخدم",
      "manual.subfield.afterUser/placeholder": "أدخل لاحقة المستخدم...",
      "manual.subfield.beforeAssistant/label": "قبل المساعد",
      "manual.subfield.beforeAssistant/placeholder": "أدخل بادئة المساعد...",
      "manual.subfield.afterAssistant/label": "بعد المساعد",
      "manual.subfield.afterAssistant/placeholder": "أدخل لاحقة المساعد...",
      "stopStrings/label": "سلاسل توقف إضافية",
      "stopStrings/subTitle": "سلاسل توقف خاصة بالقالب سيتم استخدامها بالإضافة إلى سلاسل التوقف المحددة من قبل المستخدم."
    },
    "contextLength": {
      "maxValueTooltip": "هذا هو الحد الأقصى لعدد الرموز التي تم تدريب النموذج على معالجتها. انقر لتعيين السياق إلى هذه القيمة",
      "maxValueTextStart": "يدعم النموذج حتى",
      "maxValueTextEnd": "رمز",
      "tooltipHint": "بينما قد يدعم النموذج عدداً معيناً من الرموز، قد يتدهور الأداء إذا لم تتمكن موارد جهازك من تحمل الحمل - كن حذراً عند زيادة هذه القيمة"
    },
    "contextOverflowPolicy": {
      "stopAtLimit": "التوقف عند الحد",
      "stopAtLimitSub": "التوقف عن التوليد بمجرد امتلاء ذاكرة النموذج",
      "truncateMiddle": "اقتطاع الوسط",
      "truncateMiddleSub": "إزالة الرسائل من منتصف المحادثة لإفساح المجال للرسائل الأحدث. سيظل النموذج يتذكر بداية المحادثة",
      "rollingWindow": "نافذة متحركة",
      "rollingWindowSub": "سيحصل النموذج دائماً على أحدث الرسائل القليلة ولكن قد ينسى بداية المحادثة"
    },
    "llamaAccelerationOffloadRatio": {
      "max": "الحد الأقصى",
      "off": "إيقاف"
    },
    "gpuSplitStrategy": {
      "evenly": "بالتساوي",
      "favorMainGpu": "تفضيل GPU الرئيسي"
    },
    "llamaAccelerationSplitStrategy": {
      "evenly": "بالتساوي",
      "favorMainGpu": "تفضيل GPU الرئيسي"
    },
    "speculativeDecodingDraftModel": {
      "readMore": "اقرأ كيف يعمل",
      "placeholder": "حدد نموذج مسودة متوافق",
      "noCompatible": "لم يتم العثور على نماذج مسودة متوافقة مع اختيار النموذج الحالي",
      "stillLoading": "تحديد نماذج المسودة المتوافقة...",
      "notCompatible": "نموذج المسودة المحدد (<draft/>) غير متوافق مع اختيار النموذج الحالي (<current/>).",
      "off": "إيقاف",
      "loadModelToSeeOptions": "قم بتحميل النموذج <keyboard-shortcut /> لرؤية الخيارات المتوافقة",
      "compatibleWithNumberOfModels": "موصى به لما لا يقل عن {{dynamicValue}} من نماذجك",
      "recommendedForSomeModels": "موصى به لبعض النماذج",
      "recommendedForLlamaModels": "موصى به لنماذج Llama",
      "recommendedForQwenModels": "موصى به لنماذج Qwen",
      "onboardingModal": {
        "introducing": "تقديم",
        "speculativeDecoding": "فك التشفير التخميني",
        "firstStepBody": "تسريع الاستدلال لنماذج <custom-span>llama.cpp</custom-span> و <custom-span>MLX</custom-span>",
        "secondStepTitle": "تسريع الاستدلال مع فك التشفير التخميني",
        "secondStepBody": "فك التشفير التخميني هو تقنية تتضمن تعاون نموذجين:\n - نموذج \"رئيسي\" أكبر\n - نموذج \"مسودة\" أصغر\n\nخلال التوليد، يقترح نموذج المسودة الرموز بسرعة للنموذج الرئيسي الأكبر للتحقق. التحقق من الرموز هو عملية أسرع بكثير من توليدها فعلياً، وهو مصدر مكاسب السرعة. **بشكل عام، كلما زاد الفرق في الحجم بين النموذج الرئيسي ونموذج المسودة، زادت السرعة**.\n\nللحفاظ على الجودة، يقبل النموذج الرئيسي فقط الرموز التي تتماشى مع ما كان سيولده بنفسه، مما يتيح جودة استجابة النموذج الأكبر بسرعات استدلال أسرع. يجب أن يشارك كلا النموذجين نفس المفردات.",
        "draftModelRecommendationsTitle": "توصيات نموذج المسودة",
        "basedOnCurrentModels": "بناءً على نماذجك الحالية",
        "close": "إغلاق",
        "next": "التالي",
        "done": "تم"
      },
      "speculativeDecodingLoadModelToSeeOptions": "يرجى تحميل نموذج أولاً <model-badge /> ",
      "errorEngineNotSupported": "يتطلب فك التشفير التخميني على الأقل الإصدار {{minVersion}} من المحرك {{engineName}}. يرجى تحديث المحرك (<key/>) وإعادة تحميل النموذج لاستخدام هذه الميزة.",
      "errorEngineNotSupported/noKey": "يتطلب فك التشفير التخميني على الأقل الإصدار {{minVersion}} من المحرك {{engineName}}. يرجى تحديث المحرك وإعادة تحميل النموذج لاستخدام هذه الميزة."
    },
    "llmReasoningParsing": {
      "startString/label": "سلسلة البداية",
      "startString/placeholder": "أدخل سلسلة البداية...",
      "endString/label": "سلسلة النهاية",
      "endString/placeholder": "أدخل سلسلة النهاية..."
    }
  },
  "saveConflictResolution": {
    "title": "اختر القيم التي تريد تضمينها في الإعداد المسبق",
    "description": "اختر وحدد القيم التي تريد الاحتفاظ بها",
    "instructions": "انقر على قيمة لتضمينها",
    "userValues": "القيمة السابقة",
    "presetValues": "القيمة الجديدة",
    "confirm": "تأكيد",
    "cancel": "إلغاء"
  },
  "applyConflictResolution": {
    "title": "أي القيم تريد الاحتفاظ بها؟",
    "description": "لديك تغييرات غير مكتملة تتداخل مع الإعداد المسبق الوارد",
    "instructions": "انقر على قيمة للاحتفاظ بها",
    "userValues": "القيمة الحالية",
    "presetValues": "قيمة الإعداد المسبق الوارد",
    "confirm": "تأكيد",
    "cancel": "إلغاء"
  },
  "empty": "<فارغ>",
  "noModelSelected": "لم يتم تحديد أي نماذج",
  "apiIdentifier.label": "معرف API",
  "apiIdentifier.hint": "اختيارياً، قدم معرفاً لهذا النموذج. سيتم استخدامه في طلبات API. اتركه فارغاً لاستخدام المعرف الافتراضي.",
  "idleTTL.label": "إلغاء التحميل التلقائي عند الخمول (TTL)",
  "idleTTL.hint": "إذا تم تعيينه، سيتم إلغاء تحميل النموذج تلقائياً بعد الخمول للمدة المحددة.",
  "idleTTL.mins": "دقائق",

  "presets": {
    "title": "الإعداد المسبق",
    "commitChanges": "تأكيد التغييرات",
    "commitChanges/description": "تأكيد تغييراتك على الإعداد المسبق.",
    "commitChanges.manual": "تم اكتشاف حقول جديدة. ستتمكن من اختيار التغييرات التي تريد تضمينها في الإعداد المسبق.",
    "commitChanges.manual.hold.0": "اضغط مع الاستمرار",
    "commitChanges.manual.hold.1": "لاختيار التغييرات التي تريد تأكيدها في الإعداد المسبق.",
    "commitChanges.saveAll.hold.0": "اضغط مع الاستمرار",
    "commitChanges.saveAll.hold.1": "لحفظ جميع التغييرات.",
    "commitChanges.saveInPreset.hold.0": "اضغط مع الاستمرار",
    "commitChanges.saveInPreset.hold.1": "لحفظ التغييرات فقط في الحقول المضمنة بالفعل في الإعداد المسبق.",
    "commitChanges/error": "فشل في تأكيد التغييرات على الإعداد المسبق.",
    "commitChanges.manual/description": "اختر التغييرات التي تريد تضمينها في الإعداد المسبق.",
    "saveAs": "حفظ كجديد...",
    "presetNamePlaceholder": "أدخل اسماً للإعداد المسبق...",
    "cannotCommitChangesLegacy": "هذا إعداد مسبق قديم ولا يمكن تعديله. يمكنك إنشاء نسخة باستخدام \"حفظ كجديد...\".",
    "cannotCommitChangesNoChanges": "لا توجد تغييرات لتأكيدها.",
    "emptyNoUnsaved": "حدد إعداداً مسبقاً...",
    "emptyWithUnsaved": "إعداد مسبق غير محفوظ",
    "saveEmptyWithUnsaved": "حفظ الإعداد المسبق كـ...",
    "saveConfirm": "حفظ",
    "saveCancel": "إلغاء",
    "saving": "جاري الحفظ...",
    "save/error": "فشل في حفظ الإعداد المسبق.",
    "deselect": "إلغاء تحديد الإعداد المسبق",
    "deselect/error": "فشل في إلغاء تحديد الإعداد المسبق.",
    "select/error": "فشل في تحديد الإعداد المسبق.",
    "delete/error": "فشل في حذف الإعداد المسبق.",
    "discardChanges": "تجاهل غير المحفوظ",
    "discardChanges/info": "تجاهل جميع التغييرات غير المكتملة واستعادة الإعداد المسبق إلى حالته الأصلية",
    "newEmptyPreset": "+ إعداد مسبق جديد",
    "importPreset": "استيراد",
    "contextMenuSelect": "تطبيق الإعداد المسبق",
    "contextMenuDelete": "حذف...",
    "contextMenuShare": "نشر...",
    "contextMenuOpenInHub": "عرض في Hub",
    "contextMenuPushChanges": "دفع التغييرات إلى Hub",
    "contextMenuPushingChanges": "جاري الدفع...",
    "contextMenuPushedChanges": "تم دفع التغييرات",
    "contextMenuExport": "تصدير الملف",
    "contextMenuRevealInExplorer": "إظهار في مستكشف الملفات",
    "contextMenuRevealInFinder": "إظهار في Finder",
    "share": {
      "title": "نشر الإعداد المسبق",
      "action": "شارك إعدادك المسبق للآخرين لتنزيله، الإعجاب به، وتفرعته",
      "presetOwnerLabel": "المالك",
      "uploadAs": "سيتم إنشاء إعدادك المسبق كـ {{name}}",
      "presetNameLabel": "اسم الإعداد المسبق",
      "descriptionLabel": "الوصف (اختياري)",
      "loading": "جاري النشر...",
      "success": "تم نشر الإعداد المسبق بنجاح",
      "presetIsLive": "<preset-name /> متاح الآن على Hub!",
      "close": "إغلاق",
      "confirmViewOnWeb": "عرض على الويب",
      "confirmCopy": "نسخ الرابط",
      "confirmCopied": "تم النسخ!",
      "pushedToHub": "تم دفع إعدادك إلى Hub",
      "descriptionPlaceholder": "أدخل وصفاً...",
      "willBePublic": "نشر إعدادك سيجعله عام",
      "publicSubtitle": "إعدادك عام. يمكن للآخرين تنزيله وتفرعه على lmstudio.ai",
      "confirmShareButton": "نشر",
      "error": "فشل نشر إعدادك",
      "createFreeAccount": "إنشاء حساب مجاني في Hub لنشر إعداداتك"
    },
    "update": {
      "title": "دفع التغييرات إلى Hub",
      "title/success": "تم تحديث إعدادك بنجاح",
      "subtitle": "إجراء تغييرات على <custom-preset-name /> ودفعها إلى Hub",
      "descriptionLabel": "الوصف",
      "descriptionPlaceholder": "أدخل وصفاً...",
      "loading": "جاري الدفع...",
      "cancel": "إلغاء",
      "createFreeAccount": "إنشاء حساب مجاني في Hub لنشر إعداداتك",
      "error": "فشل دفع التغييرات",
      "confirmUpdateButton": "دفع"
    },
    "import": {
      "title": "استيراد إعداد مسبق من ملف",
      "dragPrompt": "سحب وإفلات ملفات JSON لإعداد المسبق أو <custom-link>حدد من جهازك</custom-link>",
      "remove": "إزالة",
      "cancel": "إلغاء",
      "importPreset_zero": "استيراد إعداد مسبق",
      "importPreset_one": "استيراد إعداد مسبق",
      "importPreset_other": "استيراد {{count}} إعدادات مسبقة",
      "selectDialog": {
        "title": "حدد ملف إعداد المسبق (.json)",
        "button": "استيراد"
      },
      "error": "فشل استيراد إعداد مسبق",
      "resultsModal": {
        "titleSuccessSection_one": "تم استيراد إعداد مسبق واحد بنجاح",
        "titleSuccessSection_other": "تم استيراد {{count}} إعدادات مسبقة بنجاح",
        "titleFailSection_zero": "",
        "titleFailSection_one": "({{count}} فشل)",
        "titleFailSection_other": "({{count}} فشل)",
        "titleAllFailed": "فشل استيراد إعدادات مسبقة",
        "importMore": "استيراد أكثر",
        "close": "تم",
        "successBadge": "تم",
        "alreadyExistsBadge": "إعداد مسبق موجود",
        "errorBadge": "خطأ",
        "invalidFileBadge": "ملف غير صالح",
        "otherErrorBadge": "فشل استيراد إعداد مسبق",
        "errorViewDetailsButton": "إظهار التفاصيل",
        "seeError": "إظهار الخطأ",
        "noName": "لم يتم إدخال اسم إعداد مسبق",
        "useInChat": "استخدام في المحادثة"
      },
      "importFromUrl": {
        "button": "استيراد من رابط...",
        "title": "استيراد من رابط",
        "back": "استيراد من ملف...",
        "action": "صق رابط Hub LM Studio لإعداد المسبق الذي تريد استيراده أدناه",
        "invalidUrl": "رابط غير صالح. يرجى التأكد من صق عنوان URL LM Studio Hub صحيح",
        "tip": "يمكنك تثبيت إعداد المسبق مباشرة باستخدام زر {{buttonName}} في Hub LM Studio",
        "confirm": "استيراد",
        "cancel": "إلغاء",
        "loading": "جاري الاستيراد...",
        "error": "فشل تنزيل إعداد مسبق"
      }
    },
    "download": {
      "title": "سحب <preset-name /> من Hub LM Studio",
      "subtitle": "حفظ <custom-name /> إلى إعدادات مسبقة. بذلك ستسمح لك باستخدام هذا الإعداد المسبق في التطبيق",
      "button": "سحب",
      "button/loading": "جاري السحب...",
      "cancel": "إلغاء",
      "error": "فشل تنزيل إعداد مسبق"
    },
    "inclusiveness": {
      "speculativeDecoding": "تضمين في إعداد مسبق"
    }
  },

  "flashAttentionWarning": "Flash Attention هو ميزة تجريبية قد تسبب مشاكل مع بعض النماذج. إذا واجهت مشاكل، جرب تعطيله.",
  "llamaKvCacheQuantizationWarning": "تكميم KV Cache هو ميزة تجريبية قد تسبب مشاكل مع بعض النماذج. يجب تمكين Flash Attention لتكميم KV Cache. إذا واجهت مشاكل، أعد تعيينه إلى الإفتراضي \"F16\".",

  "seedUncheckedHint": "بذرة عشوائية",
  "ropeFrequencyBaseUncheckedHint": "آلي",
  "ropeFrequencyScaleUncheckedHint": "آلي",

  "hardware": {
    "advancedGpuSettings": "إعدادات GPU متقدمة",
    "advancedGpuSettings.info": "إذا كنت غير متأكد، ترك هذه القيم في القيم الافتراضية",
    "advancedGpuSettings.reset": "إعادة تعيين إلى الافتراضي",
    "environmentVariables": {
      "title": "متغيرات البيئة",
      "description": "متغيرات البيئة النشطة خلال حياة النموذج.",
      "key.placeholder": "اختر متغير...",
      "value.placeholder": "القيمة"
    },
    "mainGpu": {
      "title": "GPU الرئيسي",
      "description": "ال-GPU الذي يجب التركيز عليه لحساب النموذج.",
      "placeholder": "اختر GPU الرئيسي..."
    },
    "splitStrategy": {
      "title": "إستراتيجية التقسيم",
      "description": "كيفية تقسيم حساب النموذج عبر ال-GPUs.",
      "placeholder": "اختر إستراتيجية التقسيم..."
    }
  }
}
